% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = computabilità e algoritmi.tex
% !TEX spellcheck = it-IT
\subsection{Codice del merge parallelo}\label{codice-del-merge-parallelo}

Ci sarebbe prima il codice della ricerca binaria, ma è quella classica
sequenziale e che ritorna l'indice dell'elemento in tempo $O(\log n)$

\begin{breakablealgorithm}
	\caption{\textsc{P-Merge}: merge di due array parallelizzato}
	\begin{algorithmic}[1]
\Function{P-Merge}{$T, p_1, r_1, p_2, r_2, A, p_e$}
    \State $n_1 \gets r_1 - p_1 +1$
    \State $n_2 \gets r_2 - p_2 +1$
    \If{$n_1 < n_2$}
        \State inverti le due parti in modo che $n_1 \geq n_2$
    \EndIf
    \If{$n_1 = 0$}
        \State \Return
    \EndIf
    \State $q_1 \gets \lfloor (p_1 + r_1) / 2 \rfloor$ \Comment{Elemento mediano della prima parte}
    \State $q_2 \gets \textsc{Binary-Search}(T[q_1], T, p_2, r_2)$
    \State $q_3 \gets p_3 + (q_1 - p_1) + (q_2 - p_2)$ 
    \State $A[q_3] \gets T[q_1]$
    \State \textbf{spawn } \textsc{P-Merge}$(T, p_1, q_1 -1, p_2, q_2 -1, A, p_3)$ \Comment{Unisce i valori $\leq x$}
    \State \textsc{P-Merge}$(T, q_1 +1, r_1, q_2, r_2, A, q_3+1)$
    \State \textbf{sync}
\EndFunction
\end{algorithmic}
\end{breakablealgorithm}

\subsubsection{Analisi della complessità}\label{analisi-della-complessituxe0}

La durata $PM_\infty(n)$ del merge è data da una costante per i vari calcoli dell'indice, più un tempo logaritmico per la ricerca binaria, più il tempo delle due chiamate che vengono fatte in parallelo.

La durate delle chiamate parallele dipende dal blocco più grande, ma che dimensione ha?

Ogni chiamata, nella peggiore delle ipotesi viene fatta su $n_1/2 + n_2$ elementi, $n_2$ deriva dal fatto che gli elementi della seconda parte dell'array possono essere tutti minori di $x$ o tutti maggiori uguali.

$$\frac{n_1}{2} +n_2 = \frac{n_1}{2} + \frac{n_2}{2} + \frac{n_2}{2} \leq \frac{n}{2} + \frac{n}{4} = \frac{3n}{4}$$

Si ha quindi che

$$
PM_\infty(n) \leq PM_\infty(\frac{3}{4}n) + O(\log n) = O(\log^2 n)
$$

Per quanto riguarda il lavoro si ha

$$
PM_1(n) = PM_1(\alpha n) + PM_1( (1-\alpha) n) + O(\log n)
$$

perché è dato dalla somma del lavoro delle due parti parallele, più il lavoro necessario per la ricerca binaria.

Per quanto riguarda $\alpha$ si ha che è nel range $1/4 \leq \alpha \leq 3/4$.

Risparmiando i conti, il lavoro finale è dato da

$$
PM_1(n) \leq c_1 - c_2 \log (n) = \Theta (n)
$$

Il parallelismo di questo algoritmo risulta essere buono, perché

$$
\frac{PM_1}{PM_\infty} = \Theta (\frac{n}{log^2 n})
$$

e si ottiene uno speedup quasi lineare già per $n$ maggiore di 10.

\subsection{Merge Sort parallelo v2}\label{merge-sort-parallelo-v2}

\begin{breakablealgorithm}
	\caption{\textsc{P-Merge-Sort}: merge sort parallelizzato bene}
	\begin{algorithmic}[1]
\Function{P-Merge-Sort}{$A,p,r, B, S$}
\State $n \gets r - p +1$
\If{$n = 1$}
    \State \Return
\EndIf 
\If{$p < r$}
    \State $T[1 \ldots n] $ nuovo array
    \State $q \gets floor(p+r/2)$
    \State $q' \gets q - p +1$
    \State \textbf{spawn } \textsc{P-Merge-Sort}$(A,p,q, T, 1)$
    \State \textsc{P-Merge-Sort}$(A,q+1,r, T, q'+1)$
    \State \textbf{sync}
    \State \texttt{P-Merge}$(T, 1, q', q'+1, n, B, s)$
\EndIf
\EndFunction
\end{algorithmic}
\end{breakablealgorithm}

Questa versione modificata riceve come parametro anche un'array dove mettere gli elementi una volta ordinati ed esegue le chiamate ricorsive in parallelo.

La differenza sta che una volta sincronizzate le due chiamate, il merge viene fatto con la procedura parallela.

Il lavoro di questa versione è

$$
MS_1(n) = 2 MS_1(n/2) + \Theta(n) = \Theta (n \log n)
$$

che è lo stesso della versione precedente.

La durata invece è

\begin{align*}
MS_\infty (n) &= MS_\infty (n/2) + \Theta(\log^2 n) = \Theta (n) \\
              &=\Theta (\log^3 n)
\end{align*}

ovvero la durata di una delle due chiamate ricorsive parallele, che tanto sono uguali perché l'array viene diviso a metà, più la durata dell merge ricorsivo.

Anche in questo caso il parallelismo risulta essere

$$
O(n \log^2 n)
$$

\section{P-Scan}\label{p-scan}

Si ha a disposizione un'array e una certa operazione associativa da effettuare sugli elementi dell'array, come la somma di interi, la $and$ tra valori booleani, ecc.

Noi ci concentreremo sulla somma di numeri interi.

Fare questo è facile, ed è facilmente parallelizzabile in modo divide-et-impera, ma una cosa più interessante è quella di creare un nuovo array che contiene gli \emph{step intermedi}:

\begin{align*}
y[1] &= x[1] \\
y[2] &= x[1] + x[2] \\
&\vdots \\
y[n] &= x[1] + \ldots + x[n]
\end{align*}

La versione sequenziale dell'algoritmo può essere quindi definita come

\begin{breakablealgorithm}
\begin{algorithmic}[1]
\Function{Scan}{x}
\State \ldots
\State $y[1] \gets x[1]$
\For{$ i = 2 \textbf{ to } n$}
    \State $y[i]\gets y[i-1] (x) x[i]$
\EndFor
\State \Return $y$
\EndFunction
\end{algorithmic}
\end{breakablealgorithm}

Per parallelizzare questa procedura può essere utile calcolare il valore centrale dell'array.

Prima vediamo il codice:

\begin{breakablealgorithm}
	\caption{\textsc{P-Scan}: funzione principale}
	\begin{algorithmic}[1]
\Function{P-Scan}{$x$}
    \State $y[1] \gets x[1]$
    \If{$n > 1$}
        \State //$t$ è un array temporaneo
        \State \textsc{P-Scan-Up}$(x, t, 2, n)$
        \State \textsc{P-Scan-Down}$(x[1], x, t, y, 2, n)$
    \EndIf
    \State \Return $y$
\EndFunction
\end{algorithmic}
\end{breakablealgorithm}

La procedura \textsc{P-Scan-Up} calcola ricorsivamente la somma della prima metà dell'array e pone il risultato al centro dell'array \emph{t}, dopodiché si invoca ricorsivamente sulla seconda parte dell'array \emph{x}. (Le due invocazioni ricorsive vengono fatte in parallelo).
Quando entrambe le chiamate ricorsive sono terminate, viene ritornata la somma dei due risultati.

\todo[inline]{inserire albero chiamate}

\begin{breakablealgorithm}
	\caption{\textsc{P-Scan-Up}}
	\begin{algorithmic}[1]
\Function{P-Scan-Up}{$x,t,i,j$}
    \If {$i = j$}
        \State \Return $ x[i]$
    \EndIf
   \State $k \gets \lfloor (i+j)/2\rfloor$
   \State $t[k] \gets $ \textbf{spawn} \textsc{P-Scan-Up}$(x,t,i,k)$
    \State $r \gets \: \textsc{P-Scan-Up}(x,t,k+1,j)$
    \State \textbf{sync}
    \State \Return $T[k]+r$
\EndFunction
\end{algorithmic}
\end{breakablealgorithm}

La funzione \textsc{P-Scan-Down} utilizza le somme parziali prodotte da \textsc{P-Scan-Up} per calcolare e memorizzare nell'array \textit{y} i risultati finali.

\begin{breakablealgorithm}
		\caption{\textsc{P-Scan-Up}}
		\begin{algorithmic}[1]
\Function{P-Scan-Down}{$v,x,t,y,i,j$}
    \State // $ v $ è il valore della somma fino ad $ i $ escluso
    \If{$i=j$}
        \State $y[i] \gets v+x[i]$
    \Else
        \State $ k \gets \lfloor(i+j)/2\rfloor$
        \State \textbf{spawn} \textsc{P-Scan-Down}($v,x,t,i,k$)
        \State \textsc{P-Scan-Down}($v+t[k],x,t,k+1,j$)
        \State \textbf{sync}
    \EndIf
\EndFunction
\end{algorithmic}
\end{breakablealgorithm}

Il lavoro di \textsc{P-Scan} è

$$
T_{1}^{pscan}(n) = T_{1}^{pscan-up}(n) + T_{1}^{pscan-down}(n) + \Theta(1)
$$

e dal momento che anche le due chiamate vengono fatte in modo
sequenziale, anche la durata è uguale a

$$
T_{\infty}^{pscan}(n) = T_{\infty}^{pscan-up}(n) + T_{\infty}^{pscan-down}(n) + \Theta(1)
$$

Sia \textsc{P-Scan-Up} che \textsc{P-Scan-Down} hanno la stessa durata e lo stesso lavoro, perché fanno operazioni molto simili, ci concentriamo quindi su \textsc{P-Scan-Up}, tanto la differenza è al più di una costante.

Tenendo a mente che $n = j - i +1 $

$$
T_{1}^{pscan-up}(n) = 2 T_{1}^{pscan-up}(n/2) + \Theta(1) = \Theta(n)
$$

e

$$
T_{\infty}^{pscan-up}(n) = T_{\infty}^{pscan-up}(n/2) + \Theta(1) = \Theta(\log n)
$$

Mettendo assieme i vari pezzi si ha che

$$
T_{1}^{pscan}(n) = 2 T_{1}^{pscan-up}(n) = \Theta(n)
$$

e

$$
T_{\infty}^{pscan}(n) = 2T_{\infty}^{pscan-up}(n) = \Theta(\log n)
$$

Il parallelismo dell'algoritmo risulta essere $\Theta(n \log n)$ che è molto buono.


\chapter{Geometria computazionale}

Ci sono varie applicazioni della geometria computazionale

Noi ci concentriamo sullo spazio bi-dimensionale.

L'elemento alla base di tutto è il punto, che sarà caratterizzato da due coordinate, le quali saranno tipicamente dei numeri float che sono soggetti a degli errori di arrotondamento.

Ma c'è sempre il piano B, ovvero utilizzare le coordinate intere a 32 bit.

Le nostre coordinate saranno quindi compresi tra un $-$\textsc{Maxint} e \textsc{Maxint}.

C'è però un problema, tipicamente nella geometria computazionale vengono calcolate delle aree, che devono anch'esse essere contenute in un intero e quindi i valori delle coordinate devono essere compresi in un intervallo $-$\textsc{CMax} e \textsc{CMax} con $\textsc{CMax} \leq \sqrt{\textsc{Maxint}} /2$, quindi facendo due conti si ha $\textsc{Maxint} = 2^{31} $ e $\textsc{CMax} = 2^{15}$.

E' poco ma sufficientemente buono, perché su uno schermo di un metro per un metro si ottengono 32 punti per ogni millimetro.

Una volta stabilito come rappresentare i punti si possono rappresentare:

\begin{itemize}
\item   un segmento, utilizzando due punti
\item   un cerchio, con il centro e il raggio
\item   un poligono, con una serie di punti che rappresentano i vertici.
\end{itemize}

Il vettore \emph{v} di coordinate $(v_x, v_y)$ viene rappresentato con uno qualsiasi dei segmenti orientati $\overrightarrow{pq}$ tali
che $v_x = x_q-x_p$ e $v_y = y_q - y_p$.

Talvolta con lo stesso simbolo può essere rappresentato sia il punto di coordinate $(x_p,y_p)$ che il \textbf{vettore posizione} $(x_p,y_p)$ rappresentato dal segmento orientato $\overrightarrow{op}$, dove \textit{o} è l'origine degli assi.

Il \textbf{prodotto vettoriale} di due vettori $v_1 = (x_1,y_1)$ e $v_2 = (x_2,y_2)$ è definito come:

$$
v_1 \times v_2 = (x_1+x_2, y_1+y_2)
$$

ovvero l'area orientata del parallelogramma di vertici $o, p_1, q,p_2$, l'orientamento è positivo se l'angolo da $v_1$ a $v_2$ è orientato in
senso antiorario, con segno negativo altrimenti.

\begin{figure}
	\centering
	\includegraphics[width=0.7\textwidth]{./notes/immagini/l27-fig1.png}
	\caption{L'area orientata del parallelogramma individuato dai due vettori $v_1$ e $v_2$.}
\end{figure}

L'area orientata può essere calcolata come il determinate della matrice

$$
v_1 \times v_2 = \det \: \begin{bmatrix}
x_1 & x_2 \\
y_1 & y_2
\end{bmatrix} = x_1 y_2 - x_2 y_1
$$

questo perché l'area del trapezio è uguale a

$$
A = \frac{x_2y_2}{2} + x_1\frac{y_2+(y_1+y_2)}{2} - \frac{x_2y_2}{2} - x_2\frac{y_2+ (y_1+y_2)}{2} = x_1y_2 - x_2y_1
$$

Se cambio l'ordine dei punti, il segno dell'area cambia.
