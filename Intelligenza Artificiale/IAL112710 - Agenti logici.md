#Lezione 11 - Agenti logici

![](./immagini/l2-agente-goal.png)

##Base di conoscenza

Un agente logico Ã¨ composto da due componenti che possono essere modificati:

- **Inference Engine** (motore inferenziale): Ã¨ indipendete dal dominio applicativo e permette di utilizzare un linguaggio dichiarativo in quanto Ã¨ in grado di andare a valutare dei simboli.
- **Knowledge base** (base di conoscenza): contiene le informazioni specifiche del problema.

Queste due parti sono tra loro intercambiabili, lo stesso motore inferenziale puÃ² essere utilizzato in piÃ¹ domini specifici e allo stesso modo la stessa base di conoscenza puÃ² essere trattata da vari tipi di motori inferenzial.

**Base di conoscenza**: insieme di sentenze espresse in un linguaggio formale che permette di utilizzare un approccio dichiarativo per definire degli agenti logici.

Le formule o sentenze contenute nella base di conoscenza di un agente rappresentano configurazioni fisiche di una parte dellâ€™agente stesso, il ragionamento svolto dall'agente coinvolgerÃ  la generazione e manipolazione di tali configurazioni.

Tutte le sentenze contenute nella base di conoscenza possono essere espresse come un'unica congiunzione, in questo modo si assume che tutta l'informazione presente nella base di conoscenza sia vera.

Sulla base di conoscenza Ã¨ possibile eseguire un `Tell` o `Dire` per aggiungere informazioni alla base di conosceza oppure Ã¨ possibile andare a cercare delle inforazioni `Ask` o `Chiedere`.

Ogni agente puÃ² essere descritto a *livello di conoscenza* cioÃ¨ per quello che sa e indipendentemente dall'implementazione oppure a *livello implementativo* cosÃ¬ considerando le stutture dati e gli algoritmi che le manipolano.

## Agente bastato sulla conoscenza

```
funciton KB-Agente(percezione) retruns una azione
    static: KB, una base di conoscenza
            t, un contatore inizializzato a 0 che indica il tempo
    Tell(KB, CostruisciFormulaPercezione(percezione, t))
    azione <- Ask(KB, CostruisciInterrogazioneAzione(t))
    Tell(KB, CostruisciForumlaAzione(azione, t)
    t <- t +1
    return azione
```

L'agente deve essere capace di:

- Rappresentare stati, azioni, ecc.
- Incorporare nuove percezioni
- Aggiornare le rappresentazioni interne del mondo (ambiente)
- Dedurre proprietÃ  nascoste del mondo
- Dedurre le azioni appropriate da intraprendere

## Il magico mondo dei Wumpus

**PEAS**: Performance Enviroment "Attuatori" Sensors, sono le caratteristiche di valutazione di un ambiente.

**Misura della prestazione**: +1000 Oro, -1000 Morte, -1 per ogni spostamento, -10 per l'uso della freccia.

**Ambiente**: Scacchiera 4x4 con determinate caratteristiche (vedi slide)

**Attuatori**: Spostamento a DX/SX/UP/DOWN, prendi, lascia, lancia freccia.

**Sensori**: Brezza, Luccichio, Puzza.

Questo ambiente:

- **Non Ã¨ osservabile**: si hanno solo percezioni locali per la casella su cui ci si trova.
- **Deterministico**: i risultati delle azioni sono specificati.
- **Episodico**: no, Ã¨ necessario scegliere una sequenza di azioni.
- **Statico**: sia il Wumpus sia le trappole non si muovono.
- **Discreto**
- **Agente singolo**: il Wumpus fa parte dell'ambiente.

Per muoversi nell'ambiente l'agente deve valutare se Ã¨ sicuro spostarsi in una determinata cella in base alle percezioni che ha nello stato corrente.

In base a queste percezioni deve essere in grado di inferire quali sono le mosse sicure per poi sceglierne una di queste.

In alcune situazioni non Ã¨ possibile andare ad inferire la pericolositÃ  di una mossa, in questo caso Ã¨ necessario passare all'**inferenza probabilitstica**. (Vado a caso ma con il buon senso).

In altri scenari, come quando subito all'inizio si percepisce la puzza del Wumpus, si possono usare strategia di **coercizione**.
In questo caso si sa che c'Ã¨ un Wumpus vicino e si lancia una freccia. Se dove ho lanciato la freccia c'era il Wumpus, questo ora Ã¨ morto ed Ã¨ possibile andarci, se invece la freccia Ã¨ andata a vuoto, ho solamente sprecato la freccia ma ho la certezza che il quadrato Ã¨ sicuro.

## Modelli

I logici tipicamente pensano in termini di modelli, che formalmente sono mondi strutturati rispetto ai quali si puÃ² valutare se un'affermazione Ã¨ vera o falsa.

Formalmente i modelli possibili non sono altro che tutti i modi in cui si possono assegnare i valori alle varie variabili presenti nella sentenza.

Diciamo che *m* Ã¨ un modello di una sentenza ğœ¶ se ğœ¶ Ã¨ vera in *m* e con *M(ğœ¶)* indichiamo l'insieme di tutti i modelli di ğœ¶.

Allora KB (la base di conoscenza) |= ğœ¶ se e solo se *M(KB) âŠ† M(ğœ¶)* (ğœ¶ Ã¨ deducibile dalla base di conosceza).

Questo perchÃ© la KB puÃ² essere vista come una concatenazione di varie sequenze.

Per verificare la deducibilitÃ  Ã¨ necessario andare ad enumerare tutte le possibili combinazioni. Il che vuol dire che se ğœ¶ contiene *n* simboli Ã¨ necessario verificare tutte le 2<sup>*n*</sup> combinazioni.

Si assume sempre che la base di conoscenza sia vera. In questo modo si puÃ² dedurre i letterali ğœ¶ dalla base, da notare anche che se KB|=ğœ¶ allora si sa che ğœ¶ Ã¨ vera, perÃ² se KB|/=ğœ¶ allora non si sa se ğœ¶ Ã¨ vera o falsa.

**Implicazione logica**: tra due formule significa che una *segue logicamenete* l'altra (entailment), in notazione si usa il simbolo ğœ¶|=ğœ· e si dice che "ğœ¶ **implica** ğœ·". La definizione formale di implicazione Ã¨ la seguete: ğœ¶ implica ğœ· se e solo se, in ogni modello in cui ğœ¶ Ã¨ vera, anche ğœ· lo Ã¨.

L'**inferenza** invece Ã¨ il processo con il quale da una proposizione accolta come vera si passa ad una seconda proposizione la cui veritÃ  deriva dal contenuto della prima. L'inferenza Ã¨ quindi il processo che porta a trovare l'implicazione tra due formule.
 
### Modellazione per il Wumpus (lite)

P<sub>i,j</sub> = vero se c'Ã¨ una trappola in (i,j)

B<sub>i,j</sub> = vero se c'Ã¨ brezza in (i,j)

Codifica di alcune percezioni:

- not(P<sub>1,1</sub>)
- not(B<sub>1,1</sub>)
- B<sub>2,1</sub>

Codifica della brezza causata dalla trappole:

- B<sub>1,1</sub> sse (P<sub>1,2</sub>  \/ P<sub>2,1</sub> )
- B<sub>2,1</sub> sse (P<sub>1,1</sub>  \/ P<sub>2,2</sub>  \/ P<sub>3,1</sub>)
- ...

Con queste informazioni Ã¨ possibile andare a creare una tabella di veritÃ , con le colonne per i vari letterali, le informazioni presenti nella base di conoscenza e una colonna per l'affermazione ğœ¶<sub>1</sub> che vogliamo dedurre.

![](./immagini/l11-tabella.png)

Per controllare l'inferenza di ğœ¶<sub>1</sub> Ã¨ necessario andare a verificare tutti i possibili valori di veritÃ  (**model checking**).

### Inferenza per mezzo di enumerazione

Enumerazioni a scandaglio (depth first) di tutti i modelli, Ã¨ un algoritmo corretto e completo.

```
function TVImplica?(KB, ğœ¶) returns true o false
    s <- una lista di simboli proposizioniali contenuti sia in KB che ğœ¶
    return TVVerificaTutto(KB, ğœ¶, s, [])

function TVVerificaTtto(KB, ğœ¶, s, modello) returns true oppure false
    if Vuoto(s) then
        if CPVero(KB, modello) then 
            return CPVero(ğœ¶, modello)
        else
            return true
    else do
        P <- Primo(s); resto <- Resto(s)
        return TVVerificaTutto(KB, a, resto, Estendi(P, true, modello)) and TVVerificaTutto(KB, ğœ¶, resto, Estendi(P, false, modello))    
```

## Metodi di prova

Ci sono due tipologie di prove che si possono fare:

- **Model Checking**: viene fatta l'enumerazioe delle tabelle di verita, con una complessitÃ  esponenziale in *n* (numero di simboli nella KB), puÃ² essere migliorata con euristiche o Hill climbing, ma in questo caso si perde la completezza.
- **Applicazione di regole di inferenza**: si inizia ad estendere la base di conoscenza utilizzando i dati attuali, se ğœ¶ Ã¨ tra queste nuove sentenze allora viene inferito, altrimenti ripeto il passo utilizzando le nuove informazioni inferite. L'utilizzo di questa strategia risulta piÃ¹ efficiente ma le sentenze devono essere scritte in una forma normale.