<html><head><meta charset="utf-8"><link rel="stylesheet" href="_builder/pdf.css"><link rel="stylesheet" href="_builder/highlight/styles/default.css"><script src="_builder/highlight/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><h1 id="apprendimento-automatico">Apprendimento automatico</h1>
<p>Non sempre √® possibile utilizzare degli algoritmi per risolvere un problema.</p>
<p>Per vari motivi:</p>
<ul>
<li>non sempre si pu√≤ formalizzare un determinato problema</li>
<li>ci sono delle situazioni di incertezza</li>
<li>risulta troppo complesso trovare una soluzione oppure sono richieste troppe risorse</li>
</ul>
<p>Alcuni esempi sono: riconoscimento facciale, filtro anti-spam.</p>
<p>In questi casi gli algoritmi (sequenza finita di passi che portano ad un risultato determinato in un tempo finito) non funzionano ed √® quindi preferibile fornire una soluzione &quot;<em>imperfetta</em>&quot;.</p>
<p>In apprendimento automatico si studiano i metodi per trasformare l&#39;infomrazione empirica (dati del problema) in conoscenza.</p>
<p>Questo approccio √® diventato possibile grazie al fatto che grazie ad Internet sono diventati disponibili molti dati.</p>
<h2 id="le-basi">Le basi</h2>
<p>Perch√© il machine leargning funzioni deve esserci un processo (stocastico o deterministico) che spiega i dati che osserviamo, in modo da riuscire a costruire un approssimazione di tale processo che pu√≤ anche risultare imperfetta dal momento che il processo che si vuole approssimare non √® noto.</p>
<p><em>Stocastico</em>: random a probabilit√†</p>
<p>L&#39;obiettivo finale del machine learning √® quello di definire dei criteri da ottimizzare in modo che sia possibile andare a migliorare dei modelli definiti su certi parametri.</p>
<p>Questi modelli possono essere:</p>
<ul>
<li><strong>Preditivi</strong>: per fare previsioni sul futuro (es: filtro anti-spam)</li>
<li><strong>Descrittivi</strong>: utilizzare dei dati per ottenere maggiori informazioni (data mining)</li>
</ul>
<p>Esempi applicativi:</p>
<ul>
<li>Software OCR</li>
<li>Estrapolazione di dati a partire dal linguaggio naturale</li>
<li>Riconoscimento facciale</li>
<li>Giochi con informazione incompleta (Gaist? gioco con fantasmi rosso/blu, tedesco)</li>
</ul>
<h2 id="problemi-tipici-dell-apprendimento-automatico">Problemi tipici dell&#39;apprendimento automatico</h2>
<ul>
<li><strong>Classificazione binaria</strong>: dato un input dire se appartiene ad una determinata classe o meno. Esempio: data una cifre dire se √® uno 0 o meno.</li>
<li><strong>Classificazione multiclasse</strong>: dato un input lo assegno ad una determianta categoria. Es: identificare una cifra manoscritta.</li>
<li><strong>Regressione</strong>: dato un insieme di valori, trovare una funzione che li approssimi.</li>
<li><strong>Ranking di classi</strong> (non sar√† affrontato): data una serie di dati, dire quali sono pi√π rilevanti, ovvero, data una serie di documenti ordinarli nel modo migliore secondo una determinata preferenza, es: motore di ricerca.</li>
<li><strong>Novelty detection</strong>: riconoscimento delle irregolarit√† a partire da una serie di dati. es: frode bancaria su una serie di transazioni, controllo degli accessi, ecc.</li>
<li><strong>Clustering</strong>: raggruppamento di dati in modo gerarchico, basandosi su alcune caratteristiche che li accomunano o meno.</li>
<li><strong>Associazioni</strong>: quello che fa Amazon con &quot;altri utenti hanno comprato&quot;</li>
<li><strong>Reinforcement Learning</strong>: valutazioni di strategie, quando si ha una serie di stati e possibili azioni, si vuole valutare la qualit√† complessiva, es: movimenti di un robot.</li>
</ul>
<h1 id="lezione-2-ripasso-di-probabilit-">Lezione 2 - Ripasso di probabilit√†</h1>
<p>(Kaggle)[<a href="https://www.kaggle.com/">https://www.kaggle.com/</a>], sito che offre sfide con problemi di machine learing sponsorizzati da grandi compagnie.</p>
<p><strong>Proposta di un progetto di gruppo (opzionale):</strong> affrontare uno dei problemi proposti da Kraggle per ottenere un bonus sul voto finale.</p>
<h2 id="problemi-tipici-in-modo-matematico">Problemi tipici in modo matematico</h2>
<p>_Notazione: </p>
<ul>
<li>√ò --&gt; teta, insieme di parametri che rappresenta l&#39;apprendimento (lo so √® il simbolo dell&#39;insieme vuoto, ma √® semplice da fare)</li>
<li>X --&gt; insieme di dati su cui applicare l&#39;algoritmo</li>
<li>Y --&gt; enumeratore (etichette)_</li>
</ul>
<ul>
<li>Classificazione binaria: h(√ò): <code>X --&gt; {-1,+1}</code> (<em>h di teta</em>, funzione che mappa un dato valore in -1 o +1 (oppure 0 o 1) la funzione <em>h</em> √® sempre parametrica, in qunato i parametri rappresentano l&#39;apprendimento (<em>teta</em> √ò));</li>
<li>Classificazione multiclasse: <code>h(√ò): X --&gt; Y</code> con Y che prende come valori un enumeratore o un intervallo di numeri 1..k;</li>
<li>Regressione: <code>h(√ò): X --&gt; Reale</code></li>
<li>Ranking di istanze e classi: <code>h(√ò): XxY --&gt; Reale</code> dati elementi del prodotto cartesiano tra X (esempio) e Y (etichetta) associa un punteggio espresso da un numero reale. Una funzione che valuta la coppia (x,y) con <em>x</em> valore e <em>y</em> classificazione.</li>
<li>Novelty detection: <code>h(√ò): X --&gt; [0,1]</code> funzione che dato un&#39;esempio mi calcola il fattore di rischio come numero reale da 0 a 1.</li>
<li>Clustering: <code>h(√ò): X --&gt; {1,..,k}</code> funzione che ad un esempio associa una valutazione.</li>
<li>Associazioni (Basket Analysis): <code>P(Y|X)</code>.</li>
</ul>
<h2 id="ripasso-di-probabilit-e-statistica">Ripasso di probabilit√† e statistica</h2>
<p><em>Evento</em>: qualcosa che pu√≤ essere o vero o falso.</p>
<p>La probabilit√† che si verifichi un&#39;evento √® un numero compreso tra 0 e 1, <code>0 &lt;= P(E) &lt;= 1</code>. Questo numero pu√≤ essere calcolato usando la frequenza con la quale si verifica l&#39;evento.</p>
<p>Dato un insieme di eventi E_i mutuamente esclusivi tra loro. La probabilit√† dell&#39;unione di tutti gli eventi √® la somma delle probabilit√† dei singoli eventi.</p>
<p>La probabilit√† che si verifichi un evento o il suo complementare √® 1. (sempre se gli eventi sono mutuamente esclusivi).</p>
<p>La probabilit√† dell&#39;unione di due eventi non esclusivi √® data dalla probabilit√† che si verifichi uno o l&#39;altro, meno la probabilit√† che si verifichino entrambi contemporaneamente.</p>
<p><code>P(E unito F) = P(E)+P(F)+P(E intersecato F)</code></p>
<p><strong>Probabilit√† condizionale</strong>: probabilit√† che l&#39;evento E accada sapendo che si √® verificato l&#39;evento F <code>P(E|F)</code>.</p>
<p>L&#39;evento E √® indipendente da F se <code>P(E|F) = P(E)</code>.</p>
<p><code>P(E intersecato F) = P(E|F)*P(F) = P(F|E)*P(E)</code></p>
<p><strong>Formula di Bayes</strong></p>
<p><code>P(F|E) = [P(E|F)P(F)] / P(E)</code></p>
<p>Deriva dalla probabilit√† condizionata, sar√† utile nella classificazioni di tipo <em>bayesiano</em> (non sono sicuro che sia scritto giusto).</p>
<p>Dato un insieme di eventi F_i, tra loro esclusivi ed esasutivi (gli Fi coprono tutti i possibili esiti, la propabilit√† dell&#39;unione di tutti gli F_i √® 1).
Allora <code>E = unione su i (E intersecato F_i)</code>, la probabilit√† di E √® quindi uguale alla sommatoria della probabilit√† di tutte le intersezioni.</p>
<p>Il tutto per arrivare a:</p>
<p><code>P(F_i | E) = [P(E | F_i)P(F_i)] / sommatoria su j ( P(E|F_j)P(F_j))</code></p>
<p><strong>Valore atteso</strong>: detto anche media, con X e Y variabili aleatorie.</p>
<p><code>E[X] = sommatoria su i (x_i * P(x_i))</code></p>
<p><code>E[aX + b] = aE[X] + b</code></p>
<p><code>E[X + Y] = E[X] + E[Y]</code></p>
<p><code>E[g(X)] = sommatoria su i (g(x_i) * P(x_i))</code></p>
<p><code>E[X^n] = sommatoria su i ((x_i)^n * P(x_i))</code> detto anche n-esimo momento </p>
<p><strong>Varianza</strong>: quanto varia il valore ottenuto attorno alla media dei vari esperimenti.</p>
<p><code>sigma^2 = VAR(X) = E[ (X-mu)^2 ]</code> dove <code>mu</code> √® il valore atteso. <code>= E[X^2] - mu^2</code>.</p>
<p><strong>Deviazione standard</strong>: o scarto quadratico medio, √® la radice quadrata della varianza, ed √® la media di quando ci si discosta dal valore attesso.</p>
<h1 id="lezione-3-ripasso-di-probabilit-e-algebra-supervised-learning">Lezione 3 - Ripasso di probabilit√† e algebra + Supervised Learning</h1>
<h2 id="variabili-aleatorie">Variabili aleatorie</h2>
<h3 id="bernoulli">Bernoulli</h3>
<p>Esito di un esperimento che pu√≤ essere positivo o negativo.</p>
<pre><code><span class="hljs-function"><span class="hljs-title">P</span><span class="hljs-params">(X = i)</span></span> = <span class="hljs-tag">p</span>   se i=<span class="hljs-number">1</span> 
           <span class="hljs-number">1</span>-<span class="hljs-tag">p</span> se i=<span class="hljs-number">0</span>
</code></pre><h3 id="binomiale">Binomiale</h3>
<p>La probabilat√† di avere <em>i</em> successi su <em>N</em> esperimenti √® uguale a </p>
<blockquote>
<p>P(X=i) = (N su i)p<sup>i</sup>(1-p)<sup>N-i</sup></p>
</blockquote>
<p>Il valore atteso di questa variabile √® dato da <code>N*p</code> mentre la varianza √® <code>N*p*(1-p)</code>.</p>
<h3 id="distribuzione-uniforme">Distribuzione uniforme</h3>
<p>Assume che in un intervallo <code>[a,b]</code> tutti i punti hanno la stessa probabilit√†.</p>
<blockquote>
<p>P(X = x) = 1 / (b-a) con <code>a &lt;= x &lt;= b</code></p>
<p>P(X = x) = 0 altrimenti</p>
</blockquote>
<p>Il valore atteso di X (<code>E[X]</code>) √® uguale a <code>(a+b)/2</code></p>
<h3 id="distribuzione-normale-gaussaina-">Distribuzione normale (Gaussaina)</h3>
<p>La distribuzione si concentra in un certo valore medio <code>mu</code> ed ha la forma <em>a campana</em>.</p>
<blockquote>
<p>N(mu, sigma<sup>2</sup>)</p>
<p>P(x) = [1 / sigma(‚àö2Pi)]*e<sup>(x-mu)^2 / 2sigma^2</sup></p>
</blockquote>
<p>&lt;!-- https://it.wikipedia.org/wiki/Distribuzione_normale --&gt;
</p>
<h2 id="algebra-lineare">Algebra lineare</h2>
<blockquote>
<p>M ‚Ç¨ R<sup>m x d</sup></p>
</blockquote>
<p>Somma di due matrici: le matrici A e B devono avere la stessa dimensione, e la matrice somma ha come elementi la somma degli elementi delle matrici.</p>
<blockquote>
<p>C = [A + B]<sub>i,j</sub> = [a]<sub>i,j</sub> + [b]<sub>i,j</sub></p>
</blockquote>
<p>Per fare il prodotto di due matrici √® necessario che siano di dimensioni compatibili.</p>
<blockquote>
<p>A ‚Ç¨ R<sup>m x d</sup>
B ‚Ç¨ R<sup>d x k</sup>
L&#39;emento (i,j) della matrice C = A * B √® uguale alla somma del prodotto riga i-esima di a e colonna j-esima di B</p>
</blockquote>
<p>La matrice trasposta di una matriche √® la stessa matrice &quot;<em>ribaltata</em>&quot; sulla diagonale.</p>
<blockquote>
<p>(AB)<sup>T</sup> = B<sup>T</sup>A<sup>T</sup></p>
</blockquote>
<p>Un vettore √® una matrice di una sola colonna. </p>
<p>Il prodotto scalare tra due vettori √® la sommatoria del prodotti dei vari elementi del prodotto.</p>
<p>Due vettori si dicono ortogonali quando il loro prodotto scalare √® 0.</p>
<p>Due vettori si dicono correlati se il loro prodotto scalare √® maggiore di 0, in caso contrario si dicono scorrelati.</p>
<p>La lunghezza di un vettore (norma2, distanza eculidea) √® definita come la radice quadrata della sommatoria dei vari elementi del vettore, eleveati al quadrato.</p>
<p>Allo stesso modo il quadrato della lunghezza √® la sommatoria dei quadrati degli elementi del vettore.</p>
<p>Il prodotto scalare tra due vettori √® anche uguale al prodotto delle lunghezza dei due vettori, moltiplicato anche per il coseno dell&#39;angolo tra i due vettori.</p>
<p>La distanza tra due vettori √® la norma della differenza tra i due vettori.</p>
<p>Matrice inversa e determinante.</p>
<p>Utilizzando le matrici √® possibile risolvere i sistemi lineari.</p>
<p>Una matrice pseudo inversa √® un qualcosa di simile ad una matrice inversa per le matrici rettangolari.</p>
<blockquote>
<p>A<sup>+</sup> = A<sup>T</sup>(AA<sup>T</sup>)<sup>-1</sup></p>
</blockquote>
<h3 id="autovalori-e-autovettori">Autovalori e autovettori</h3>
<blockquote>
<p>A <em> e = lambda </em> e
A matrice
e vettore</p>
</blockquote>
<p><code>e</code> √® un autovettore della matrice A e <code>lambda</code> √® il corrispondente autovalore.</p>
<p><strong>Traccia</strong>: la traccia di una matrice √® la somma degli elementi nella diagonale.</p>
<p>Una matrice si dice <strong>simmetrica</strong> se tutti gli autovalori sono maggiori di 0.</p>
<h2 id="supervised-learning">Supervised Learning</h2>
<p>Si vuole tradurre un insieme di dati in ingresso <em>X</em> in un insieme di dati di uscita <em>Y</em>.</p>
<p>Anche in questo caso c&#39;√® un <em>oracolo</em> che funziona in modo stocastico e che sceglie un oggetto <em>x</em> in <em>X</em> secondo una certa probabilit√† <em>P(x)</em> e sceglie <em>y</em> in <em>Y</em> in base a <em>P(y|x)</em>.</p>
<p>L&#39;obiettivo che si vuole raggiungere √® quello di approssimare queste probabilit√†.</p>
<p>Cosa importante, questo oracolo non sempre √® una funzione, questo perch√© pu√≤ capitare che ad uno stesso <em>x</em> corrispondano <em>y</em> diversi.</p>
<h3 id="operativamente">Operativamente</h3>
<p>Si dispone di una serie di coppie <em>(x,y)</em> che seguono lo schema naturale, insieme di queste coppie prende il nome di <strong>training set</strong>.</p>
<p>Viene quindi scelta un funzione <em>h</em> che prende il nome di <strong>ipotesi</strong>, definita nello spazio delle ipotesi <em>H</em> tale che, da valori presenti nell&#39;insieme <em>X</em>, restituisca dei valori nell&#39;insieme <em>Y</em>.</p>
<p>L&#39;apprendimento consiste quindi nell&#39;andare a scegliere l&#39;<em>h</em> migliore a partire dai dai presenti nel training set in modo che questa funzione approssimi bene i dati presenti nel training set e che riesca a generalizzare e predirre i corretti valori <em>y</em> anche per valori di <em>x</em> non presenti nel training set.</p>
<p>Da ci√≤ segue che possono essere commessi due tipi di errori:</p>
<ul>
<li><strong>Errore empirico</strong>: √® l&#39;errore commesso da <em>h</em> in media, all&#39;interno del training set. In altre parole √® l&#39;errore medio dell&#39;ipotesi sul training set.</li>
<li><strong>Errore ideale</strong>: √® l&#39;errore commesso da <em>h</em> su una qualsiasi coppia <em>(x,y) ~ P(x,y)</em>, come media su un&#39;insieme infinito di coppie. Questo errore pu√≤ essere solamente stimato.</li>
</ul>
<p>Per calcolare una stima dell&#39;errore ideale si pu√≤ usare un <strong>test set</strong>, cio√® un altro insieme di coppie <em>(x,y)</em> che non compaiono nel training set. Questa discriminazione √® importante perch√© se cos√¨ non fosse l&#39;errore ideale sarebbe influenzato dall&#39;errore empirico.</p>
<p><em>Riassumendo: l&#39;errore empirico √® quello che si fa sui dati che si conoscono, l&#39;errore ideale √® quello che si fa su dei dati nuovi.</em></p>
<p>Dal momento che lo spazio delle ipotesi non pu√≤ coincidere con tutte le funzioni calcolabili √®  necessario fare delle assunzioni sulla funzione oracolo, queste assunzioni prendono il nome di <strong>bias induttivo</strong> e derivano da delle conscenze a priori che abbiamo sul dominio e che vengono utilizzate per fare delle previsioni induttive sui dati.</p>
<p>Fanno parte del bias induttivo:</p>
<ul>
<li>Come vengono rappresentati gli esempi;</li>
<li>Come viene modellato lo spazio delle ipotesi <em>H</em>;</li>
<li>La funzione obiettivo per la ricerca nello spazio <em>H</em>, cio√® come viene scelta la funzione <em>h</em>.</li>
</ul>
<h4 id="es-regressione-polinomiale">Es: regressione polinomiale</h4>
<blockquote>
<p>TRAIN = {(x<sub>1</sub>,y<sub>1</sub>),...,(x<sub>n</sub>,y<sub>n</sub>)}</p>
</blockquote>
<p>Si vuole trovare una funzione polinomiale in grado di approssimare i punti.</p>
<p>In questo caso il bias induttivo √® assumere che esista una funzione polinomiale in grado di approssimare i vari punti.</p>
<p>Lo spazio delle ipotesi diventa quindi l&#39;insieme dei vari polinomi e l&#39;apprendimento viene fatto sui vari coefficenti.</p>
<p>Dobbiamo quindi scegliere tra questo spazio un grado <em>p</em> che va a limitare i possibili polinomi (definzione di <em>H</em>) e i vari parametri della curva (ricerca nello spazio <em>H</em>).</p>
<h1 id="lezione-4-laboratorio">Lezione 4 - Laboratorio</h1>
<p>Durante il corso useremo Python 2.7.x</p>
<p>Python √® un linguaggio orientato agli oggetti.</p>
<p>Ogni oggetto √® caratterizzato da:</p>
<ul>
<li>identit√†: √® un identificativo dell&#39;oggetto (!= puntatore).</li>
<li>tipo: rappresenta le operazioni che si possono fare con un oggetto, python √® un linguaggio a tipizzazione dinamica e il tipo viene determinato a runtime.</li>
<li>valore: rappresenta il valore effettivo contenuto nell&#39;oggetto.</li>
</ul>
<p>In python non c&#39;√® il concetto classico di variabile, ma vengono usati dei riferimenti.</p>
<pre><code class="lang-python">x = <span class="hljs-number">2</span>
y = <span class="hljs-number">3</span>
y = x <span class="hljs-comment">//y e x puntano allo stesso oggetto</span>
</code></pre>
<p>La funzione <code>id()</code> permette di sapere l&#39;identificatore di un oggetto.</p>
<p>Gli oggetti in Python sono immutabili.</p>
<p>Contenitori:</p>
<ul>
<li>liste</li>
<li>set (insiemi)</li>
<li>tuple</li>
<li>dizionari</li>
</ul>
<p>Tutti questi contenitori possono essere eterogenei, una lista pu√≤ tenere sia numeri che stringhe contemporaneamente.</p>
<p>Le liste in python sono mutabili.</p>
<p>Un contenitore si dice iterabile se gli elementi possono essere iterati.</p>
<p>Un contenitore si dice sequenziale se √® definita una sequenza di elementi e pu√≤ essere acceduto mediante indice (liste e tuple).</p>
<p>Un contenitere si dice associativo quando si comporta come un dizionario, quindi solo i dizionari.  </p>
<p>In python non esitono i caratteri, esistono solo stringhe di lunghezza uno.</p>
<p>Gli indici per accedere ad una collezione con le <code>[]</code> possono anche essere negativi, in questo caso si procede all&#39;indietro.</p>
<pre><code class="lang-python"><span class="hljs-prompt">&gt;&gt;</span>&gt; s = <span class="hljs-string">"Giacomo"</span>
<span class="hljs-prompt">&gt;&gt;</span>&gt; s[<span class="hljs-number">3</span>]
<span class="hljs-string">'c'</span>
<span class="hljs-prompt">&gt;&gt;</span>&gt; s[-<span class="hljs-number">3</span>]
<span class="hljs-string">'o'</span>
<span class="hljs-prompt">&gt;&gt;</span>&gt; s[<span class="hljs-number">1</span><span class="hljs-symbol">:-</span><span class="hljs-number">3</span>] <span class="hljs-comment">#slicing</span>
<span class="hljs-string">'iac'</span>
</code></pre>
<p><strong>List comprehension</strong></p>
<pre><code class="lang-python">&gt;&gt;&gt; [x**<span class="hljs-number">2</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-function"><span class="hljs-title">range</span><span class="hljs-params">(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>)</span></span>]
[<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">9</span>, <span class="hljs-number">16</span>, <span class="hljs-number">25</span>, <span class="hljs-number">36</span>, <span class="hljs-number">49</span>, <span class="hljs-number">64</span>, <span class="hljs-number">81</span>]
</code></pre>
<p><strong>operatore in</strong></p>
<pre><code class="lang-python"><span class="hljs-keyword">if</span> k <span class="hljs-keyword">in</span> dictiornary:
    <span class="hljs-comment"># something</span>
</code></pre>
<p><strong>copy()</strong></p>
<pre><code class="lang-python"><span class="hljs-operator">a</span> = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]
b = <span class="hljs-operator">a</span>            <span class="hljs-comment"># b riferisce a </span>
c = <span class="hljs-operator">a</span>.copy()    <span class="hljs-comment"># c √® una copia di a (oggetto diverso)</span>
</code></pre>
<h2 id="numpy">numpy</h2>
<pre><code class="lang-python">&gt;&gt;&gt; import numpy as np

&gt;&gt;&gt; a = np.<span class="hljs-built_in">array</span>([<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">8</span>], <span class="hljs-keyword">float</span>)
&gt;&gt;&gt; <span class="hljs-function">a
<span class="hljs-title">array</span><span class="hljs-params">([ <span class="hljs-number">1.</span>,  <span class="hljs-number">4.</span>,  <span class="hljs-number">5.</span>,  <span class="hljs-number">8.</span>])</span></span>
</code></pre>
<p>Questo modulo contiene alcuni metodi utili per la creazioni di matrici o array.</p>
<p><code>a</code> matrice</p>
<ul>
<li><code>a.transpose()</code></li>
<li><code>a + b</code>, <code>a - b</code>, <code>a * b</code>, <code>b / a</code> sono tutte operazioni tra matrici <em>entry wise</em>, cio√® elemento per elemento </li>
</ul>
<h2 id="scipy">scipy</h2>
<pre><code class="lang-python"><span class="hljs-preprocessor"><span class="hljs-keyword">import</span> shipy</span>
</code></pre>
<p>Libreria per la risolzione dei sistemi.</p>
<p>Anche questa ha un suo tipo per le matrici che √® diverso da quello di <code>numpy</code>.</p>
<p>Tra tipi <code>matrix</code> di <code>scipy</code> l&#39;operazione <code>\*</code> effettua il prodotto tra matrici.</p>
<h1 id="lezione-5">Lezione 5</h1>
<h2 id="esempi-di-spazi-delle-ipotesi">Esempi di spazi delle ipotesi</h2>
<p>Seguono alcuni esempi di spazi per le ipotesi nei problemi di apprendimento supervisionato, cio√® quei problemi in cui si vuole stabilire se un elemento <em>x</em> appartiene o meno ad una classe.</p>
<h3 id="iperpiani-in-r-sup-2-sup-">Iperpiani in R<sup>2</sup></h3>
<p><strong>Iperpiano</strong>: dato uno spazio a <em>n</em>-dimensioni, un iperpiano per quello spazio √® un sottospazio di dimensione <em>n-1</em>. Quindi gli iperpiani in R<sup>2</sup> sono tutte le rette del piano.</p>
<p>Lavorando in R<sup>2</sup> lo spazio delle istanze √® definito come:</p>
<blockquote>
<p>X = {x | x œµ R<sup>2</sup>}.</p>
</blockquote>
<p>Mentre lo spazio delle ipotesi √® dato dalle dicotomie indotte da iperpiani in R<sup>2</sup>, cio√® da tutte le possibili divisioni del piano.</p>
<blockquote>
<p>H = {f<sub>(w,b)</sub>(x) | f<sub>(w,b)</sub>(x) = sign(w * x + b), w œµ R<sup>2</sup>, b œµ R}</p>
</blockquote>
<p>Cos√¨ facendo vengono prese in considerazione tutte le rette che dividono R<sup>2</sup> in due parti in modo che da una parte l&#39;ipotesi valga 1 e dall&#39;altra -1.</p>
<h3 id="dischi-in-r-sup-2-sup-">Dischi in R<sup>2</sup></h3>
<p>Sempre in R<sup>2</sup> √® possibile considerare come spazio delle ipotesi tutte le dicotomie indotte da disci in R<sup>2</sup> e centrati nell&#39;origine.</p>
<blockquote>
<p>H = {f<sub>b</sub>(x) | f<sub>b</sub>(x) = sign(||x||<sup>2</sup> - b), w œµ R<sup>2</sup>, b œµ R}</p>
</blockquote>
<p>Il che vuol dire che all&#39;interno del disco le ipotesi valgono -1 mentre al di fuori valgono 1.</p>
<h3 id="congiunzione-di-m-letterali-positivi">Congiunzione di <em>m</em> letterali positivi</h3>
<p>Lo spazio delle istanze questa volta √® dato da tutte le stringhe di <em>m</em> bits </p>
<blockquote>
<p>X = {s | s œµ {0,1}<sup>m</sup>}</p>
</blockquote>
<p>Lo spazio delle ipotesi √® dato da tutte le sentenze logiche che riguardano i letterali positivi l<sub>1</sub>,l<sub>2</sub>,...,l<sub>m</sub> (l<sub>i</sub> √® vero se l&#39;<em>i</em>-esimo bit √® 1) e che contengono solo l&#39;operatore ‚ãÄ.</p>
<blockquote>
<p>H = { f<sub>{i<sub>1</sub>,...,i<sub>j</sub>}</sub>(s) | f<sub>{i<sub>1</sub>,...,i<sub>j</sub>}</sub> (s) equivale a l<sub>i<sub>1</sub></sub> ‚ãÄ l<sub>i<sub>2</sub></sub> ‚ãÄ ... ‚ãÄ <sub>i<sub>j</sub></sub>, {i<sub>1</sub>...i<sub>j</sub>} sottoinsieme di {1..m}}</p>
</blockquote>
<h2 id="misurare-la-complessit-dello-spazio-delle-ipotesi">Misurare la complessit√† dello spazio delle ipotesi</h2>
<p>Considerato un determinato spazio delle ipotesi <em>H</em>, questo contiene sempre:</p>
<ul>
<li>L&#39;<strong>ipotesi pi√π specifica</strong>: ipotesi pi√π stretta, consistente con i dati, nell&#39;esempio del disco √® il disco pi√π stretto in grado di contenere tutti i punti negativi.</li>
<li>L&#39;<strong>ipotesi pi√π generale</strong>: quella pi√π grande, consistente con i dati, sempre nell&#39;esempio del disco, √® quello del disco pi√π grande possibile e che non contiene punti positivi.</li>
</ul>
<p><strong>shattering</strong>: (frammentazione), dato <em>S</em> sottoinsieme dello spazio delle istanze, si dice che <em>S</em> √® frammentato dallo spazio delle ipotesi <em>H</em> se:</p>
<blockquote>
<p>‚àÄ S&#39; ‚äÜ S, ‚àÉ h œµ H, tale che ‚àÄx in S, h(x) = 1 se e solo se x appartiene a S&#39;.</p>
</blockquote>
<p>Cio√® <em>H</em> realizza tutte le possibili dicotomie di <em>S</em>.</p>
<p><em>H</em> frammenta un certo insieme <em>S</em> se √® possibile trovare un iperpiano che raccoglie tutti i punti dell&#39;insieme <em>S</em>. Ovvero per tutte le dicotomie di <em>S</em> esiste un iperpiano che riesce a realizzarle.</p>
<h3 id="vc-vapnik-chervonenkis-dimension">VC (Vapnik-Chervonenkis) Dimension</h3>
<p>La VC-Dimension √® la dimensione di uno spazio delle ipotesi <em>H</em> definito su uno spazio delle istanze <em>X</em> ed √® data dalla cardinalit√† del sottoinsieme pi√π grande frammentato da <em>H</em>.</p>
<blockquote>
<p>VC(H) = max(<sub>S ‚äÜ X</sub>)|S| tale che H frammenta S</p>
<p>VC(H) = ‚àû se S non √® limitato</p>
</blockquote>
<p>Ad esempio nello spazio delle ipotesi dato dagli iperpiani su R<sup>2</sup>.</p>
<p>Se nello spazio delle istanze ho 2 punti, questo viene frammentato da <em>H</em>, perch√© posso sempre trovare una retta che riesce a realizzare tutte le possibili dicotomie di due punti su un piano.</p>
<p>Se nello spazio delle istanze ho 3 punti, riesco comunque a realizzare tutte le dicotomie.</p>
<p>Se nello spazio delle istanze ho 4 punti qualsiasi non si riesce a trovare un iperpiano che realizza la dicotonomia, quindi <em>VC(H) = 3</em>.</p>
<p>Segue che, prendendo uno spazio delle ipotesi di cardinalit√† finita si ha che:</p>
<blockquote>
<p>VC(H) ‚â§ log<sub>2</sub>(|H|)</p>
</blockquote>
<p>Questo perch√© per ogni <em>S</em> frammentato da <em>H</em>, abbiamo <em>|H| &gt;= 2<sup>|S|</sup></em>, cio√® per ogni dicotomia in <em>S</em> esite un ipotesi in <em>H</em> che la realizza, ovvero devono essere disponibili in <em>H</em> tante ipotesi quanti sono le dicotomie in <em>H</em>.</p>
<p>Scegliendo un <em>S</em> tale che <em>|S| = VC(H)</em>, si ottiene <em>|H| &gt;= 2<sup>VC(H)</sup></em>, prendendo il logaritmo si trova quello che si stava cercando, ovvero <em>VC(H) &lt;= log<sub>2</sub>(|H|)</em>.</p>
<p><strong>Dal libro</strong>:</p>
<p>Se un dataset contiene <em>N</em> elementi, questi <em>N</em> elementi possono essere etichettati con degli 0 e 1 in <em>2<sup>N</sup></em> modi diversi.</p>
<p>Se per ognuno di questi modi √® possibile trovare un ipotesi <em>h œµ H</em> che separa tutte le istanze negative da quelle positive allora si dice che <em>H</em> frammenta il dataset <em>N</em>. Il che vuol dire che il dataset <em>N</em> pu√≤ essere appreso con un errore empirico nullo.</p>
<p>Il massimo numero di punti che possono essere frammentati da <em>H</em> √® detto <em>VC(H)</em> e fornisce una misura della capacit√† di <em>H</em>.</p>
<h2 id="bound-sull-errore-di-generalizzazione">Bound sull&#39;errore di generalizzazione</h2>
<p>Considerando un problema di apprendimento binario, con: </p>
<blockquote>
<p>Training set S={(x<sub>i</sub>,y<sub>i</sub>)}<sub>i=1...N</sub></p>
<p>Spazio delle ipotesi H={h<sub>ùúÉ</sub>(x)}</p>
</blockquote>
<p>Supponendo di avere un algoritmo di apprendimento <em>L</em> che restituisce l&#39;ipotesi <em>h<sub>ùúÉ*</sub>(x)</em> che minimizza l&#39;errore empirico su <em>S</em> espresso come <em>errore<sub>S</sub>(h<sub>ùúÉ</sub>(x))</em>.</p>
<p>√à possibile derivare un bound (limite superiore) per l&#39;errore ideale o errore di generalizzazione, valido con probabilit√† <em>(1 - Œ¥)</em> con <em>Œ¥</em> piccolo a piacere:</p>
<blockquote>
<p>errore<sub>D</sub>(h<sub>ùúÉ</sub>(x)) ‚â§ errore<sub>S</sub>(h<sub>ùúÉ</sub>(x)) + g(N, VC(H), Œ¥)</p>
</blockquote>
<p>Il primo termine <em>errore<sub>S</sub>(h<sub>ùúÉ</sub>(x))</em> dipende dall&#39;ipotesi restituita dall&#39;algoritmo di apprendimento L.</p>
<p>Il secondo termine <em>g(N, VC(H), Œ¥)</em> non dipende da <em>L</em>, ma dal numero di esempi di training utilizzati (inversamente proporzionale), dalla <em>VC-dimension</em> (direttamente proporzionale) e dalla confidenza, ovvero dal termine <em>Œ¥</em>.</p>
<p>Il termine <em>g(N, VC(H), Œ¥)</em> viene anche chiamato <strong>VC-confidence</strong> e risulta essere monotono rispetto al rapporto <em>VC(H)/N</em>.</p>
<h2 id="structural-risk-minimization-srm-">Structural Risk Minimization (SRM)</h2>
<p>Approccio per la scelta dello spazio delle ipotesi proposto da Vapnik che cerca di trovare un compromesso tra l&#39;errore empirico e la VC-Confidence.</p>
<p>Si considerano spazi delle ipotesi sempre pi√π piccoli H<sub>1</sub> ‚äÜ H<sub>2</sub> ‚äÜ ... ‚äÜ H<sub>n</sub> tali che VC(H<sub>1</sub>) ‚â§ VC(H<sub>2</sub>) ‚â§ ... ‚â§ VC(H<sub>n</sub>)</p>
<p>Si seleziona lo spazio delle ipostesi H<sub>i</sub> che ha il valore del bound sull&#39;errore di generalizzazione pi√π piccolo.</p>
<p><img src="Apprendimento Automatico/immagini/l5-srm.png" alt=""></p>
<h1 id="lezione-6-apprendimento-di-concetti">Lezione 6 - Apprendimento di concetti</h1>
<h2 id="il-concetto-di-concetto">Il concetto di Concetto</h2>
<p>In uno spazio delle istanze <em>X</em>, un <strong>concetto</strong> √® una funzione booleana su <em>X</em>, cio√® una funzione che prende in input un oggetto dello spazio <em>X</em> e ritorna un booleano che specifica se l&#39;elemento appartiene a quel concetto o meno.</p>
<p>Un concetto <em>C</em> su uno spazio delle istanze <em>X</em> viene definito come una coppia <em>(x,C(x))</em> con <em>x œµ X</em>, e <em>C(x)</em> √® la funzione concetto applicata ad <em>x</em>.</p>
<p>Si dice che un ipotesi booleana <em>h</em> per lo spazio delle istanze <em>X</em> <strong>soddisfa</strong> <em>x œµ X</em> se <em>h(x) == 1</em>.</p>
<p>La stessa ipotesi <em>h</em> si dice che √® <strong>consistente</strong> con un esempio <em>(x,C(x))</em> se <em>h(x) == C(x)</em>.</p>
<p>La definizione di consistenza pu√≤ essere poi estesa ad in insieme se l&#39;ipotesi <em>h</em> √® consistente con tutti gli elementi presenti nell&#39;insieme.</p>
<h2 id="ordine-parziale">Ordine parziale</h2>
<p>Siano <em>h<sub>i</sub></em> e <em>h<sub>j</sub></em> due funzioni booleane definite su uno spazio delle istanze <em>X</em>, diciamo che <em>h<sub>i</sub></em> √® <strong>pi√π generale</strong> o equivalente di <em>h<sub>j</sub></em> (<em>h<sub>i</sub> &gt;=<sub>g</sub> h<sub>j</sub></em>) se:</p>
<blockquote>
<p>‚àÄx œµ X | h<sub>j</sub>(x) == 1 --&gt; h<sub>i</sub>(x) == 1</p>
</blockquote>
<p>Cio√® tutti gli esempi che sono soddisfatti dall&#39;ipotesi pi√π specifica sono sempre soddisfatti anche dall&#39;ipotesi pi√π generale.</p>
<p>Pu√≤ essere che due ipotesi possono non essere comparabili tra loro.</p>
<h2 id="find-s">Find-S</h2>
<p>Algoritmo che permette di trovare tra tutte le ipotesi, quella pi√π specifica e consistente con l&#39;insieme di apprendimento.</p>
<p>Si parte da un training set <em>Tr</em> e si inizializza <em>h</em> con l&#39;ipotesi pi√π specifica di tutte.</p>
<p>Per ogni istanza positiva <em>x</em> del training set, cio√® per tutti gli esempi che appartengono al concetto, si modifica <em>h</em> in modo che riesca a soddisfare l&#39;esempio <em>x</em>.</p>
<p>Una volta terminate le istanze presenti nel training set viene ritornata <em>h</em>.</p>
<p>L&#39;algoritmo parte dall&#39;ipotesi pi√π specifica possibile e man mano che procede nell&#39;analisi del training set la generalizzarla, in modo da trovare la prima ipotesi consistente con il training set che sia il pi√π specifica possibile.</p>
<p>L&#39;ipotesi pi√π specifica di tutte √® quella che rifiuta tutti i valori, poi per ogni istanza del training set positiva, questa viene generalizzata il meno possibile in modo che venga soddisfatta l&#39;istanza che si sta esaminando.</p>
<p>Bisogna notare che l&#39;ipotesi pi√π specifica non √® sempre la migliore, inoltre per funzionare bene il training set dovrebbe essere molto grande.</p>
<h2 id="candidate-elimination">Candidate Elimination</h2>
<p><strong>Version space</strong>: sottoinsieme dello spazio <em>H</em> contenete solo ipotesi che sono consistenti con gli esempi del training set.
Per essere contenuta nel version space, un&#39;ipotesi deve essere pi√π generale o equivalente a quella ottenuta con Find-S.</p>
<p>Dal momento che Find-S ritorna solamente un ipotesi e non √® detto che quella ritornata sia l&#39;ipotesi migliore per il training set √® stato proposto l&#39;algoritmo Candidate Elimination che ritorna tutte le ipotesi contenute nel version space.</p>
<p><strong>Confine pi√π specifico</strong>: <em>S</em>, insieme delle ipotesi <em>s</em> in <em>H</em>, consistenti con il traingin set e tali che non esistano altre ipotesi consistenti e pi√π specifiche.</p>
<p><strong>Confine pi√π generale</strong>: <em>G</em>, insieme delle ipotesi <em>g</em> in <em>H</em>, consistenti nel training set e tali che non esistano altre ipotesi pi√π generali che siano consistenti con il trainging set.</p>
<p>Il version space √® quindi contenuto tra i due confini, cio√® contiene tutte quelle ipotesi pi√π generali di quelle contenute in <em>S</em> e meno generali di quelle contenute in <em>G</em>, <em>S</em> e <em>G</em> inclusi.</p>
<h3 id="algoritmo">Algoritmo</h3>
<p>Si inizializzano gli insiemi <em>G</em> e <em>S</em> in modo che conengano rispettivamente le ipotesi pi√π generali e pi√π specifiche.</p>
<pre><code><span class="hljs-keyword">foreach</span> <span class="hljs-keyword">d</span> == (x,c(x)) <span class="hljs-keyword">in</span> Tr <span class="hljs-keyword">do</span>
    <span class="hljs-keyword">if</span> c(x) = 1
        rimuovi da <span class="hljs-keyword">G</span> ogni ipotesi inconsistente con <span class="hljs-literal">d</span>
        per ogni ipotesi s <span class="hljs-keyword">in</span> S <span class="hljs-keyword">e</span> inconsistente con <span class="hljs-literal">d</span>
            rimuovi s da S.
            aggiungi ad S tutte le generalizzazioni minime <span class="hljs-keyword">h</span> <span class="hljs-keyword">di</span> s tali che sono consistenti con <span class="hljs-keyword">d</span> <span class="hljs-keyword">ed</span> esiste un altra ipotesi <span class="hljs-keyword">g</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">G</span> pi√π generale <span class="hljs-keyword">di</span> <span class="hljs-keyword">h</span>.
            rimuovi da S tutte le ipotesi s' che sono pi√π generali <span class="hljs-keyword">di</span> altre ipotesi <span class="hljs-keyword">in</span> S.
    <span class="hljs-keyword">if</span> c(x) == 0
        rimuovi da S tutte le ipotesi inconsistenti con <span class="hljs-literal">d</span>
        per ogni ipotesi <span class="hljs-keyword">g</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">G</span> inconsistente con <span class="hljs-literal">d</span>
            rimuovi <span class="hljs-keyword">g</span> da <span class="hljs-keyword">G</span>
            aggiungi a <span class="hljs-keyword">G</span> tutte le specificazioni (?) minime <span class="hljs-keyword">h</span> <span class="hljs-keyword">di</span> <span class="hljs-keyword">g</span> tali che siano consistenti con <span class="hljs-keyword">d</span> <span class="hljs-keyword">e</span> che esiste un'altra ipotesi s <span class="hljs-keyword">in</span> S pi√π specifica <span class="hljs-keyword">di</span> <span class="hljs-keyword">h</span>.
            rimuovi da <span class="hljs-keyword">G</span> tutte le ipotesi <span class="hljs-keyword">g</span>' che sono pi√π specifiche <span class="hljs-keyword">di</span> altre ipotesi <span class="hljs-keyword">in</span> <span class="hljs-keyword">G</span>.
</code></pre><p>Quando viene trovato un esempio <em>d</em> nel training set che soddisfa il concetto che si cerca di apprendere:</p>
<ul>
<li>Vengono rimosse da <em>G</em> e da <em>S</em> tutte le ipotesi che sono inconsistenti con <em>d</em>, questo perch√© il version space deve contenere solo ipotesi consistenti con il traingin set.</li>
<li>Per ogni ipotesi <em>s</em> rimossa da <em>S</em> viengono aggiunte tutte le generalizzazioni minime di <em>s</em> che sono in grado di soddisfare <em>d</em>, questo per andare a definire delle nuove ipotesi specifiche e consistenti con il Tr.</li>
<li>Vengono poi rimosse tutte le ipotesi <em>s&#39;</em> da <em>S</em> che sono pi√π generali di altre ipotesi presenti in <em>S</em>, cos√¨ facendo <em>S</em> conterr√† sempre e solo le ipotesi pi√π specifiche.</li>
</ul>
<p>Se <em>d</em> non soddisfa il concetto viene applicato lo stesso scambiando i due insiemi.</p>
<h1 id="lezione-7-alberi-di-decisione">Lezione 7 - Alberi di decisione</h1>
<p>In molte situazioni del mondo reale non √® sufficiente apprendere funzioni booleane con ingressi binari (quello che si fa con il concept learning).</p>
<p>Gli alberi di decisione funzionano bene con:</p>
<ul>
<li>Istanze rappresentate da coppie attributo-valore</li>
<li>Funzioni target con valori di output discreti (pi√π di due valori), come il riconoscimento della categoria di una pagina web</li>
<li>Concetti descritti da disgiunzioni di funzioni booleane</li>
<li>Esempi di apprendimento che possono contenere errori e/o valori mancanti (es: diagnosi medica senza alcuni esami).</li>
</ul>
<p>Gli algoritmi che lavorano su alberi di decisione sono molto efficenti ed √® per questo che vengono utilizzati in applicazioni pratiche.</p>
<h2 id="-il-giorno-giusto-per-giocare-a-tennis-">√à il giorno giusto per giocare a tennis?</h2>
<p>Dati:</p>
<p><img src="Apprendimento Automatico/immagini/l7-tabella.png" alt=""></p>
<p>Albero:</p>
<p><img src="Apprendimento Automatico/immagini/l7-albero.png" alt=""></p>
<p>Come si pu√≤ notare, nell&#39;albero ogni nodo corrisponde ad un attributo e l&#39;arco tra un nodo e l&#39;altro corrisponde uno dei possibili valori, mentre le foglie dell&#39;albero forniscono una classificazione.</p>
<p>Per classificare un&#39;istanza si parte dalla radice e si scende verso le foglie, secondo quanto specificato dai test sugli attributi definiti dai nodi dell&#39;albero.</p>
<p>Se si raggiunge una foglia l&#39;etichetta ad essa associata rappresenta la classificazione.</p>
<p>Dato un albero di decisione, questo corrisponde ad una <strong>disgiunzione di congiunzioni</strong>.</p>
<p>Lo stesso albero pu√≤ essere infatti rappresentato come:</p>
<pre><code>(Outlook = Sunny <span class="hljs-built_in">and</span> <span class="hljs-built_in">Humidity</span> = Normal) 
            <span class="hljs-built_in">or</span> 
    (Outlook = <span class="hljs-built_in">Overcast</span>)
            <span class="hljs-built_in">or</span>
(Outlook = <span class="hljs-built_in">Rain</span> <span class="hljs-built_in">and</span> <span class="hljs-built_in">Wind</span> = Weak)
</code></pre><h2 id="id3-apprendimento-su-un-albero">ID3 - Apprendimento su un albero</h2>
<p>L&#39;algoritmo di apprendimento che costruisce l&#39;albero di decisione trammite una procedura top down in stile divide et impera.</p>
<p>Questo algoritmo apprende l&#39;albero di dicesione costruendolo con un approccio top-down. La costruzione inizia con la domanda &quot;Quale attributo dovrebbe essere testato alla radice dell&#39;albero?&quot;. Per scegliere l&#39;attributo vengono valutati tutti i possibili candidati utilizzando un test statistico per valutare quando bene il singolo attributo classifica il training set.</p>
<p>Viene selezionato il miglior attributo e utilizzato come test alla radice dell&#39;albero. Vengono poi creati tanti figli quanti sono i possibili valori dell&#39;attributo e gli esempi del training set vengono partizionati tra i vari figli, in modo che il loro valore per quell&#39;attributo corrisponda con il valore del nodo.</p>
<p>Questo processo vienei ripetuto per ognuno dei nodi creati fino a che non vengono esaminati tutti gli esempi.</p>
<p>Pi√π formalmente, dato un training set <em>Tr</em> e un insieme di attributi <em>A</em>, algoritmo √® definito come:</p>
<ol>
<li>Crea il nodo radice e copia in <em>T</em> gli esempi di <em>Tr</em> e inserisce tutti gli attributi in <em>A</em>.</li>
<li>Se gli esempi in <em>T</em> sono tutti delle stessa classe, ritorna l&#39;albero con un solo nodo e etichetta uguale alla classe.</li>
<li>Se <em>A</em> √® vuoto, ritorna l&#39;lalbero con un solo nodo e come etichetta la classe di maggioranza in <em>T</em>.</li>
<li>Altrimenti, si sceglie l&#39;attributo <em>a</em> tra gli attributi presenti in <em>A</em> (il migliore) e si partiziona <em>T</em> secondo i possibili valori che l&#39;attributo <em>a</em> pu√≤ assumere: <em>T<sub>a = val<sub>1</sub></sub>, ... ,  T<sub>a = val<sub>n</sub></sub></em><ol>
<li>Per ogni <em>T<sub>a = val<sub>i</sub></sub></em>, se √® vuoto crea una foglia con l&#39;etichetta della classe pi√π frequente, altrimenti crea un sottoalbero con l&#39;algoritmo ID3 con <em>T<sub>a = val<sub>i</sub></sub></em> e <em>A - {</em>a<em>}</em>.</li>
</ol>
</li>
<li>Ritorna <em>T</em>.</li>
</ol>
<p>Quando una partizione risulta vuota, vuol dire che non esistono esempi nel training set per i quali il valore dell&#39;attributo selezionato √® uguale a quel dato valore.</p>
<h3 id="esempio-sui-dati-del-tennis">Esempio sui dati del tennis</h3>
<pre><code>T = {D1, ..., D14}
A = {Outlook, Temperature, <span class="hljs-built_in">Humidity</span>, <span class="hljs-built_in">Wind</span>}

a = Outlook

                   (Outlook)
               /       |       \
            sunny    <span class="hljs-built_in">overcast</span>   <span class="hljs-built_in">rain</span>
            /          |          \
(T_Overlook = Sunny
A = Temp, Hum, <span class="hljs-built_in">Wind</span>})
</code></pre><p>Al secondo passo mi ritrovo scelgo <code>a = Humidity</code>, ottenendo:</p>
<pre><code>                   (Outlook)
               /       |       <span class="hljs-string">\</span>
            sunny    overcast   rain
            /          |          <span class="hljs-string">\</span>
       (Humidity)
       /        <span class="hljs-string">\</span>
    High        Normal
    /               <span class="hljs-string">\</span>
   No               Si
</code></pre><p>In questo caso i figli vengono marcati con un valore quando si √® nel caso in cui tutti gli esempi della partizione hanno lo stesso valore target.</p>
<p>Si prosegue finch√© l&#39;albero non √® completo</p>
<h3 id="alla-ricerca-dell-attributo-ottimo">Alla ricerca dell&#39;attributo ottimo</h3>
<p>Nell&#39;esempio precedente √® stato scelto un attributo a caso, ma nel caso pratico questo non conviene.</p>
<p>Come viene scelto l&#39;ottimo dipende da algoritmo ad algoritmo, nel caso di ID3 vengono utilizzati i concetti di <em>entropia</em> e <em>guadagno entropico</em>.</p>
<blockquote>
<p>E(S) = -p<sub>-</sub>log<sub>2</sub>(p<sub>-</sub>) -p<sub>+</sub>log<sub>2</sub>(p<sub>+</sub>)</p>
</blockquote>
<p>Dove p<sub>-</sub> e p<sub>+</sub> rappresentano la proporzione degli esempi della di una classe e dell&#39;altra (si assume che ci siano solo due classi) all&#39;interno dell&#39;insieme S.</p>
<p>L&#39;entropia misura il grado di purezza degll&#39;insieme degli esempi.</p>
<p>Nel caso ci siano pi√π valori l&#39;entropia si calcola come</p>
<blockquote>
<p>- Sommatoria<sub>v</sub> (p<sub>v</sub>log<sub>2</sub>(p<sub>v</sub>))</p>
</blockquote>
<p>ID3 sceglie come attributo <em>a</em>, quello che massimizza il guadagno entropico.</p>
<blockquote>
<p>G(S,<em>a</em>) = E(S) - Sommatoria<sub>v œµ V(a)</sub> (E(S<sub>a = v</sub>) |S<sub>a=v</sub>| / |S|)</p>
</blockquote>
<p>Il guadagno misura la riduzione aspettata dell&#39;entropia nel partizionare i dati utilizzando <em>a</em>.</p>
<p>L&#39;entropia attesa √® descritta dal secondo termine ed √® semplicemente la sommatoria delle entropie di tutti i sottoinsiemi di <em>S</em>, pesata secondo il numero di esempi che appartengono al sottoinsieme di <em>S</em>.</p>
<p><strong>Problema</strong>: L&#39;utilizzo del guadagno entropico favorisce troppo gli attributi che possono assumere tanti valori diversi, ad esempio l&#39;attributo <em>Data</em>.
Seguendo l&#39;esempio della data, segliere quell&#39;attributo porta ad ottenere tante partizioni, ognuna di pochi elementi e che non forniscono informazioni utili.</p>
<blockquote>
<p>GainRatio(S, a) = G(S, a) / SI(S,a)</p>
</blockquote>
<p>Dove <em>SI</em> rappresenta la <em>split information</em>, un valore che misura quanti e quanto uniformi sono i sottoinsiemi generati dall&#39;attributo <em>a</em> a partire dall&#39;insieme <em>S</em>.</p>
<blockquote>
<p>SI(S,a) = - Sommatoria<sub>v œµ V(a)</sub>( log<sub>2</sub>(|S<sub>a = v</sub>| / |S|) |S<sub>a = v</sub>| / |S| )</p>
</blockquote>
<p>E corrispone all&#39;entropia di <em>S</em> dati i possibili valori di <em>a</em>.</p>
<p><em>GainRatio</em> non risolve tutti i problemi, infatti pu√≤ succedere che attributi significativi e che possono assumere tanti valori, vengano svantaggiati rispetto al altri.</p>
<p>Un&#39;altra idea pu√≤ essere quella di calcolare il <em>Guadagno</em> per ogni attributo e fare la media dei valori trovati, per poi andare a scegliere, tra gli attributi con <em>Guadagno</em> sopra la media, l&#39;attributo che ha <em>GainRatio</em> maggiore.</p>
<h1 id="lezione-8-alberi-di-decisione-2">Lezione 8 - Alberi di decisione 2</h1>
<h2 id="dove-il-bias-induttivo-degli-alberi-di-decisione-">Dove&#39;√® il bias induttivo degli alberi di decisione?</h2>
<p>Con <strong>candidate elimination</strong> c&#39;era l&#39;incompletezza delle ipotesi ma la ricerca all&#39;interno dello spazio √® esaustiva, mentre negli alberi di decisione, c&#39;√® la completezza per quanto riguarda lo spazio delle ipotesi ma la ricerca non √® completa in quanto vengono effettuate scelte greedy.</p>
<p>Un altro bias induttivo √® che tutti gli attributi che producono un guadagno entropico alto si trovano vicino alla radice.</p>
<h2 id="casi-speciali">Casi speciali</h2>
<h3 id="attributi-continui">Attributi continui</h3>
<p>Uno o pi√π attributi hanno dei valori continui, escluso il target che rimane binario o con un numero discreto di possibili valori.</p>
<p>La soluzione √® quella di trasformare dinamicamente un attributo continuo <em>A</em> nell&#39;attributo booleano <em>A<sub>c</sub></em> in modo che sia true se il valore di <em>A</em> √® minore di una certa soglia <em>c</em>.</p>
<p>Il tutto sta ne scegliere la soglia <em>c</em> migliore cio√® che corrispone al massimo guadagno entropico.</p>
<p>Si √® dimostrato che il valore ottimo di soglia si localizza nel valore di mezzo tra due valori a cui corrisponde un target diverso.</p>
<p>Da notare che con ID3 un attributo pu√≤ essere utilizzato soltanto una volta, in questo caso per√≤ √® possibile riutilizzare l&#39;attributo con un <em>c</em> diverso. </p>
<h3 id="attributi-con-costi">Attributi con costi</h3>
<p>In alcune situazioni andare a verificare il valore assunto da un attributo potrebbe avere un costo.</p>
<p>Pu√≤ essere preferibile quindi testare prima gli attributi meno costosi, serve quindi un criterio per la selezione degll&#39;attributo ottimo che tiene conto dei costi.</p>
<p>Alcuni criteri sono:</p>
<blockquote>
<p><strong>Diagnosi medica</strong> (2<sup>Guadagno(S,A)</sup>-1)/(Costo(A)+1)<sup><em>w</em></sup> con <em>w</em> tra 0 e 1 (pi√π vicino a 1 √® <em>w</em> pi√π peso si da al costo)</p>
<p><strong>Percezione robotica</strong>: (Guadagno<sup>2</sup>(S,A))/Costo(A)</p>
</blockquote>
<h3 id="attributi-con-valori-mancanti">Attributi con valori mancanti</h3>
<p>In alcuni casi si vuole classificare qualcosa che non ha tutti i dati per gli attributi.</p>
<p>Questi casi possono essere trattati in vari modi diversi:</p>
<ul>
<li>Utilizzare per <em>A</em> il valore pi√π comune nell&#39;insieme d&#39;esempi associato al nodo interno.</li>
<li>Come prima, solo che vengono considerati solamente esempi con target uguale a quello dell&#39;esempio corrente (ovviamente devo sapere il valore del target dell&#39;esempio corrente).</li>
<li>Considerare tutti i valori <em>a<sub>i</sub></em> che pu√≤ assumere l&#39;attributo e la loro probabilit√† di occorrenza nell&#39;insieme degli esempi associati al nodo interno e andare sostituire l&#39;esempio corrente <em>(x,target)</em> con delle istanze frazionarie per ogni possibile valore di <em>A</em>, ognuna con un peso pari alla probabilit√†. Quando devo scoprire il target di un&#39;esempio &quot;provo&quot; con tutti i possibili valori, e poi faccio la media pesata dei valori ottenuti, rispondo come target la classe pi√π probabile.</li>
</ul>
<h2 id="overfitting">Overfitting</h2>
<p>Cio√® l&#39;ipotesi √® molto accurata sui valori di training, ma sui valori di test risulta meno accurata.</p>
<p>All&#39;aumentare della complessit√† dell&#39;albero creato, l&#39;accuratezza dell&#39;abero sui dati di trainging aumenta, ma una volta provata con i dati di test, l&#39;accuratezza cala drastricamente.</p>
<pre><code><span class="hljs-operator">in</span> fact <span class="hljs-keyword">it</span> can lead <span class="hljs-built_in">to</span> difficulties when there is noise <span class="hljs-operator">in</span> <span class="hljs-operator">the</span> data, <span class="hljs-operator">or</span> when <span class="hljs-operator">the</span> <span class="hljs-built_in">number</span> <span class="hljs-operator">of</span> training examples is too small <span class="hljs-built_in">to</span> produce <span class="hljs-operator">a</span> representative sample <span class="hljs-operator">of</span> <span class="hljs-operator">the</span> <span class="hljs-constant">true</span> target <span class="hljs-function"><span class="hljs-keyword">function</span></span>
</code></pre><p>Si √® osservato che fino ad un certo livello di complessit√† l&#39;accuratezza in training √® molto simile all&#39;accuratezza in test, √® quindi importante <strong>potare</strong> gli albteri complessi.</p>
<p>Ci sono per√≤ due problemi:</p>
<ol>
<li>Come si effettua la potatura?</li>
<li>Quando fermarsi con la potatura o con l&#39;apprendimento?</li>
</ol>
<p>Per quanto riugarda il problema (2) ci sono varie soluzioni:</p>
<ul>
<li>Valutare le prestazioni sull&#39;insieme di apprendimento usando un test statistico;</li>
<li>Valutare le prestazioni su un&#39;insieme separato di validazione;</li>
<li>Usare un principio di <strong>minimizzazione della lunghezza di descrizione (MDL)</strong>: min_Tree[size(tree) - size(errori(tree))].</li>
</ul>
<h3 id="come-potare">Come potare</h3>
<h4 id="reduce-error-pruning">Reduce error pruning</h4>
<p>Pruning a decision node consists of removing the subtree rooted at that node, making it a leaf node, and assigning it the most common classification of the training examples affiliated with that node. Nodes are removed only if the resulting pruned tree performs no worse than-the original over the validation set</p>
<ul>
<li>Dividere il training set in due sottinsiemi, uno per fare training e l&#39;altro per fare validazione.</li>
<li>Ripetere fino a quando le prestazioni peggiorano:<ul>
<li>Per ogni nodo interno <em>n</em> valutare l&#39;impatto del nodo sul sottoinsieme di valutazione avendo potato il nodo</li>
<li>Effettuare la potatura che porta alle prestazioni migliori sull&#39;insieme di valutazione.</li>
</ul>
</li>
</ul>
<p>Al sottoalbero radicato in <em>n</em> si sotistuisce la foglia con etichetta uguale alla classe pi√π frequente nell&#39;insieme degli esempi associati al nodo <em>n</em>.</p>
<h4 id="rule-post-pruning">Rule-Post pruning</h4>
<ul>
<li>Si genera una regola <em>R<sub>i</sub></em> per ogni cammino <em>path(r, f<sub>i</sub>)</em> dalla radice <em>r</em> alla foglia <em>i</em>-esima <em>f<sub>i</sub></em>.</li>
<li>Si effettua la potatura indipendentemente su ogni regola <em>R<sub>i</sub></em>:<ul>
<li>Si stimano le prestazioni utilizzando solo <em>R<sub>i</sub></em> come classificatore</li>
<li>Si rimuovo le precondizioni (una o pi√π) che conducono ad un aumento della stima delle prestazioni utilizzando un approccio greedy.</li>
</ul>
</li>
<li>Si ordinano le <em>R<sub>i</sub></em> potate per ordine crescente di prestazione (evitando i conflitti)</li>
<li>Eventualmente si aggiunge come classicazione di default la classe pi√π frequente</li>
</ul>
<p><em>R<sub>i</sub></em> √® del tipo:</p>
<blockquote>
<p>IF (Attr<sub>i<sub>1</sub></sub> = v<sub>i<sub>1</sub></sub>) ‚ãÄ ... ‚ãÄ (Attr<sub>i<sub>k</sub></sub> = v<sub>i<sub>k</sub></sub>) THEN label<sub>f<sub>i</sub></sub></p>
</blockquote>
<p>La classificazione di una nuova istanza a partire da parte delle regole ordinate avviene seguendo l&#39;ordine stabilito per le regole:</p>
<ul>
<li>La prima regola la cui precondizione √® soddisfatta dalla istanza √® usata per generare la classificazione</li>
<li>Se nessuna regola ha le condizioni soddisfatte, si utilizza la regola di default per la classificazione, cio√® si ritorna la classi pi√π frequente nell&#39;insieme di apprendimento.</li>
</ul>
<h1 id="lezione-9-reti-neurali">Lezione 9 - Reti neurali</h1>
<p>Due approcci principali per studiarle:</p>
<ol>
<li>Riprodurre il cervello umano<ul>
<li>Modellare tutto o parte del cervello umano in modo affidabile, concentrandosi non tanto sul comportamento ma sulla struttura</li>
</ul>
</li>
<li>Estrarre i principi fondamentali di calcolo utilizzati dal cervello<ul>
<li>replicare solamente il compratmento del cervello umano, concentrandosi nei principi fondamentali del calcolo che il cervello utilizza, al fine di produrre un sistema artificiale in grado di replicarli</li>
</ul>
</li>
</ol>
<p>Durante il corso ci concetreremo sul secondo approccio applicato al contesto dell&#39;apprendimento supervisionato.</p>
<h2 id="tipologie-di-reti">Tipologie di reti</h2>
<p>Le reti neurali differiscono per:</p>
<ul>
<li>Topologia della rete</li>
<li>Funzionamento dei neuroni</li>
<li>...</li>
</ul>
<h2 id="quando-usarle-">Quando usarle?</h2>
<p>Quando si hanno tanti input numerici e discreti e si vuole effettuare una classificazione o regressione.</p>
<p>I dati di input possono anche contenere del rumore e la forma della funzione target √® totalmente sconosciuta.</p>
<p>Il risultato finale non deve essere compreso da un esperto umano, il funzionamento della rete √® una black-box.</p>
<p>Tipicamente vengono utilizzate quando non ci sono conoscenze a priori nel dominio.</p>
<h2 id="reti-neurali-artificiali">Reti neurali artificiali</h2>
<p><img src="Apprendimento Automatico/immagini/l9-rete.png" alt=""></p>
<p>Il cervello umano √® sostituito da circa 10 alla 10 neuroni fortemente interconnessi tra loro (da 10 alla 4 a 10 alla 5 connessioni), il tempo di risposta di un neurone √® di circa 0.001 secondi.</p>
<p>Considerando che per riconoscere il contenuto di una scena un unmano impiega circa 0.1 secondi, ne consegue che il cervello umano sfrutta pesantemente il calcolo parallelo: infatti, in questo caso, non pul effettuare pi√π di 100 calcoli seriali.</p>
<p>I processori attuali fanno ancora fatica a lavorare in parallelo.</p>
<p>Una rete neurale artificiale √® un sistema costituito da unit√† interconnesse che calclano funzioni numeriche, ci sono vari tipi di unit√†:</p>
<ul>
<li>le unit√† di input rappresentano le variabili di ingresso</li>
<li>le unit√† di output rappresentano le variabili di uscita</li>
<li>le unit√† nascoste rappresentano le variabili interne che codificano (dopo l&#39;apprendimento) le correlazioni tra le variabili di input relativamente al valore di output che si vuole generare</li>
</ul>
<p>E sulle connessioni tra le varie unit√† sono definiti dei pesi adattabili dall&#39;algoritmo di apprendimento.</p>
<p>Ci sono due modi per replicare un neurone.</p>
<h3 id="hard-threshold-iperpiano">Hard-threshold - iperpiano</h3>
<p><img src="Apprendimento Automatico/immagini/l9-threshold.png" alt=""></p>
<p>L&#39;idea √® quella di avere un vettore di input (nodi d&#39;ingresso) e da ogni nodo arriva un segnale x<sub>i</sub>, ognuno di questi segnali viene aplificato di un fattore w<sub>i</sub>.</p>
<p>C&#39;√® un primo elmento che effettua la sommatoria <em>net</em> di tutti i segnali d&#39;ingresso considerando il loro peso, dove x<sub>0</sub> per devinizione viene posto a 1.</p>
<p>Sul risultato <em>net</em> viene applciata una funzione gradino che ritorna -1 o 1 un base al segno di <em>net</em>.</p>
<p>Si pu√≤ dimostrare che questo tipo di neurone definisce un iperpiano.</p>
<p>Questo perch√© la somamtoria a partire da i=1 pu√≤ essere vista come un W trasposto x +w0 ed √® la definizione precedentemente data di iperpiano.</p>
<h3 id="sigmoidale">Sigmoidale</h3>
<p><img src="Apprendimento Automatico/immagini/l9-sigmoidale.png" alt=""></p>
<p>Utilizza la stessa sommatoria <em>net</em> alla quale viene applicata la funzione œÉ.</p>
<blockquote>
<p>œÉ(z) = 1 / (1 + e<sup>-z</sup>)</p>
</blockquote>
<p>La funzione √® continua e compresa tra 0 e 1.</p>
<p>Il vantaggio fondamentale di œÉ √® che √® una funzione derivabile e quindi permette di utilizzare l&#39;algoritmo di <strong>back propagation</strong> che permette di fare apprendimento all&#39;indietro usando pi√π livelli di neuroni.</p>
<h2 id="perceptron">Perceptron</h2>
<p>√à un singolo neurone con Hard Threshold, l&#39;idea √® quella di ridursi ad un iperpiano.</p>
<p>Quando facciamo apprendimento si cerca di trovare un valore ai vari pesi w<sub>i</sub> in modo da apprendere la funzione target (anche in questo caso viene utilizzato un training set).</p>
<h3 id="implementazione-di-funzioni-booleane">Implementazione di funzioni booleane</h3>
<p>Ad esempio Percepton pu√≤ implementare l&#39;operatore or con gli ingressi y<sup>-</sup> ‚Ç¨ {0,1}<sup>n+1</sup> (stringhe binarie), si possono usare come pesi w&#39;<sub>0</sub> = -0.5 e w&#39;<sub>i</sub> = 1 per i=1...n.</p>
<p>In modo simile pu√≤ essere implementato anche l&#39;operatore and con w&#39;<sub>0</sub> = -n+0.5 e w&#39;<sub>i</sub> = 1 per i = 1..n.</p>
<p>Si pu√≤ anche realizzare l&#39;operatore not con una singola connessione e con un unico peso negativo.</p>
<p>Un problema che il perceptron non riesce a risolvere √® la xor.</p>
<h3 id="apprendimento-di-funzioni-linearmente-separabili">Apprendimento di funzioni linearmente separabili</h3>
<p>Si pu√≤ far apprendere a Perceptron delle funzioni linearmente separabili con un algoritmo che √® garantito che termini.</p>
<p>Tuttavia se la funzione da apprendere non √® linearmente separabile l&#39;algoritmo non converge.</p>
<p>Dato un insieme di apprendimento Tr = {(x<sup>-</sup>,t), dove t ‚Ç¨ {-1,+1}}.</p>
<ol>
<li>Inizializza il vettore dei pesi w al vettore nullo (con tutte le componenti a 0, possono anche essere random ma piccole)</li>
<li>Ripeti finch√© non si raggiunge un punto fisso:<ol>
<li>seleziona a caso uno delgi esempi di apprendimento (x<sup>-</sup>,t)</li>
<li>se out = sign(w<sup>-</sup> * x<sup>-</sup>) != t allora w<sup>-</sup> = w<sup>-</sup> + (t-out)x<sup>-</sup></li>
</ol>
</li>
</ol>
<p>Cio√® per ogni esempio nel training set va a controllare il segno di del prodotto scalare tra x e i pesi, se questo non coincide con il valore di training √® necessario adattare w in modo che anche per x venga calcolato il valore corretto.</p>
<p>In questo modo si riesce ad apprendere una funzione che per costruzione non commette nessun errore nel training set.</p>
<h1 id="lezione-10">Lezione 10</h1>
<p>Perceptron va bene ma non riesce ad apprendere la XOR perch√© non √® linearmente separabile.</p>
<h2 id="reti-di-perceptron">Reti di Perceptron</h2>
<p>Una rete di Perceptron pu√≤ apprendere qualsiasi funzione booleana.</p>
<p>Problema: come effettuare l‚Äôapprendimento di una rete di Perceptron?</p>
<p>Non si sa come assegnare pesi alle unit√† nascoste,una possibile soluzione e`quella di rendere il singolo neurone derivabile e sfruttare la tecnica di Discesa del Gradiente per apprendere i pesi &quot;giusti&quot;.</p>
<h3 id="discesa-di-gradiente">Discesa di gradiente</h3>
<p><strong>Richiami di analisi</strong>: il segno della derivata di una funzione determina se la funzione √® crescente o decrescente. Inoltre se la derviata vale 0, la funzione in quel punto ha un minimo o un massimo locale.</p>
<p>Il core business della derivata √® che noi possiamo seguire il segno della derivata per trovare dei valori pi√π grandi per la funzione originale.</p>
<hr>
<p><img src="Apprendimento Automatico/immagini/l10-threshold.png" alt=""></p>
<p>La funzione obbiettivo da minimizzare √® la <strong>funzione errore</strong>, l&#39;idea della funzione √® di calcolare lo scarto quadratico medio del valore target predetto dal neurone (<em>funzione out</em>).</p>
<p>L&#39;idea della disceza di grandiente √® quello di spostarsi nella direzione contraria del gradiente in modo da ottenere il valore pi√π piccolo della funzione obiettivo.</p>
<p><img src="Apprendimento Automatico/immagini/l10-step.png" alt=""></p>
<p><em>-Œ∑</em> √® lo step con il quale mi sposto.</p>
<p>Per calcolare lo spostamento rispetto ad ogni <em>w_i</em> per minimizzare la funzione obiettivo, vado a calcolare la derivata.</p>
<p><em>out^(d)</em> e <em>t^(d)</em> si riferiscono all&#39;esempio <em>d</em>-esimo nel training set.</p>
<p><img src="Apprendimento Automatico/immagini/l10-step-passaggi.png" alt=""></p>
<h4 id="algoritmo-di-apprendimento">Algoritmo di apprendimento</h4>
<p><em>Œîw_i</em> rappresenta lo spostamento dal w_i iniziale</p>
<p><img src="Apprendimento Automatico/immagini/l10-algoritmo-gradiente.png" alt=""></p>
<p>In pratica prima viene esaminato tutti il training set per aggiornare i vari <em>Œîw_i</em>, una folta finito di esaminare il training set si aggiornano i <em>w_i</em> e si riparte da capo.</p>
<p>Le condizioni di stop dell&#39;algoritmo possono essere:</p>
<ul>
<li><em>E(w)</em> minore di una soglia prefissata</li>
<li><em>Œîw_i = 0 ‚àÄi</em></li>
<li>Il numero di iterazioni ha superato una soglia prefissata. </li>
</ul>
<h3 id="discesa-di-gradiente-con-sigmoide">Discesa di gradiente con sigmoide</h3>
<p><img src="Apprendimento Automatico/immagini/l10-sigmoidale.png" alt=""></p>
<p>Nell&#39;ultimo conto c&#39;√® una &quot;)&quot; di troppo.</p>
<p>L&#39;algoritmo di apprendimento √® sempre lo stesso, cambia come vengono aggirnati i <em>Œîw_i</em>.</p>
<h2 id="rete-di-perceptron">Rete di Perceptron</h2>
<p><img src="Apprendimento Automatico/immagini/l10-rete.png" alt=""></p>
<p><img src="Apprendimento Automatico/immagini/l10-rete-parametri.png" alt=""></p>
<p>L&#39;errore √® l&#39;errore quadratico medio di tutte le unit√† di output.</p>
<h3 id="calcolo-dei-pesi-per-le-unit-di-output">Calcolo dei pesi per le unit√† di output</h3>
<p>Calcoliamo i pesi per le unit√† di output, considerando i livelli nascosti come se fossero degli ingressi.</p>
<p>I <em>w_i</em> adesso diventano <em>w_k,j</em> perch√© i pesi sono come pesi da un&#39;unit√† nascosta <em>j</em> all&#39;unit√† di output <em>k</em>.</p>
<p><img src="Apprendimento Automatico/immagini/l10-rete-output.png" alt=""></p>
<p>Nel secondo passo sono state fatte due operazioni, prima viene tolta la sommatoria, perch√© quando viene fatta la derivata della sommatoria c&#39;√® un solo elemento diverso da ed √® quello di indice <em>k^=k</em>.</p>
<h3 id="calcolo-dei-pesi-per-le-unit-nascoste">Calcolo dei pesi per le unit√† nascoste</h3>
<p><img src="Apprendimento Automatico/immagini/l10-rete-input.png" alt=""></p>
<h3 id="algoritmo-di-apprendimento">Algoritmo di apprendimento</h3>
<p>L&#39;apprendimento viene fatto in due fasi, una <strong>forward</strong> nella quale si fa apprendimento sull&#39;input, e una base <strong>backward</strong> nella quale si fa apprendimento sull&#39;output. Ma non ne sono sicuro.</p>
<p><img src="Apprendimento Automatico/immagini/l10-apprendimento-rete.png" alt=""></p>
<p>Il passo 2 rappresenta la fase <strong>forward</strong> mentre il passo 3 rappresenta la fase <strong>backward</strong></p>
<p>Le possibili condizioni di terminazione sono le stesse che si hanno quando c&#39;√® un solo neurone.</p>
<h1 id="lezione-11-reti-neurali-3">Lezione 11 - Reti neurali 3</h1>
<p>Pipeline di apprendimento supervisionato per una rete.</p>
<h2 id="oggetti">Oggetti</h2>
<p>In natura possono essere presenti varie tipologie di oggetti:</p>
<ul>
<li><strong>vettori</strong>: come il valore di pressione del sangue, il battito cardiacoo, altezza e peso, (Un vettore con dei numeri.</li>
<li><strong>stringhe</strong>: Una serie di caratteri che rappresentano un documento o la struttura del DN</li>
<li><strong>insiemi</strong>: ad esempio l&#39;insieme di termini che compare in un documento</li>
<li><strong>array multidimensionali</strong>: come immagini e video</li>
<li><strong>albero o grafi</strong>: un documento XML </li>
<li><strong>strutture composte</strong>: ottenute combinando tra loro le precedenti.</li>
</ul>
<p>Nel corso ci concentriamo principamente nei vettori.</p>
<p>Per ogni oggetto possiamo avere a disponsizione delle <strong>feature categoriche</strong>, che rappresentano delle caratteristiche nominali dell&#39;oggetto (marca di un auto, paese di origine), alcune di queste possono essere anche <strong>ordinali</strong>, cio√® che impongno un ordine (gradi militari: soldato, caporale,...) ma la distanza tra un valore e un altro non √® quantificabile.</p>
<p>Possono essere definite delle <strong>feature quantitative</strong>, cio√® delle caratteristiche che sono <strong>enumerabili</strong> (livello di apprezzamento di un prodotto) oppure <strong>ratio</strong>, ovvero dei numeri reali (peso di una persona).</p>
<h3 id="mapping-feature-categoriche">Mapping Feature categoriche</h3>
<p>Le feature categoriche si possono mappare in un vettore con tante componenti quanti sono i possibili valori della variabile (<strong>one-hot</strong>).</p>
<p>Esempio: possibili valori delle variabili:</p>
<ul>
<li>Marca: Fiat [c1], Toyota [c2], Ford [c3]</li>
<li>Colore: Bianco [c4], Nero [c5], Rosso [c6],</li>
<li>Tipo: Economica [c7], Sportiva [c8]</li>
</ul>
<p>Un oggetto con le caratteristiche (Toyota, Rossa, Economica) viene rappresentato con un vettore <code>[0,1,0,0,0,1,1,0]</code></p>
<h3 id="mapping-per-feature-continue">Mapping per feature continue</h3>
<p>Tipicamente le feature continue vengono trasformate per ottenere dei valori comparabili con le altre feature.</p>
<p>Per ottenere ci√≤ √® possibile applicare una delle seguenti traformazioni:</p>
<ul>
<li><strong>Centramento</strong>: <em>f(x) = x - E(x)</em></li>
<li><strong>Normalizzazione STD</strong>: <em>f(x) = (x - E(x))/œÉ(x)</em></li>
<li><strong>Rescaling</strong>: <em>f(x) = (x - xmin)/(xmax-xmin)</em></li>
</ul>
<h3 id="similarit-e-distanza">Similarit√† e Distanza</h3>
<p>Distanza tra vettori: se i vettori hanno stessa norma, la disntaza √® equivalente alla similarit√† indotta dal prodotto scalare.</p>
<p>Altrimenti anche la lunghezza dei due vettori conta.</p>
<p>Se i vettori sono normalizzati, allora la distanza e la similarit√† coindicono, senn√≤ distanza e similiarit√† non sono lo stesso valore.</p>
<h3 id="algoritmo-k-nn">Algoritmo k-nn</h3>
<p><strong>K-Nearest-Neighbors</strong>: √® un algoritmo di classificazione in cui un esempio di test √® classificato come la classe di maggioranza dei sui k-vicini nel training set.</p>
<p>Si vanno a scegliere i k elementi pi√π vicini ad un dato elemento, e l&#39;elemento viene classificato come la maggioranza dei sui k-vicini.</p>
<p>Volendo si pu√≤ normalizzare per perdere volontariamente delle informazioni, in modo da togliere del rumore.</p>
<h2 id="scelta-degli-iper-parametri">Scelta degli iper-parametri</h2>
<p>I parametri sono i valori che influiscono nell&#39;apprendimento (i pesi w). Gli iper-parametri sono tutti gli altri parametri che non influiscono con l&#39;apprendimento, come il numero di unit√† nascoste o il k per l&#39;algoritmo k-nn.</p>
<p><strong>Model selection</strong>: fase di una piple di apprendimento dove si vanno a individuare gli iper-parametri che ...</p>
<h3 id="bias-e-varianzaa">Bias e varianzaa</h3>
<p>Il bias misura la distorsione di una stima (quanto lo stimatore √® corretto), mentre la varianza misura la dispersione di una stima.</p>
<p>ùúÉ √® la cosa corretta, ùúÉ&#39; √® quella calcolata dallo stimatore.</p>
<p>b = E[ùúÉ&#39;] - ùúÉ </p>
<p>v = E[(ùúÉ&#39; - E[ùúÉ&#39;])<sup>2</sup>]</p>
<h3 id="hold-out">Hold out</h3>
<p>Ovvero la ricerca del valore per un determinato iper-parametro.</p>
<ol>
<li>Si sceglie un piccolo sottoinsieme Tr del training-set che viene utilizzato come set di validazione Va.</li>
<li>Il classificatore (algoritmo) apprende utilizzando gli esempi in Tr ma senza usare quelli che compaiono in Va.</li>
<li>Osservo poi come si comporta il classificatore con un determinato valore dell&#39;iper-parametro, e ripeto a partire dal punto 2 per tutti i possibili valori dell&#39;iper-parametro.</li>
</ol>
<p>In questo modo riesco a calcolare l&#39;<em>accuracy</em> per ogni valore del iper-parametro e di conseguenza posso scegliere il valore migliore.</p>
<p>Una volta scelto il valore, rieffetto l&#39;apprendimento utilizzando per√≤ il training set completo.</p>
<h3 id="k-fold-cross-validation">K-fold Cross Validation</h3>
<p>Alternativa all&#39;hold-out, cio√® permette anche questo di scegliere il valore migliore per un dato iper-parametro.</p>
<p>Si partizione in modo casuale l&#39;insieme di apprendimento in k parti.</p>
<p>Viene poi fissata una partzione da usare come Va e le restanti come insieme di apprendimento.
Si ripete questo procedimento per ogni partzione.</p>
<p>Per ogni valore dell&#39;iper-parametro si ottengono cos√¨ k valori di accuracy, in questo modo √® possibile fare la media di questi valori ed ottenere cos√¨ un valore di accuracy pi√π accurato.</p>
<p>Il valore di k influisce la dimensione del training set, utilizzando un k piccolo, si ottiene un training set pi√π piccolo e il bias induttivo aumenta e la varianza della stima ottenuta diminuisce.</p>
<p>Viceversa, se k √® grande, il training set √® pi√π grande e si ottiene un minor bias induttivo.</p>
<p>Tipicamente si usa k=5 o k=10.</p>
<h2 id="valutazione-per-dati-non-bilanciati">Valutazione per dati non bilanciati</h2>
<p>Cio√® quando nel training set c&#39;√® una classe che domanina sulle altre.</p>
<p>L&#39;accuracy in questo caso non √® una misura adatta.</p>
<p>Vengono quindi utilizzate <strong>precision</strong>, <strong>recall</strong> e <strong>F-Measure</strong>.</p>
<p><strong>Precision</strong> misura quante volte, quanti tra quelli classificati positivi sono effettivamente positivi, mentre la <strong>recall</strong> misura quanti che sono effettivamente positivi sono stati classificati come positivi.</p>
<p><strong>Precioson</strong>: quanti tra quelli che ho detto essere positivi sono effettivamente positivi.</p>
<blockquote>
<p>œÄ  = true positive / (true positive + false positive)</p>
</blockquote>
<p><strong>Recall</strong>: quanti tra quelli che so essere positivi sono riuscito a classificare correttamente (ovvero li ho calcolati positivi).</p>
<blockquote>
<p>p = true positive / (true positive + false negative)</p>
</blockquote>
<p><strong>F-measure</strong>: combina tra loro precision e recall.</p>
<blockquote>
<p>F<sub>1</sub> = 2 œÄp / (œÄ + p)</p>
<p>F<sub>ùú∑</sub> = (1+ùú∑<sup>2</sup>)œÄp / (ùú∑<sup>2</sup> +....)</p>
</blockquote>
<h1 id="lezione-12-super-vector-machine">Lezione 12 - Super Vector Machine</h1>
<p>Richiamo: l&#39;errore ideale, cio√® quello commesso su esempi che non sono stati valutati durante l&#39;apprendimento, pu√≤ essere visto come composto da due termini, un errore empirico sui dati e la VC-Confidence.</p>
<p>L&#39;algoritmo di minimizzazione dei rischi cerca lo spazio delle impotesi che va a minimizzare la VC-Confidence.</p>
<h2 id="svm-idea-di-base">SVM - Idea di base</h2>
<p>Sappiamo che la VC dimension di un iperpiano nello spazio <em>m</em> √® <em>m+1</em>.</p>
<p>Considerando il caso in cui gli esempi sono linearmente separabili si pu√≤ definire il margine <em>r</em> come la distanza minima tra l&#39;iperpiano e l&#39;esempio pi√π vicino.</p>
<p>L&#39;iperpiano che ha un margine maggiore viene detto ottimo e massimizza la minima distanza con gli esempi.</p>
<p><img src="Apprendimento Automatico/immagini/l12-space.png" alt=""></p>
<h3 id="margine">Margine</h3>
<p><img src="Apprendimento Automatico/immagini/l12-distanza.png" alt=""></p>
<p><img src="Apprendimento Automatico/immagini/l12-distanza-2.png" alt=""></p>
<p><img src="Apprendimento Automatico/immagini/l12-distanza-3.png" alt=""></p>
<p>Vincoli e funzione di costo sono convessi perch√© i vincoli sono lineare e il costo √® una parabola.</p>
<p><img src="Apprendimento Automatico/immagini/l12-caso-separabile.png" alt=""></p>
<p><img src="Apprendimento Automatico/immagini/l12-caso-separabile-2.png" alt=""></p>
<p>Quindi i vettori di supporto sono gli esempi di training che si trovano in uno dei due iperpiani margine.</p>
<h1 id="lezione-13-support-vector-machine">Lezione 13 - Support Vector Machine</h1>
<p>Nelle precedenti puntate:</p>
<ul>
<li>Sappiamo che un iperpiano in uno spazio di dimensione m ha VC dimension m+1.</li>
<li>Si pu√≤ aggiungere un vincolo di classificazione relativo al margine.</li>
<li>Per ottenere l&#39;iperpiano con margine ottimo √® necessario considerare le ipotesi che minimizza la norma di <em>w</em>.</li>
<li>Il tutto si fa prima con un polinomio di Lagrange e il suo duale.</li>
</ul>
<h2 id="dati-non-separabili-linearmente">Dati non separabili linearmente</h2>
<p>Tutto quello visto finora funziona se i dati sono linearmente separabili.</p>
<p>Nel caso questi non lo siano √® necessario aggiungere una nuova variabile per ogni elemento presente nel training set.</p>
<p><img src="Apprendimento Automatico/immagini/l13-non-linear.png" alt=""></p>
<p>Vengono quindi definite delle psi_i che rappresenta la distanza del elemento i-esimo dal margine entro il quale dovrebbe trovarsi.</p>
<p>L&#39;idea √® quindi quella di andare a sommare alla funzione costo, un altro quoziente della sommatoria di tutti i psi_i dei vari esempi presenti nel training set.</p>
<p>Il valore <em>C</em> del coefficente che va a moltiplicare la sommatoria degli psi_i pu√≤ essere scelta con le tecniche di model selection.</p>
<p>In pratica vengono penalizzati (aumentato il costo) gli esempi che non rispettano il margine.</p>
<p>La funzione psi_i si comprota anche come upper buond per la rappresentazione dell&#39;esempoio i-esimo del trainging set.</p>
<p>Sommando le psi_i di tutti gli esempi √® maggiore o ugale al numero di errrori analizzzando tutto il trainingset.</p>
<p><img src="Apprendimento Automatico/immagini/l13-slack.png" alt=""></p>
<p>Allo stesso modo si pu√≤ trovare il problema duale (non vengono visti i conti)</p>
<p><img src="Apprendimento Automatico/immagini/l13-cost.png" alt=""></p>
<p>Da notare che nel caso separabile i vettori di supporto stanno su uno dei due iperpiani margini.</p>
<p>Nel caso di dati non linearmente separabili o si trovano in un ipermpiano margine oppire uno psi_i negativo.</p>
<p>Da notare che le psi_i sono variabili del problema primale e che quindi non compaiono nel problema duale.</p>
<p>Questa strategia per esempi non linearmente separabili non sempre garantisce buone prestazioni perch√© un iperpiano pul solo rappresentare dicotomie dello spazio delle istanze.</p>
<p>Per questo motivio, quando gli esempi non sono lineramente separabili su usa una strategia divisa in due passi:</p>
<ol>
<li>Si mappano i dati di ingresso (input sapce) in uno spazio a dimnesione molto superirore (feature space). Quindi a partire dalle feature degli elementi dell&#39;input space vengono creati nuovi esempi nel feature space che utilizza combinazioni non lineari delle feature del primo spazio.</li>
<li>Si calcola poi l&#39;iperpiano ottimo per il nuovo spazio usando la formulazione precedente (che prende il nome di variabili slack).</li>
</ol>
<p>Perch√© dovrei farlo?</p>
<ol>
<li>Perch√© il teorema sulla separabilit√† di Cover afferma che uno spazio delle ipotesi pi√π grande √® pi√π probabile che questo sia linearmente separabile. (Un problema di classificazione complesso, formulato attrvareso una trasfomrazione non linear dei dati in uno spazio ad alata dimensionalit√†, ha maggiore probabilit√† di essere linearmente separabile che in uno spazio a bassa dimnsionalit√†).</li>
<li>Perch√© l&#39;iperpiano ottimo minimizza la VC-Dimension e quindi la capacit√† di generalizzazione migliora.</li>
</ol>
<p><img src="Apprendimento Automatico/immagini/l13-alt.png" alt=""></p>
<p>In un modo simile a come accade con il perceptron.</p>
<p><img src="Apprendimento Automatico/immagini/l13-train.png" alt=""></p>
<h2 id="funzioni-kernel">Funzioni Kernel</h2>
<p><img src="Apprendimento Automatico/immagini/l13-kernel.png" alt=""></p>
<p>La cosa bella √® che si pu√≤ &quot;inventare&quot; una funzione K che ci permette di calcolare agevolmente il prododdo scalare.</p>
<p><img src="Apprendimento Automatico/immagini/l13-kernel-2.png" alt=""></p>
<p><img src="Apprendimento Automatico/immagini/l13-comparsion.png" alt=""></p>
<h2 id="regressione">Regressione</h2>
<p>Quando si considera il problema di approssimazione di funzioni a valori reali (regressione) si utilizza l&#39;œµ-tubo: output che differiscono dai valori di target per pi√π di œµ in valore assolunto vengono penalizzati linearmente, altrimenti non vengono considerati errori.
In partica aggiungo un intervallo di tolleranza al iperpiano che partiziona lo spazio.</p>
<p><img src="Apprendimento Automatico/immagini/l13-min-primale.png" alt=""></p>
<p>che trasformata in duale diventa</p>
<p><img src="Apprendimento Automatico/immagini/l13-duale.png" alt=""></p>
</body></html>