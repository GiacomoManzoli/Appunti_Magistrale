#Lezione 5 VC-Dimension e VC-Confidence

##Esempi di spazi delle ipotesi

Seguono alcuni esempi di spazi per le ipotesi nei problemi di apprendimento supervisionato, cioÃ¨ quei problemi in cui si vuole stabilire se un elemento *x* appartiene o meno ad una classe.

###Iperpiani in R<sup>2</sup>

**Iperpiano**: dato uno spazio a *n*-dimensioni, un iperpiano per quello spazio Ã¨ un sottospazio di dimensione *n-1*. Quindi gli iperpiani in R<sup>2</sup> sono tutte le rette del piano.

Lavorando in R<sup>2</sup> lo spazio delle istanze Ã¨ definito come:

> X = {x | x âˆˆ R<sup>2</sup>}.

Mentre lo spazio delle ipotesi Ã¨ dato dalle dicotomie indotte da iperpiani in R<sup>2</sup>, cioÃ¨ da tutte le possibili divisioni del piano.

> H = {f<sub>(w,b)</sub>(x) | f<sub>(w,b)</sub>(x) = sign(w * x + b), w âˆˆ R<sup>2</sup>, b âˆˆ R}

CosÃ¬ facendo vengono prese in considerazione tutte le rette che dividono R<sup>2</sup> in due parti in modo che da una parte l'ipotesi valga 1 e dall'altra -1.

###Dischi in R<sup>2</sup>

Sempre in R<sup>2</sup> Ã¨ possibile considerare come spazio delle ipotesi tutte le dicotomie indotte da disci in R<sup>2</sup> e centrati nell'origine.

> H = {f<sub>b</sub>(x) | f<sub>b</sub>(x) = sign(||x||<sup>2</sup> - b), w âˆˆ R<sup>2</sup>, b âˆˆ R}

Il che vuol dire che all'interno del disco le ipotesi valgono -1 mentre al di fuori valgono 1.

###Congiunzione di *m* letterali positivi

Lo spazio delle istanze questa volta Ã¨ dato da tutte le stringhe di *m* bits 

> X = {s | s âˆˆ {0,1}<sup>m</sup>}

Lo spazio delle ipotesi Ã¨ dato da tutte le sentenze logiche che riguardano i letterali positivi l<sub>1</sub>,l<sub>2</sub>,...,l<sub>m</sub> (l<sub>i</sub> Ã¨ vero se l'*i*-esimo bit Ã¨ 1) e che contengono solo l'operatore â‹€.

> H = { f<sub>{i<sub>1</sub>,...,i<sub>j</sub>}</sub>(s) | f<sub>{i<sub>1</sub>,...,i<sub>j</sub>}</sub> (s) equivale a l<sub>i<sub>1</sub></sub> â‹€ l<sub>i<sub>2</sub></sub> â‹€ ... â‹€ <sub>i<sub>j</sub></sub>, {i<sub>1</sub>...i<sub>j</sub>} sottoinsieme di {1..m}}

##Misurare la complessitÃ  dello spazio delle ipotesi

Considerato un determinato spazio delle ipotesi *H*, questo contiene sempre:

- L'**ipotesi piÃ¹ specifica**: ipotesi piÃ¹ stretta, consistente con i dati, nell'esempio del disco Ã¨ il disco piÃ¹ stretto in grado di contenere tutti i punti negativi.
- L'**ipotesi piÃ¹ generale**: quella piÃ¹ grande, consistente con i dati, sempre nell'esempio del disco, Ã¨ quello del disco piÃ¹ grande possibile e che non contiene punti positivi.

**shattering**: (frammentazione), dato *S* sottoinsieme dello spazio delle istanze, si dice che *S* Ã¨ frammentato dallo spazio delle ipotesi *H* se:

> âˆ€ S' âŠ† S, âˆƒ h âˆˆ H, tale che âˆ€x in S, h(x) = 1 se e solo se x appartiene a S'.

CioÃ¨ *H* realizza tutte le possibili dicotomie di *S*.

*H* frammenta un certo insieme *S* se Ã¨ possibile trovare un iperpiano che raccoglie tutti i punti dell'insieme *S*. Ovvero per tutte le dicotomie di *S* esiste un iperpiano che riesce a realizzarle.

###VC (Vapnik-Chervonenkis) Dimension

La VC-Dimension Ã¨ la dimensione di uno spazio delle ipotesi *H* definito su uno spazio delle istanze *X* ed Ã¨ data dalla cardinalitÃ  del sottoinsieme piÃ¹ grande frammentato da *H*.

> VC(H) = max(<sub>S âŠ† X</sub>)|S| tale che H frammenta S
> 
> VC(H) = âˆ se S non Ã¨ limitato

Ad esempio nello spazio delle ipotesi dato dagli iperpiani su R<sup>2</sup>:

Se nello spazio delle istanze ho 2 punti, questo viene frammentato da *H*, perchÃ© posso sempre trovare una retta che riesce a realizzare tutte le possibili dicotomie di due punti su un piano.

Se nello spazio delle istanze ho 3 punti, riesco comunque a realizzare tutte le dicotomie.

Se nello spazio delle istanze ho 4 punti qualsiasi non si riesce a trovare un iperpiano che realizza la dicotonomia, quindi *VC(H) = 3*.

Segue che, prendendo uno spazio delle ipotesi di cardinalitÃ  finita si ha che:

> VC(H) â‰¤ log<sub>2</sub>(|H|)

Questo perchÃ© per ogni *S* frammentato da *H*, abbiamo *|H| >= 2<sup>|S|</sup>*, cioÃ¨ per ogni dicotomia in *S* esite un ipotesi in *H* che la realizza, ovvero devono essere disponibili in *H* tante ipotesi quanti sono le dicotomie in *H*.

Scegliendo un *S* tale che *|S| = VC(H)*, si ottiene *|H| >= 2<sup>VC(H)</sup>*, prendendo il logaritmo si trova quello che si stava cercando, ovvero *VC(H) <= log<sub>2</sub>(|H|)*.

**Dal libro**:

Se un dataset contiene *N* elementi, questi *N* elementi possono essere etichettati con degli 0 e 1 in *2<sup>N</sup>* modi diversi.

Se per ognuno di questi modi Ã¨ possibile trovare un ipotesi *h âˆˆ H* che separa tutte le istanze negative da quelle positive allora si dice che *H* frammenta il dataset *N*. Il che vuol dire che il dataset *N* puÃ² essere appreso con un errore empirico nullo.

Il massimo numero di punti che possono essere frammentati da *H* Ã¨ detto *VC(H)* e fornisce una misura della capacitÃ  di *H*.

##Bound sull'errore di generalizzazione

Considerando un problema di apprendimento binario, con: 

> Training set S={(x<sub>i</sub>,y<sub>i</sub>)}<sub>i=1...N</sub>
>
>Spazio delle ipotesi H={h<sub>ğœƒ</sub>(x)}

Supponendo di avere un algoritmo di apprendimento *L* che restituisce l'ipotesi _h<sub>ğœƒ\*</sub>(x)_ che minimizza l'errore empirico su *S* espresso come *errore<sub>S</sub>(h<sub>ğœƒ</sub>(x))*.

Ãˆ possibile derivare un bound (limite superiore) per l'errore ideale o errore di generalizzazione, valido con probabilitÃ  *(1 - Î´)* con *Î´* piccolo a piacere:

> errore<sub>D</sub>(h<sub>ğœƒ</sub>(x)) â‰¤ errore<sub>S</sub>(h<sub>ğœƒ</sub>(x)) + g(N, VC(H), Î´)

Il primo termine *errore<sub>S</sub>(h<sub>ğœƒ</sub>(x))* dipende dall'ipotesi restituita dall'algoritmo di apprendimento L.

Il secondo termine *g(N, VC(H), Î´)* non dipende da *L*, ma dal numero di esempi di training utilizzati (inversamente proporzionale), dalla *VC-dimension* (direttamente proporzionale) e dalla confidenza, ovvero dal termine *Î´*.

Il termine *g(N, VC(H), Î´)* viene anche chiamato **VC-confidence** e risulta essere monotono rispetto al rapporto *VC(H)/N*.

##Structural Risk Minimization (SRM)

Approccio per la scelta dello spazio delle ipotesi proposto da Vapnik che cerca di trovare un compromesso tra l'errore empirico e la VC-Confidence.

Si considerano spazi delle ipotesi sempre piÃ¹ piccoli H<sub>1</sub> âŠ† H<sub>2</sub> âŠ† ... âŠ† H<sub>n</sub> tali che VC(H<sub>1</sub>) â‰¤ VC(H<sub>2</sub>) â‰¤ ... â‰¤ VC(H<sub>n</sub>)

Si seleziona lo spazio delle ipostesi H<sub>i</sub> che ha il valore del bound sull'errore di generalizzazione piÃ¹ piccolo.

![](./immagini/l5-srm.png)