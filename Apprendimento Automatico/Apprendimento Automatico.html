<html><head><meta charset="utf-8"><link rel="stylesheet" href="../_builder/pdf.css"><link rel="stylesheet" href="../_builder/highlight/styles/default.css"><script src="../_builder/highlight/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><h1 id="apprendimento-automatico">Apprendimento automatico</h1>
<p>Non sempre √® possibile utilizzare degli algoritmi per risolvere un problema.</p>
<p>Per vari motivi:</p>
<ul>
<li>non sempre si pu√≤ formalizzare un determinato problema</li>
<li>ci sono delle situazioni di incertezza</li>
<li>risulta troppo complesso trovare una soluzione oppure sono richieste troppe risorse</li>
</ul>
<p>Alcuni esempi sono: riconoscimento facciale, filtro anti-spam.</p>
<p>In questi casi gli algoritmi (sequenza finita di passi che portano ad un risultato determinato in un tempo finito) non funzionano ed √® quindi preferibile fornire una soluzione &quot;<em>imperfetta</em>&quot;.</p>
<p>In apprendimento automatico si studiano i metodi per trasformare l&#39;informazione empirica (dati del problema) in conoscenza.</p>
<p>Questo approccio √® diventato possibile grazie al fatto che Internet ha reso disponibili molti dati.</p>
<h2 id="le-basi">Le basi</h2>
<p>Perch√© il machine leargning funzioni deve esserci un processo (stocastico o deterministico) che spiega i dati che osserviamo, in modo da riuscire a costruire un&#39;approssimazione di tale processo che pu√≤ anche risultare imperfetta dal momento che il processo che si vuole approssimare non √® noto.</p>
<p><em>Stocastico</em>: random a probabilit√†</p>
<p>L&#39;obiettivo finale del machine learning √® quello di definire dei criteri da ottimizzare in modo che sia possibile andare a migliorare dei modelli definiti su certi parametri.</p>
<p>Questi modelli possono essere:</p>
<ul>
<li><strong>Preditivi</strong>: per fare previsioni sul futuro (es: filtro anti-spam)</li>
<li><strong>Descrittivi</strong>: utilizzare dei dati per ottenere maggiori informazioni (data mining)</li>
</ul>
<p>Esempi applicativi:</p>
<ul>
<li>Software OCR</li>
<li>Estrapolazione di dati a partire dal linguaggio naturale</li>
<li>Riconoscimento facciale</li>
<li>Giochi con informazione incompleta (Gaist? gioco con fantasmi rosso/blu, tedesco)</li>
</ul>
<h2 id="problemi-tipici-dell-apprendimento-automatico">Problemi tipici dell&#39;apprendimento automatico</h2>
<ul>
<li><strong>Classificazione binaria</strong>: dato un input dire se appartiene ad una determinata classe o meno. Esempio: data una cifre dire se √® uno 0 o meno.</li>
<li><strong>Classificazione multiclasse</strong>: dato un input lo assegno ad una determianta categoria. Es: identificare una cifra manoscritta.</li>
<li><strong>Regressione</strong>: dato un insieme di valori, trovare una funzione che li approssimi.</li>
<li><strong>Ranking di classi</strong> (non sar√† affrontato): data una serie di dati, dire quali sono pi√π rilevanti, ovvero, data una serie di documenti ordinarli nel modo migliore secondo una determinata preferenza, es: motore di ricerca.</li>
<li><strong>Novelty detection</strong>: riconoscimento delle irregolarit√† a partire da una serie di dati. es: frode bancaria su una serie di transazioni, controllo degli accessi, ecc.</li>
<li><strong>Clustering</strong>: raggruppamento di dati in modo gerarchico, basandosi su alcune caratteristiche che li accomunano o meno.</li>
<li><strong>Associazioni</strong>: quello che fa Amazon con &quot;altri utenti hanno comprato&quot;</li>
<li><strong>Reinforcement Learning</strong>: valutazioni di strategie, quando si ha una serie di stati e possibili azioni, si vuole valutare la qualit√† complessiva, es: movimenti di un robot.</li>
</ul>
<h1 id="lezione-2-ripasso-di-probabilit-">Lezione 2 - Ripasso di probabilit√†</h1>
<p>(Kaggle)[<a href="https://www.kaggle.com/">https://www.kaggle.com/</a>], sito che offre sfide con problemi di machine learing sponsorizzati da grandi compagnie.</p>
<p><strong>Proposta di un progetto di gruppo (opzionale):</strong> affrontare uno dei problemi proposti da Kraggle per ottenere un bonus sul voto finale.</p>
<h2 id="problemi-tipici-in-modo-matematico">Problemi tipici in modo matematico</h2>
<p>_Notazione: </p>
<ul>
<li>√ò --&gt; teta, insieme di parametri che rappresenta l&#39;apprendimento (lo so √® il simbolo dell&#39;insieme vuoto, ma √® semplice da fare)</li>
<li>X --&gt; insieme di dati su cui applicare l&#39;algoritmo</li>
<li>Y --&gt; enumeratore (etichette)_</li>
</ul>
<ul>
<li>Classificazione binaria: h(√ò): <code>X --&gt; {-1,+1}</code> (<em>h di teta</em>, funzione che mappa un dato valore in -1 o +1 (oppure 0 o 1) la funzione <em>h</em> √® sempre parametrica, in qunato i parametri rappresentano l&#39;apprendimento (<em>teta</em> √ò));</li>
<li>Classificazione multiclasse: <code>h(√ò): X --&gt; Y</code> con Y che prende come valori un enumeratore o un intervallo di numeri 1..k;</li>
<li>Regressione: <code>h(√ò): X --&gt; Reale</code></li>
<li>Ranking di istanze e classi: <code>h(√ò): XxY --&gt; Reale</code> dati elementi del prodotto cartesiano tra X (esempio) e Y (etichetta) associa un punteggio espresso da un numero reale. Una funzione che valuta la coppia (x,y) con <em>x</em> valore e <em>y</em> classificazione.</li>
<li>Novelty detection: <code>h(√ò): X --&gt; [0,1]</code> funzione che dato un&#39;esempio mi calcola il fattore di rischio come numero reale da 0 a 1.</li>
<li>Clustering: <code>h(√ò): X --&gt; {1,..,k}</code> funzione che ad un esempio associa una valutazione.</li>
<li>Associazioni (Basket Analysis): <code>P(Y|X)</code>.</li>
</ul>
<h2 id="ripasso-di-probabilit-e-statistica">Ripasso di probabilit√† e statistica</h2>
<p><em>Evento</em>: qualcosa che pu√≤ essere o vero o falso.</p>
<p>La probabilit√† che si verifichi un&#39;evento √® un numero compreso tra 0 e 1, <code>0 &lt;= P(E) &lt;= 1</code>. Questo numero pu√≤ essere calcolato usando la frequenza con la quale si verifica l&#39;evento.</p>
<p>Dato un insieme di eventi E_i mutuamente esclusivi tra loro. La probabilit√† dell&#39;unione di tutti gli eventi √® la somma delle probabilit√† dei singoli eventi.</p>
<p>La probabilit√† che si verifichi un evento o il suo complementare √® 1. (sempre se gli eventi sono mutuamente esclusivi).</p>
<p>La probabilit√† dell&#39;unione di due eventi non esclusivi √® data dalla probabilit√† che si verifichi uno o l&#39;altro, meno la probabilit√† che si verifichino entrambi contemporaneamente.</p>
<p><code>P(E unito F) = P(E)+P(F)+P(E intersecato F)</code></p>
<p><strong>Probabilit√† condizionale</strong>: probabilit√† che l&#39;evento E accada sapendo che si √® verificato l&#39;evento F <code>P(E|F)</code>.</p>
<p>L&#39;evento E √® indipendente da F se <code>P(E|F) = P(E)</code>.</p>
<p><code>P(E intersecato F) = P(E|F)*P(F) = P(F|E)*P(E)</code></p>
<p><strong>Formula di Bayes</strong></p>
<p><code>P(F|E) = [P(E|F)P(F)] / P(E)</code></p>
<p>Deriva dalla probabilit√† condizionata, sar√† utile nella classificazioni di tipo <em>bayesiano</em> (non sono sicuro che sia scritto giusto).</p>
<p>Dato un insieme di eventi F_i, tra loro esclusivi ed esasutivi (gli Fi coprono tutti i possibili esiti, la propabilit√† dell&#39;unione di tutti gli F_i √® 1).
Allora <code>E = unione su i (E intersecato F_i)</code>, la probabilit√† di E √® quindi uguale alla sommatoria della probabilit√† di tutte le intersezioni.</p>
<p>Il tutto per arrivare a:</p>
<p><code>P(F_i | E) = [P(E | F_i)P(F_i)] / sommatoria su j ( P(E|F_j)P(F_j))</code></p>
<p><strong>Valore atteso</strong>: detto anche media, con X e Y variabili aleatorie.</p>
<p><code>E[X] = sommatoria su i (x_i * P(x_i))</code></p>
<p><code>E[aX + b] = aE[X] + b</code></p>
<p><code>E[X + Y] = E[X] + E[Y]</code></p>
<p><code>E[g(X)] = sommatoria su i (g(x_i) * P(x_i))</code></p>
<p><code>E[X^n] = sommatoria su i ((x_i)^n * P(x_i))</code> detto anche n-esimo momento </p>
<p><strong>Varianza</strong>: quanto varia il valore ottenuto attorno alla media dei vari esperimenti.</p>
<p><code>sigma^2 = VAR(X) = E[ (X-mu)^2 ]</code> dove <code>mu</code> √® il valore atteso. <code>= E[X^2] - mu^2</code>.</p>
<p><strong>Deviazione standard</strong>: o scarto quadratico medio, √® la radice quadrata della varianza, ed √® la media di quando ci si discosta dal valore attesso.</p>
<h1 id="lezione-3-ripasso-di-probabilit-e-algebra-supervised-learning">Lezione 3 - Ripasso di probabilit√† e algebra + Supervised Learning</h1>
<h2 id="variabili-aleatorie">Variabili aleatorie</h2>
<h3 id="bernoulli">Bernoulli</h3>
<p>Esito di un esperimento che pu√≤ essere positivo o negativo.</p>
<pre><code><span class="hljs-function"><span class="hljs-title">P</span><span class="hljs-params">(X = i)</span></span> = <span class="hljs-tag">p</span>   se i=<span class="hljs-number">1</span> 
           <span class="hljs-number">1</span>-<span class="hljs-tag">p</span> se i=<span class="hljs-number">0</span>
</code></pre><h3 id="binomiale">Binomiale</h3>
<p>La probabilat√† di avere <em>i</em> successi su <em>N</em> esperimenti √® uguale a </p>
<blockquote>
<p>P(X=i) = (N su i)p<sup>i</sup>(1-p)<sup>N-i</sup></p>
</blockquote>
<p>Il valore atteso di questa variabile √® dato da <code>N*p</code> mentre la varianza √® <code>N*p*(1-p)</code>.</p>
<h3 id="distribuzione-uniforme">Distribuzione uniforme</h3>
<p>Assume che in un intervallo <code>[a,b]</code> tutti i punti hanno la stessa probabilit√†.</p>
<blockquote>
<p>P(X = x) = 1 / (b-a) con <code>a &lt;= x &lt;= b</code></p>
<p>P(X = x) = 0 altrimenti</p>
</blockquote>
<p>Il valore atteso di X (<code>E[X]</code>) √® uguale a <code>(a+b)/2</code></p>
<h3 id="distribuzione-normale-gaussaina-">Distribuzione normale (Gaussaina)</h3>
<p>La distribuzione si concentra in un certo valore medio <code>mu</code> ed ha la forma <em>a campana</em>.</p>
<blockquote>
<p>N(mu, sigma<sup>2</sup>)</p>
<p>P(x) = [1 / sigma(‚àö2Pi)]*e<sup>(x-mu)^2 / 2sigma^2</sup></p>
</blockquote>
<p>&lt;!-- https://it.wikipedia.org/wiki/Distribuzione_normale --&gt;
</p>
<h2 id="algebra-lineare">Algebra lineare</h2>
<blockquote>
<p>M ‚Ç¨ R<sup>m x d</sup></p>
</blockquote>
<p>Somma di due matrici: le matrici A e B devono avere la stessa dimensione, e la matrice somma ha come elementi la somma degli elementi delle matrici.</p>
<blockquote>
<p>C = [A + B]<sub>i,j</sub> = [a]<sub>i,j</sub> + [b]<sub>i,j</sub></p>
</blockquote>
<p>Per fare il prodotto di due matrici √® necessario che siano di dimensioni compatibili.</p>
<blockquote>
<p>A ‚Ç¨ R<sup>m x d</sup>
B ‚Ç¨ R<sup>d x k</sup>
L&#39;emento (i,j) della matrice C = A * B √® uguale alla somma del prodotto riga i-esima di a e colonna j-esima di B</p>
</blockquote>
<p>La matrice trasposta di una matriche √® la stessa matrice &quot;<em>ribaltata</em>&quot; sulla diagonale.</p>
<blockquote>
<p>(AB)<sup>T</sup> = B<sup>T</sup>A<sup>T</sup></p>
</blockquote>
<p>Un vettore √® una matrice di una sola colonna. </p>
<p>Il prodotto scalare tra due vettori √® la sommatoria del prodotti dei vari elementi del prodotto.</p>
<p>Due vettori si dicono ortogonali quando il loro prodotto scalare √® 0.</p>
<p>Due vettori si dicono correlati se il loro prodotto scalare √® maggiore di 0, in caso contrario si dicono scorrelati.</p>
<p>La lunghezza di un vettore (norma2, distanza eculidea) √® definita come la radice quadrata della sommatoria dei vari elementi del vettore, eleveati al quadrato.</p>
<p>Allo stesso modo il quadrato della lunghezza √® la sommatoria dei quadrati degli elementi del vettore.</p>
<p>Il prodotto scalare tra due vettori √® anche uguale al prodotto delle lunghezza dei due vettori, moltiplicato anche per il coseno dell&#39;angolo tra i due vettori.</p>
<p>La distanza tra due vettori √® la norma della differenza tra i due vettori.</p>
<p>Matrice inversa e determinante.</p>
<p>Utilizzando le matrici √® possibile risolvere i sistemi lineari.</p>
<p>Una matrice pseudo inversa √® un qualcosa di simile ad una matrice inversa per le matrici rettangolari.</p>
<blockquote>
<p>A<sup>+</sup> = A<sup>T</sup>(AA<sup>T</sup>)<sup>-1</sup></p>
</blockquote>
<h3 id="autovalori-e-autovettori">Autovalori e autovettori</h3>
<blockquote>
<p>A <em> e = lambda </em> e
A matrice
e vettore</p>
</blockquote>
<p><code>e</code> √® un autovettore della matrice A e <code>lambda</code> √® il corrispondente autovalore.</p>
<p><strong>Traccia</strong>: la traccia di una matrice √® la somma degli elementi nella diagonale.</p>
<p>Una matrice si dice <strong>simmetrica</strong> se tutti gli autovalori sono maggiori di 0.</p>
<h2 id="supervised-learning">Supervised Learning</h2>
<p>Si vuole tradurre un insieme di dati in ingresso <em>X</em> in un insieme di dati di uscita <em>Y</em>.</p>
<p>Anche in questo caso c&#39;√® un <em>oracolo</em> che funziona in modo stocastico e che sceglie un oggetto <em>x</em> in <em>X</em> secondo una certa probabilit√† <em>P(x)</em> e sceglie <em>y</em> in <em>Y</em> in base a <em>P(y|x)</em>.</p>
<p>L&#39;obiettivo che si vuole raggiungere √® quello di approssimare queste probabilit√†.</p>
<p>Cosa importante, questo oracolo non sempre √® una funzione, questo perch√© pu√≤ capitare che ad uno stesso <em>x</em> corrispondano <em>y</em> diversi.</p>
<h3 id="operativamente">Operativamente</h3>
<p>Si dispone di una serie di coppie <em>(x,y)</em> che seguono lo schema naturale, l&#39;insieme di queste coppie prende il nome di <strong>training set</strong>.</p>
<p>Viene quindi scelta un funzione <em>h</em> che prende il nome di <strong>ipotesi</strong>, definita nello spazio delle ipotesi <em>H</em> tale che, da valori presenti nell&#39;insieme <em>X</em>, restituisca dei valori nell&#39;insieme <em>Y</em>.</p>
<p>L&#39;apprendimento consiste quindi nell&#39;andare a scegliere l&#39;<em>h</em> migliore in modo che approssimi bene i dati presenti nel training set e che riesca a generalizzare e predirre i corretti valori <em>y</em> anche per valori di <em>x</em> non presenti nel training set.</p>
<p>Da ci√≤ segue che possono essere commessi due tipi di errori:</p>
<ul>
<li><strong>Errore empirico</strong>: √® l&#39;errore commesso da <em>h</em> in media, all&#39;interno del training set. In altre parole √® l&#39;errore medio dell&#39;ipotesi sul training set.</li>
<li><strong>Errore ideale</strong>: √® l&#39;errore commesso da <em>h</em> su una qualsiasi coppia <em>(x,y) ~ P(x,y)</em>, come media su un&#39;insieme infinito di coppie. Questo errore pu√≤ essere solamente stimato.</li>
</ul>
<p>Per calcolare una stima dell&#39;errore ideale si pu√≤ usare un <strong>test set</strong>, cio√® un altro insieme di coppie <em>(x,y)</em> che non compaiono nel training set. Questa discriminazione √® importante perch√© se cos√¨ non fosse l&#39;errore ideale sarebbe influenzato dall&#39;errore empirico.</p>
<p><em>Riassumendo: l&#39;errore empirico √® quello che si fa sui dati che si conoscono, l&#39;errore ideale √® quello che si fa su dei dati nuovi.</em></p>
<p>Dal momento che lo spazio delle ipotesi non pu√≤ coincidere con tutte le funzioni calcolabili √®  necessario fare delle assunzioni sulla funzione oracolo, queste assunzioni prendono il nome di <strong>bias induttivo</strong> e derivano da delle conscenze a priori che abbiamo sul dominio e che vengono utilizzate per fare delle previsioni induttive sui dati.</p>
<p>Fanno parte del bias induttivo:</p>
<ul>
<li>Come vengono rappresentati gli esempi;</li>
<li>Come viene modellato lo spazio delle ipotesi <em>H</em>;</li>
<li>La funzione obiettivo per la ricerca nello spazio <em>H</em>, cio√® come viene scelta la funzione <em>h</em>.</li>
</ul>
<h4 id="es-regressione-polinomiale">Es: regressione polinomiale</h4>
<blockquote>
<p>TRAIN = {(x<sub>1</sub>,y<sub>1</sub>),...,(x<sub>n</sub>,y<sub>n</sub>)}</p>
</blockquote>
<p>Si vuole trovare una funzione polinomiale in grado di approssimare i punti.</p>
<p>In questo caso il bias induttivo √® assumere che esista una funzione polinomiale in grado di approssimare i vari punti.</p>
<p>Lo spazio delle ipotesi diventa quindi l&#39;insieme dei vari polinomi e l&#39;apprendimento viene fatto sui vari coefficenti.</p>
<p>Dobbiamo quindi scegliere tra questo spazio un grado <em>p</em> che va a limitare i possibili polinomi (definzione di <em>H</em>) e i vari parametri della curva (ricerca nello spazio <em>H</em>).</p>
<h1 id="lezione-4-laboratorio">Lezione 4 - Laboratorio</h1>
<p>Durante il corso useremo Python 2.7.x</p>
<p>Python √® un linguaggio orientato agli oggetti.</p>
<p>Ogni oggetto √® caratterizzato da:</p>
<ul>
<li>identit√†: √® un identificativo dell&#39;oggetto (!= puntatore).</li>
<li>tipo: rappresenta le operazioni che si possono fare con un oggetto, python √® un linguaggio a tipizzazione dinamica e il tipo viene determinato a runtime.</li>
<li>valore: rappresenta il valore effettivo contenuto nell&#39;oggetto.</li>
</ul>
<p>In python non c&#39;√® il concetto classico di variabile, ma vengono usati dei riferimenti.</p>
<pre><code class="lang-python">x = <span class="hljs-number">2</span>
y = <span class="hljs-number">3</span>
y = x <span class="hljs-comment">//y e x puntano allo stesso oggetto</span>
</code></pre>
<p>La funzione <code>id()</code> permette di sapere l&#39;identificatore di un oggetto.</p>
<p>Gli oggetti in Python sono immutabili.</p>
<p>Contenitori:</p>
<ul>
<li>liste</li>
<li>set (insiemi)</li>
<li>tuple</li>
<li>dizionari</li>
</ul>
<p>Tutti questi contenitori possono essere eterogenei, una lista pu√≤ tenere sia numeri che stringhe contemporaneamente.</p>
<p>Le liste in python sono mutabili.</p>
<p>Un contenitore si dice iterabile se gli elementi possono essere iterati.</p>
<p>Un contenitore si dice sequenziale se √® definita una sequenza di elementi e pu√≤ essere acceduto mediante indice (liste e tuple).</p>
<p>Un contenitere si dice associativo quando si comporta come un dizionario, quindi solo i dizionari.  </p>
<p>In python non esitono i caratteri, esistono solo stringhe di lunghezza uno.</p>
<p>Gli indici per accedere ad una collezione con le <code>[]</code> possono anche essere negativi, in questo caso si procede all&#39;indietro.</p>
<pre><code class="lang-python"><span class="hljs-prompt">&gt;&gt;</span>&gt; s = <span class="hljs-string">"Giacomo"</span>
<span class="hljs-prompt">&gt;&gt;</span>&gt; s[<span class="hljs-number">3</span>]
<span class="hljs-string">'c'</span>
<span class="hljs-prompt">&gt;&gt;</span>&gt; s[-<span class="hljs-number">3</span>]
<span class="hljs-string">'o'</span>
<span class="hljs-prompt">&gt;&gt;</span>&gt; s[<span class="hljs-number">1</span><span class="hljs-symbol">:-</span><span class="hljs-number">3</span>] <span class="hljs-comment">#slicing</span>
<span class="hljs-string">'iac'</span>
</code></pre>
<p><strong>List comprehension</strong></p>
<pre><code class="lang-python">&gt;&gt;&gt; [x**<span class="hljs-number">2</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-function"><span class="hljs-title">range</span><span class="hljs-params">(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>)</span></span>]
[<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">9</span>, <span class="hljs-number">16</span>, <span class="hljs-number">25</span>, <span class="hljs-number">36</span>, <span class="hljs-number">49</span>, <span class="hljs-number">64</span>, <span class="hljs-number">81</span>]
</code></pre>
<p><strong>operatore in</strong></p>
<pre><code class="lang-python"><span class="hljs-keyword">if</span> k <span class="hljs-keyword">in</span> dictiornary:
    <span class="hljs-comment"># something</span>
</code></pre>
<p><strong>copy()</strong></p>
<pre><code class="lang-python"><span class="hljs-operator">a</span> = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]
b = <span class="hljs-operator">a</span>            <span class="hljs-comment"># b riferisce a </span>
c = <span class="hljs-operator">a</span>.copy()    <span class="hljs-comment"># c √® una copia di a (oggetto diverso)</span>
</code></pre>
<h2 id="numpy">numpy</h2>
<pre><code class="lang-python">&gt;&gt;&gt; import numpy as np

&gt;&gt;&gt; a = np.<span class="hljs-built_in">array</span>([<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">8</span>], <span class="hljs-keyword">float</span>)
&gt;&gt;&gt; <span class="hljs-function">a
<span class="hljs-title">array</span><span class="hljs-params">([ <span class="hljs-number">1.</span>,  <span class="hljs-number">4.</span>,  <span class="hljs-number">5.</span>,  <span class="hljs-number">8.</span>])</span></span>
</code></pre>
<p>Questo modulo contiene alcuni metodi utili per la creazioni di matrici o array.</p>
<p><code>a</code> matrice</p>
<ul>
<li><code>a.transpose()</code></li>
<li><code>a + b</code>, <code>a - b</code>, <code>a * b</code>, <code>b / a</code> sono tutte operazioni tra matrici <em>entry wise</em>, cio√® elemento per elemento </li>
</ul>
<h2 id="scipy">scipy</h2>
<pre><code class="lang-python"><span class="hljs-preprocessor"><span class="hljs-keyword">import</span> scipy</span>
</code></pre>
<p>Libreria per la risolzione dei sistemi.</p>
<p>Anche questa ha un suo tipo per le matrici che √® diverso da quello di <code>numpy</code>.</p>
<p>Tra tipi <code>matrix</code> di <code>scipy</code> l&#39;operazione <code>\*</code> effettua il prodotto tra matrici.</p>
<h1 id="lezione-5-vc-dimension-e-vc-confidence">Lezione 5 VC-Dimension e VC-Confidence</h1>
<h2 id="esempi-di-spazi-delle-ipotesi">Esempi di spazi delle ipotesi</h2>
<p>Seguono alcuni esempi di spazi per le ipotesi nei problemi di apprendimento supervisionato, cio√® quei problemi in cui si vuole stabilire se un elemento <em>x</em> appartiene o meno ad una classe.</p>
<h3 id="iperpiani-in-r-sup-2-sup-">Iperpiani in R<sup>2</sup></h3>
<p><strong>Iperpiano</strong>: dato uno spazio a <em>n</em>-dimensioni, un iperpiano per quello spazio √® un sottospazio di dimensione <em>n-1</em>. Quindi gli iperpiani in R<sup>2</sup> sono tutte le rette del piano.</p>
<p>Lavorando in R<sup>2</sup> lo spazio delle istanze √® definito come:</p>
<blockquote>
<p>X = {x | x ‚àà R<sup>2</sup>}.</p>
</blockquote>
<p>Mentre lo spazio delle ipotesi √® dato dalle dicotomie indotte da iperpiani in R<sup>2</sup>, cio√® da tutte le possibili divisioni del piano.</p>
<blockquote>
<p>H = {f<sub>(w,b)</sub>(x) | f<sub>(w,b)</sub>(x) = sign(w * x + b), w ‚àà R<sup>2</sup>, b ‚àà R}</p>
</blockquote>
<p>Cos√¨ facendo vengono prese in considerazione tutte le rette che dividono R<sup>2</sup> in due parti in modo che da una parte l&#39;ipotesi valga 1 e dall&#39;altra -1.</p>
<h3 id="dischi-in-r-sup-2-sup-">Dischi in R<sup>2</sup></h3>
<p>Sempre in R<sup>2</sup> √® possibile considerare come spazio delle ipotesi tutte le dicotomie indotte da disci in R<sup>2</sup> e centrati nell&#39;origine.</p>
<blockquote>
<p>H = {f<sub>b</sub>(x) | f<sub>b</sub>(x) = sign(||x||<sup>2</sup> - b), w ‚àà R<sup>2</sup>, b ‚àà R}</p>
</blockquote>
<p>Il che vuol dire che all&#39;interno del disco le ipotesi valgono -1 mentre al di fuori valgono 1.</p>
<h3 id="congiunzione-di-m-letterali-positivi">Congiunzione di <em>m</em> letterali positivi</h3>
<p>Lo spazio delle istanze questa volta √® dato da tutte le stringhe di <em>m</em> bits </p>
<blockquote>
<p>X = {s | s ‚àà {0,1}<sup>m</sup>}</p>
</blockquote>
<p>Lo spazio delle ipotesi √® dato da tutte le sentenze logiche che riguardano i letterali positivi l<sub>1</sub>,l<sub>2</sub>,...,l<sub>m</sub> (l<sub>i</sub> √® vero se l&#39;<em>i</em>-esimo bit √® 1) e che contengono solo l&#39;operatore ‚ãÄ.</p>
<blockquote>
<p>H = { f<sub>{i<sub>1</sub>,...,i<sub>j</sub>}</sub>(s) | f<sub>{i<sub>1</sub>,...,i<sub>j</sub>}</sub> (s) equivale a l<sub>i<sub>1</sub></sub> ‚ãÄ l<sub>i<sub>2</sub></sub> ‚ãÄ ... ‚ãÄ <sub>i<sub>j</sub></sub>, {i<sub>1</sub>...i<sub>j</sub>} sottoinsieme di {1..m}}</p>
</blockquote>
<h2 id="misurare-la-complessit-dello-spazio-delle-ipotesi">Misurare la complessit√† dello spazio delle ipotesi</h2>
<p>Considerato un determinato spazio delle ipotesi <em>H</em>, questo contiene sempre:</p>
<ul>
<li>L&#39;<strong>ipotesi pi√π specifica</strong>: ipotesi pi√π stretta, consistente con i dati, nell&#39;esempio del disco √® il disco pi√π stretto in grado di contenere tutti i punti negativi.</li>
<li>L&#39;<strong>ipotesi pi√π generale</strong>: quella pi√π grande, consistente con i dati, sempre nell&#39;esempio del disco, √® quello del disco pi√π grande possibile e che non contiene punti positivi.</li>
</ul>
<p><strong>shattering</strong>: (frammentazione), dato <em>S</em> sottoinsieme dello spazio delle istanze, si dice che <em>S</em> √® frammentato dallo spazio delle ipotesi <em>H</em> se:</p>
<blockquote>
<p>‚àÄ S&#39; ‚äÜ S, ‚àÉ h ‚àà H, tale che ‚àÄx in S, h(x) = 1 se e solo se x appartiene a S&#39;.</p>
</blockquote>
<p>Cio√® <em>H</em> realizza tutte le possibili dicotomie di <em>S</em>.</p>
<p><em>H</em> frammenta un certo insieme <em>S</em> se √® possibile trovare un iperpiano che raccoglie tutti i punti dell&#39;insieme <em>S</em>. Ovvero per tutte le dicotomie di <em>S</em> esiste un iperpiano che riesce a realizzarle.</p>
<h3 id="vc-vapnik-chervonenkis-dimension">VC (Vapnik-Chervonenkis) Dimension</h3>
<p>La VC-Dimension √® la dimensione di uno spazio delle ipotesi <em>H</em> definito su uno spazio delle istanze <em>X</em> ed √® data dalla cardinalit√† del sottoinsieme pi√π grande frammentato da <em>H</em>.</p>
<blockquote>
<p>VC(H) = max(<sub>S ‚äÜ X</sub>)|S| tale che H frammenta S</p>
<p>VC(H) = ‚àû se S non √® limitato</p>
</blockquote>
<p>Ad esempio nello spazio delle ipotesi dato dagli iperpiani su R<sup>2</sup>:</p>
<p>Se nello spazio delle istanze ho 2 punti, questo viene frammentato da <em>H</em>, perch√© posso sempre trovare una retta che riesce a realizzare tutte le possibili dicotomie di due punti su un piano.</p>
<p>Se nello spazio delle istanze ho 3 punti, riesco comunque a realizzare tutte le dicotomie.</p>
<p>Se nello spazio delle istanze ho 4 punti qualsiasi non si riesce a trovare un iperpiano che realizza la dicotonomia, quindi <em>VC(H) = 3</em>.</p>
<p>Segue che, prendendo uno spazio delle ipotesi di cardinalit√† finita si ha che:</p>
<blockquote>
<p>VC(H) ‚â§ log<sub>2</sub>(|H|)</p>
</blockquote>
<p>Questo perch√© per ogni <em>S</em> frammentato da <em>H</em>, abbiamo <em>|H| &gt;= 2<sup>|S|</sup></em>, cio√® per ogni dicotomia in <em>S</em> esite un ipotesi in <em>H</em> che la realizza, ovvero devono essere disponibili in <em>H</em> tante ipotesi quanti sono le dicotomie in <em>H</em>.</p>
<p>Scegliendo un <em>S</em> tale che <em>|S| = VC(H)</em>, si ottiene <em>|H| &gt;= 2<sup>VC(H)</sup></em>, prendendo il logaritmo si trova quello che si stava cercando, ovvero <em>VC(H) &lt;= log<sub>2</sub>(|H|)</em>.</p>
<p><strong>Dal libro</strong>:</p>
<p>Se un dataset contiene <em>N</em> elementi, questi <em>N</em> elementi possono essere etichettati con degli 0 e 1 in <em>2<sup>N</sup></em> modi diversi.</p>
<p>Se per ognuno di questi modi √® possibile trovare un ipotesi <em>h ‚àà H</em> che separa tutte le istanze negative da quelle positive allora si dice che <em>H</em> frammenta il dataset <em>N</em>. Il che vuol dire che il dataset <em>N</em> pu√≤ essere appreso con un errore empirico nullo.</p>
<p>Il massimo numero di punti che possono essere frammentati da <em>H</em> √® detto <em>VC(H)</em> e fornisce una misura della capacit√† di <em>H</em>.</p>
<h2 id="bound-sull-errore-di-generalizzazione">Bound sull&#39;errore di generalizzazione</h2>
<p>Considerando un problema di apprendimento binario, con: </p>
<blockquote>
<p>Training set S={(x<sub>i</sub>,y<sub>i</sub>)}<sub>i=1...N</sub></p>
<p>Spazio delle ipotesi H={h<sub>ùúÉ</sub>(x)}</p>
</blockquote>
<p>Supponendo di avere un algoritmo di apprendimento <em>L</em> che restituisce l&#39;ipotesi <em>h<sub>ùúÉ*</sub>(x)</em> che minimizza l&#39;errore empirico su <em>S</em> espresso come <em>errore<sub>S</sub>(h<sub>ùúÉ</sub>(x))</em>.</p>
<p>√à possibile derivare un bound (limite superiore) per l&#39;errore ideale o errore di generalizzazione, valido con probabilit√† <em>(1 - Œ¥)</em> con <em>Œ¥</em> piccolo a piacere:</p>
<blockquote>
<p>errore<sub>D</sub>(h<sub>ùúÉ</sub>(x)) ‚â§ errore<sub>S</sub>(h<sub>ùúÉ</sub>(x)) + g(N, VC(H), Œ¥)</p>
</blockquote>
<p>Il primo termine <em>errore<sub>S</sub>(h<sub>ùúÉ</sub>(x))</em> dipende dall&#39;ipotesi restituita dall&#39;algoritmo di apprendimento L.</p>
<p>Il secondo termine <em>g(N, VC(H), Œ¥)</em> non dipende da <em>L</em>, ma dal numero di esempi di training utilizzati (inversamente proporzionale), dalla <em>VC-dimension</em> (direttamente proporzionale) e dalla confidenza, ovvero dal termine <em>Œ¥</em>.</p>
<p>Il termine <em>g(N, VC(H), Œ¥)</em> viene anche chiamato <strong>VC-confidence</strong> e risulta essere monotono rispetto al rapporto <em>VC(H)/N</em>.</p>
<h2 id="structural-risk-minimization-srm-">Structural Risk Minimization (SRM)</h2>
<p>Approccio per la scelta dello spazio delle ipotesi proposto da Vapnik che cerca di trovare un compromesso tra l&#39;errore empirico e la VC-Confidence.</p>
<p>Si considerano spazi delle ipotesi sempre pi√π piccoli H<sub>1</sub> ‚äÜ H<sub>2</sub> ‚äÜ ... ‚äÜ H<sub>n</sub> tali che VC(H<sub>1</sub>) ‚â§ VC(H<sub>2</sub>) ‚â§ ... ‚â§ VC(H<sub>n</sub>)</p>
<p>Si seleziona lo spazio delle ipostesi H<sub>i</sub> che ha il valore del bound sull&#39;errore di generalizzazione pi√π piccolo.</p>
<p><img src="./notes/immagini/l5-srm.png" alt=""></p>
<h1 id="lezione-6-apprendimento-di-concetti">Lezione 6 - Apprendimento di concetti</h1>
<h2 id="il-concetto-di-concetto">Il concetto di Concetto</h2>
<p>In uno spazio delle istanze <em>X</em>, un <strong>concetto</strong> √® una funzione booleana su <em>X</em>, cio√® una funzione che prende in input un oggetto dello spazio <em>X</em> e ritorna un booleano che specifica se l&#39;elemento appartiene a quel concetto o meno.</p>
<p>Un concetto <em>C</em> su uno spazio delle istanze <em>X</em> viene definito come una coppia <em>(x,C(x))</em> con <em>x ‚àà X</em>, e <em>C(x)</em> √® la funzione concetto applicata ad <em>x</em>.</p>
<p>Si dice che un ipotesi booleana <em>h</em> per lo spazio delle istanze <em>X</em> <strong>soddisfa</strong> <em>x ‚àà X</em> se <em>h(x) == 1</em>.</p>
<p>La stessa ipotesi <em>h</em> si dice che √® <strong>consistente</strong> con un esempio <em>(x,C(x))</em> se <em>h(x) == C(x)</em>.</p>
<p>La definizione di consistenza pu√≤ essere poi estesa ad in insieme se l&#39;ipotesi <em>h</em> √® consistente con tutti gli elementi presenti nell&#39;insieme.</p>
<h2 id="ordine-parziale">Ordine parziale</h2>
<p>Siano <em>h<sub>i</sub></em> e <em>h<sub>j</sub></em> due funzioni booleane definite su uno spazio delle istanze <em>X</em>, diciamo che <em>h<sub>i</sub></em> √® <strong>pi√π generale</strong> o equivalente di <em>h<sub>j</sub></em> (<em>h<sub>i</sub> &gt;=<sub>g</sub> h<sub>j</sub></em>) se:</p>
<blockquote>
<p>‚àÄx ‚àà X | h<sub>j</sub>(x) == 1 --&gt; h<sub>i</sub>(x) == 1</p>
</blockquote>
<p>Cio√® tutti gli esempi che sono soddisfatti dall&#39;ipotesi pi√π specifica sono sempre soddisfatti anche dall&#39;ipotesi pi√π generale.</p>
<p>Pu√≤ essere che due ipotesi possono non essere comparabili tra loro.</p>
<h2 id="find-s">Find-S</h2>
<p>Algoritmo che permette di trovare tra tutte le ipotesi, quella pi√π specifica e consistente con l&#39;insieme di apprendimento.</p>
<p>Si parte da un training set <em>Tr</em> e si inizializza <em>h</em> con l&#39;ipotesi pi√π specifica di tutte.</p>
<p>Per ogni istanza positiva <em>x</em> del training set, cio√® per tutti gli esempi che appartengono al concetto, si modifica <em>h</em> in modo che riesca a soddisfare l&#39;esempio <em>x</em>.</p>
<p>Una volta terminate le istanze presenti nel training set viene ritornata <em>h</em>.</p>
<p>L&#39;algoritmo parte dall&#39;ipotesi pi√π specifica possibile e man mano che procede nell&#39;analisi del training set la generalizzarla, in modo da trovare la prima ipotesi consistente con il training set che sia il pi√π specifica possibile.</p>
<p>L&#39;ipotesi pi√π specifica di tutte √® quella che rifiuta tutti i valori, poi per ogni istanza del training set positiva, questa viene generalizzata il meno possibile in modo che venga soddisfatta l&#39;istanza che si sta esaminando.</p>
<p>Bisogna notare che l&#39;ipotesi pi√π specifica non √® sempre la migliore, inoltre per funzionare bene il training set dovrebbe essere molto grande.</p>
<h2 id="candidate-elimination">Candidate Elimination</h2>
<p><strong>Version space</strong>: sottoinsieme dello spazio <em>H</em> contenete solo ipotesi che sono consistenti con gli esempi del training set.
Per essere contenuta nel version space, un&#39;ipotesi deve essere pi√π generale o equivalente a quella ottenuta con Find-S.</p>
<p>Dal momento che Find-S ritorna solamente un ipotesi e non √® detto che quella ritornata sia l&#39;ipotesi migliore per il training set √® stato proposto l&#39;algoritmo Candidate Elimination che ritorna tutte le ipotesi contenute nel version space.</p>
<p><strong>Confine pi√π specifico</strong>: <em>S</em>, insieme delle ipotesi <em>s</em> in <em>H</em>, consistenti con il traingin set e tali che non esistano altre ipotesi consistenti e pi√π specifiche.</p>
<p><strong>Confine pi√π generale</strong>: <em>G</em>, insieme delle ipotesi <em>g</em> in <em>H</em>, consistenti nel training set e tali che non esistano altre ipotesi pi√π generali che siano consistenti con il trainging set.</p>
<p>Il version space √® quindi contenuto tra i due confini, cio√® contiene tutte quelle ipotesi pi√π generali di quelle contenute in <em>S</em> e meno generali di quelle contenute in <em>G</em>, <em>S</em> e <em>G</em> inclusi.</p>
<h3 id="algoritmo">Algoritmo</h3>
<p>Si inizializzano gli insiemi <em>G</em> e <em>S</em> in modo che conengano rispettivamente le ipotesi pi√π generali e pi√π specifiche.</p>
<pre><code class="lang-python"><span class="hljs-keyword">foreach</span> <span class="hljs-keyword">d</span> == (x,c(x)) <span class="hljs-keyword">in</span> Tr <span class="hljs-keyword">do</span>
    <span class="hljs-keyword">if</span> c(x) = 1:
        rimuovi da <span class="hljs-keyword">G</span> ogni ipotesi inconsistente con <span class="hljs-literal">d</span>
        per ogni ipotesi s <span class="hljs-keyword">in</span> S <span class="hljs-keyword">e</span> inconsistente con <span class="hljs-literal">d</span>
            rimuovi s da S.
            aggiungi ad S tutte le generalizzazioni minime <span class="hljs-keyword">h</span> <span class="hljs-keyword">di</span> s tali che sono consistenti con <span class="hljs-keyword">d</span> <span class="hljs-keyword">ed</span> esiste un altra ipotesi <span class="hljs-keyword">g</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">G</span> pi√π generale <span class="hljs-keyword">di</span> <span class="hljs-keyword">h</span>.
            rimuovi da S tutte le ipotesi s' che sono pi√π generali <span class="hljs-keyword">di</span> altre ipotesi <span class="hljs-keyword">in</span> S.
    <span class="hljs-keyword">if</span> c(x) == 0:
        rimuovi da S tutte le ipotesi inconsistenti con <span class="hljs-literal">d</span>
        per ogni ipotesi <span class="hljs-keyword">g</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">G</span> inconsistente con <span class="hljs-literal">d</span>
            rimuovi <span class="hljs-keyword">g</span> da <span class="hljs-keyword">G</span>
            aggiungi a <span class="hljs-keyword">G</span> tutte le specificazioni (?) minime <span class="hljs-keyword">h</span> <span class="hljs-keyword">di</span> <span class="hljs-keyword">g</span> tali che siano consistenti con <span class="hljs-keyword">d</span> <span class="hljs-keyword">e</span> che esiste un'altra ipotesi s <span class="hljs-keyword">in</span> S pi√π specifica <span class="hljs-keyword">di</span> <span class="hljs-keyword">h</span>.
            rimuovi da <span class="hljs-keyword">G</span> tutte le ipotesi <span class="hljs-keyword">g</span>' che sono pi√π specifiche <span class="hljs-keyword">di</span> altre ipotesi <span class="hljs-keyword">in</span> <span class="hljs-keyword">G</span>.
</code></pre>
<p>Quando viene trovato un esempio <em>d</em> nel training set che soddisfa il concetto che si cerca di apprendere:</p>
<ul>
<li>Vengono rimosse da <em>G</em> e da <em>S</em> tutte le ipotesi che sono inconsistenti con <em>d</em>, questo perch√© il version space deve contenere solo ipotesi consistenti con il traingin set.</li>
<li>Per ogni ipotesi <em>s</em> rimossa da <em>S</em> viengono aggiunte tutte le generalizzazioni minime di <em>s</em> che sono in grado di soddisfare <em>d</em>, questo per andare a definire delle nuove ipotesi specifiche e consistenti con il Tr.</li>
<li>Vengono poi rimosse tutte le ipotesi <em>s&#39;</em> da <em>S</em> che sono pi√π generali di altre ipotesi presenti in <em>S</em>, cos√¨ facendo <em>S</em> conterr√† sempre e solo le ipotesi pi√π specifiche.</li>
</ul>
<p>Se <em>d</em> non soddisfa il concetto viene applicato lo stesso scambiando i due insiemi.</p>
<h1 id="lezione-7-alberi-di-decisione">Lezione 7 - Alberi di decisione</h1>
<p>In molte situazioni del mondo reale non √® sufficiente apprendere funzioni booleane con ingressi binari (quello che si fa con il concept learning).</p>
<p>Gli alberi di decisione funzionano bene con:</p>
<ul>
<li>Istanze rappresentate da coppie attributo-valore</li>
<li>Funzioni target con valori di output discreti (pi√π di due valori), come il riconoscimento della categoria di una pagina web</li>
<li>Concetti descritti da disgiunzioni di funzioni booleane</li>
<li>Esempi di apprendimento che possono contenere errori e/o valori mancanti (es: diagnosi medica senza alcuni esami).</li>
</ul>
<p>Gli algoritmi che lavorano su alberi di decisione sono molto efficenti ed √® per questo che vengono utilizzati in applicazioni pratiche.</p>
<h2 id="-il-giorno-giusto-per-giocare-a-tennis-">√à il giorno giusto per giocare a tennis?</h2>
<p>Dati:</p>
<p><img src="./notes/immagini/l7-tabella.png" alt=""></p>
<p>Albero:</p>
<p><img src="./notes/immagini/l7-albero.png" alt=""></p>
<p>Come si pu√≤ notare, nell&#39;albero ogni nodo corrisponde ad un attributo e l&#39;arco tra un nodo e l&#39;altro corrisponde uno dei possibili valori, mentre le foglie dell&#39;albero forniscono una classificazione.</p>
<p>Per classificare un&#39;istanza si parte dalla radice e si scende verso le foglie, secondo quanto specificato dai test sugli attributi definiti dai nodi dell&#39;albero.</p>
<p>Se si raggiunge una foglia l&#39;etichetta ad essa associata rappresenta la classificazione.</p>
<p>Dato un albero di decisione, questo corrisponde ad una <strong>disgiunzione di congiunzioni</strong>.</p>
<p>Lo stesso albero pu√≤ essere infatti rappresentato come:</p>
<pre><code>(Outlook = Sunny <span class="hljs-built_in">and</span> <span class="hljs-built_in">Humidity</span> = Normal) 
            <span class="hljs-built_in">or</span> 
    (Outlook = <span class="hljs-built_in">Overcast</span>)
            <span class="hljs-built_in">or</span>
(Outlook = <span class="hljs-built_in">Rain</span> <span class="hljs-built_in">and</span> <span class="hljs-built_in">Wind</span> = Weak)
</code></pre><h2 id="id3-apprendimento-su-un-albero">ID3 - Apprendimento su un albero</h2>
<p>L&#39;algoritmo di apprendimento che costruisce l&#39;albero di decisione trammite una procedura top down in stile divide et impera.</p>
<p>Questo algoritmo apprende l&#39;albero di dicesione costruendolo con un approccio top-down. La costruzione inizia con la domanda &quot;<em>Quale attributo dovrebbe essere testato alla radice dell&#39;albero?</em>&quot;. 
Per scegliere l&#39;attributo vengono valutati tutti i possibili candidati utilizzando un test statistico per valutare quando bene il singolo attributo classifica il training set.</p>
<p>Viene selezionato il miglior attributo e utilizzato come test alla radice dell&#39;albero. Vengono poi creati tanti figli quanti sono i possibili valori dell&#39;attributo e gli esempi del training set vengono partizionati tra i vari figli, in modo che il loro valore per quell&#39;attributo corrisponda con il valore del nodo.</p>
<p>Questo processo vienei ripetuto per ognuno dei nodi creati fino a che non vengono esaminati tutti gli esempi.</p>
<p>Pi√π formalmente, dato un training set <em>Tr</em> e un insieme di attributi <em>A</em>, algoritmo √® definito come:</p>
<ol>
<li>Crea il nodo radice e copia in <em>T</em> gli esempi di <em>Tr</em> e inserisce tutti gli attributi in <em>A</em>.</li>
<li>Se gli esempi in <em>T</em> sono tutti delle stessa classe, ritorna l&#39;albero con un solo nodo e etichetta uguale alla classe.</li>
<li>Se <em>A</em> √® vuoto, ritorna l&#39;lalbero con un solo nodo e come etichetta la classe di maggioranza in <em>T</em>.</li>
<li>Altrimenti, si sceglie l&#39;attributo <em>a</em> tra gli attributi presenti in <em>A</em> (il migliore) e si partiziona <em>T</em> secondo i possibili valori che l&#39;attributo <em>a</em> pu√≤ assumere: <em>T<sub>a = val<sub>1</sub></sub>, ... ,  T<sub>a = val<sub>n</sub></sub></em><ol>
<li>Per ogni <em>T<sub>a = val<sub>i</sub></sub></em>, se √® vuoto crea una foglia con l&#39;etichetta della classe pi√π frequente, altrimenti crea un sottoalbero con l&#39;algoritmo ID3 con <em>T<sub>a = val<sub>i</sub></sub></em> e <em>A - {</em>a<em>}</em>.</li>
</ol>
</li>
<li>Ritorna <em>T</em>.</li>
</ol>
<p>Quando una partizione risulta vuota, vuol dire che non esistono esempi nel training set per i quali il valore dell&#39;attributo selezionato √® uguale a quel dato valore.</p>
<h3 id="esempio-sui-dati-del-tennis">Esempio sui dati del tennis</h3>
<pre><code>T = {D1, ..., D14}
A = {Outlook, Temperature, <span class="hljs-built_in">Humidity</span>, <span class="hljs-built_in">Wind</span>}

a = Outlook

                   (Outlook)
               /       |       \
            sunny    <span class="hljs-built_in">overcast</span>   <span class="hljs-built_in">rain</span>
            /          |          \
(T_Overlook = Sunny
A = Temp, Hum, <span class="hljs-built_in">Wind</span>})
</code></pre><p>Al secondo passo mi ritrovo scelgo <code>a = Humidity</code>, ottenendo:</p>
<pre><code>                   (Outlook)
               /       |       <span class="hljs-string">\</span>
            sunny    overcast   rain
            /          |          <span class="hljs-string">\</span>
       (Humidity)
       /        <span class="hljs-string">\</span>
    High        Normal
    /               <span class="hljs-string">\</span>
   No               Si
</code></pre><p>In questo caso i figli vengono marcati con un valore quando si √® nel caso in cui tutti gli esempi della partizione hanno lo stesso valore target.</p>
<p>Si prosegue finch√© l&#39;albero non √® completo</p>
<h3 id="alla-ricerca-dell-attributo-ottimo">Alla ricerca dell&#39;attributo ottimo</h3>
<p>Nell&#39;esempio precedente √® stato scelto un attributo a caso, ma nel caso pratico questo non conviene.</p>
<p>Come viene scelto l&#39;ottimo dipende da algoritmo ad algoritmo, nel caso di ID3 vengono utilizzati i concetti di <em>entropia</em> e <em>guadagno entropico</em>.</p>
<blockquote>
<p>E(S) = -p<sub>-</sub>log<sub>2</sub>(p<sub>-</sub>) -p<sub>+</sub>log<sub>2</sub>(p<sub>+</sub>)</p>
</blockquote>
<p>Dove p<sub>-</sub> e p<sub>+</sub> rappresentano la proporzione degli esempi della di una classe e dell&#39;altra (si assume che ci siano solo due classi) all&#39;interno dell&#39;insieme S.</p>
<p>L&#39;entropia misura il grado di purezza degll&#39;insieme degli esempi.</p>
<p>Nel caso ci siano pi√π valori l&#39;entropia si calcola come</p>
<blockquote>
<p>- ‚àë<sub>v</sub> (p<sub>v</sub>log<sub>2</sub>(p<sub>v</sub>))</p>
</blockquote>
<p>ID3 sceglie come attributo <em>a</em>, quello che massimizza il guadagno entropico.</p>
<blockquote>
<p>G(S,<em>a</em>) = E(S) - ‚àë<sub>v œµ V(a)</sub> (E(S<sub>a = v</sub>) |S<sub>a=v</sub>| / |S|)</p>
</blockquote>
<p>Il guadagno misura la riduzione aspettata dell&#39;entropia nel partizionare i dati utilizzando <em>a</em>.</p>
<p>L&#39;entropia attesa √® descritta dal secondo termine ed √® semplicemente la sommatoria delle entropie di tutti i sottoinsiemi di <em>S</em>, pesata secondo il numero di esempi che appartengono al sottoinsieme di <em>S</em>.</p>
<p><strong>Problema</strong>: L&#39;utilizzo del guadagno entropico favorisce troppo gli attributi che possono assumere tanti valori diversi, ad esempio l&#39;attributo <em>Data</em>.
Seguendo l&#39;esempio della data, segliere quell&#39;attributo porta ad ottenere tante partizioni, ognuna di pochi elementi e che non forniscono informazioni utili.</p>
<blockquote>
<p>GainRatio(S, a) = G(S, a) / SI(S,a)</p>
</blockquote>
<p>Dove <em>SI</em> rappresenta la <em>split information</em>, un valore che misura quanti e quanto uniformi sono i sottoinsiemi generati dall&#39;attributo <em>a</em> a partire dall&#39;insieme <em>S</em>.</p>
<blockquote>
<p>SI(S,a) = - ‚àë<sub>v œµ V(a)</sub>( log<sub>2</sub>(|S<sub>a = v</sub>| / |S|) |S<sub>a = v</sub>| / |S| )</p>
</blockquote>
<p>E corrispone all&#39;entropia di <em>S</em> dati i possibili valori di <em>a</em>.</p>
<p><em>GainRatio</em> non risolve tutti i problemi, infatti pu√≤ succedere che attributi significativi e che possono assumere tanti valori, vengano svantaggiati rispetto al altri.</p>
<p>Un&#39;altra idea pu√≤ essere quella di calcolare il <em>Guadagno</em> per ogni attributo e fare la media dei valori trovati, per poi andare a scegliere, tra gli attributi con <em>Guadagno</em> sopra la media, l&#39;attributo che ha <em>GainRatio</em> maggiore.</p>
<h1 id="lezione-8-alberi-di-decisione-2">Lezione 8 - Alberi di decisione 2</h1>
<h2 id="dove-il-bias-induttivo-degli-alberi-di-decisione-">Dove&#39;√® il bias induttivo degli alberi di decisione?</h2>
<p>Con <strong>candidate elimination</strong> c&#39;era l&#39;incompletezza delle ipotesi ma la ricerca all&#39;interno dello spazio √® esaustiva, mentre negli alberi di decisione, c&#39;√® la completezza per quanto riguarda lo spazio delle ipotesi ma la ricerca non √® completa in quanto vengono effettuate scelte greedy.</p>
<p>Un altro bias induttivo √® che tutti gli attributi che producono un guadagno entropico alto si trovano vicino alla radice.</p>
<h2 id="casi-speciali">Casi speciali</h2>
<h3 id="attributi-continui">Attributi continui</h3>
<p>Uno o pi√π attributi hanno dei valori continui, escluso il target che rimane binario o con un numero discreto di possibili valori.</p>
<p>La soluzione √® quella di trasformare dinamicamente un attributo continuo <em>A</em> nell&#39;attributo booleano <em>A<sub>c</sub></em> in modo che sia true se il valore di <em>A</em> √® minore di una certa soglia <em>c</em>.</p>
<p>Il tutto sta ne scegliere la soglia <em>c</em> migliore cio√® che corrispone al massimo guadagno entropico.</p>
<p>Si √® dimostrato che il valore ottimo di soglia si localizza nel valore di mezzo tra due valori a cui corrisponde un target diverso.</p>
<p>Da notare che con ID3 un attributo pu√≤ essere utilizzato soltanto una volta, in questo caso per√≤ √® possibile riutilizzare l&#39;attributo con un <em>c</em> diverso. </p>
<h3 id="attributi-con-costi">Attributi con costi</h3>
<p>In alcune situazioni andare a verificare il valore assunto da un attributo potrebbe avere un costo.</p>
<p>Pu√≤ essere preferibile quindi testare prima gli attributi meno costosi, serve quindi un criterio per la selezione degll&#39;attributo ottimo che tiene conto dei costi.</p>
<p>Alcuni criteri sono:</p>
<blockquote>
<p><strong>Diagnosi medica</strong> (2<sup>Guadagno(S,A)</sup>-1)/(Costo(A)+1)<sup><em>w</em></sup> con <em>w</em> tra 0 e 1 (pi√π vicino a 1 √® <em>w</em> pi√π peso si da al costo)</p>
<p><strong>Percezione robotica</strong>: (Guadagno<sup>2</sup>(S,A))/Costo(A)</p>
</blockquote>
<h3 id="attributi-con-valori-mancanti">Attributi con valori mancanti</h3>
<p>In alcuni casi si vuole classificare qualcosa che non ha tutti i dati per gli attributi.</p>
<p>Questi casi possono essere trattati in vari modi diversi:</p>
<ul>
<li>Utilizzare per <em>A</em> il valore pi√π comune nell&#39;insieme d&#39;esempi associato al nodo interno.</li>
<li>Come prima, solo che vengono considerati solamente esempi con target uguale a quello dell&#39;esempio corrente (ovviamente devo sapere il valore del target dell&#39;esempio corrente).</li>
<li>Considerare tutti i valori <em>a<sub>i</sub></em> che pu√≤ assumere l&#39;attributo e la loro probabilit√† di occorrenza nell&#39;insieme degli esempi associati al nodo interno e andare sostituire l&#39;esempio corrente <em>(x,target)</em> con delle istanze frazionarie per ogni possibile valore di <em>A</em>, ognuna con un peso pari alla probabilit√†. Quando devo scoprire il target di un&#39;esempio &quot;provo&quot; con tutti i possibili valori, e poi faccio la media pesata dei valori ottenuti, rispondo come target la classe pi√π probabile.</li>
</ul>
<h2 id="overfitting">Overfitting</h2>
<p>Cio√® l&#39;ipotesi √® molto accurata sui valori di training, ma sui valori di test risulta meno accurata.</p>
<p>All&#39;aumentare della complessit√† dell&#39;albero creato, l&#39;accuratezza dell&#39;abero sui dati di trainging aumenta, ma una volta provata con i dati di test, l&#39;accuratezza cala drastricamente.</p>
<pre><code><span class="hljs-operator">in</span> fact <span class="hljs-keyword">it</span> can lead <span class="hljs-built_in">to</span> difficulties when there is noise <span class="hljs-operator">in</span> <span class="hljs-operator">the</span> data,
 <span class="hljs-operator">or</span> when <span class="hljs-operator">the</span> <span class="hljs-built_in">number</span> <span class="hljs-operator">of</span> training examples is too small <span class="hljs-built_in">to</span> produce <span class="hljs-operator">a</span> 
 representative sample <span class="hljs-operator">of</span> <span class="hljs-operator">the</span> <span class="hljs-constant">true</span> target <span class="hljs-function"><span class="hljs-keyword">function</span></span>
</code></pre><p>Si √® osservato che fino ad un certo livello di complessit√† l&#39;accuratezza in training √® molto simile all&#39;accuratezza in test, √® quindi importante <strong>potare</strong> gli albteri complessi.</p>
<p>Ci sono per√≤ due problemi:</p>
<ol>
<li>Come si effettua la potatura?</li>
<li>Quando fermarsi con la potatura o con l&#39;apprendimento?</li>
</ol>
<p>Per quanto riugarda il problema (2) ci sono varie soluzioni:</p>
<ul>
<li>Valutare le prestazioni sull&#39;insieme di apprendimento usando un test statistico;</li>
<li>Valutare le prestazioni su un&#39;insieme separato di validazione;</li>
<li>Usare un principio di <strong>minimizzazione della lunghezza di descrizione (MDL)</strong>: <em>min_Tree[size(tree) - size(errori(tree))].</em></li>
</ul>
<h3 id="come-potare">Come potare</h3>
<h4 id="reduce-error-pruning">Reduce error pruning</h4>
<p>Effettuare il pruning di un nodo consiste nel rimuovere il sotto albero che ha origine in quel nodo, trasformando il nodo potato in una foglia e assegnandogli come valore la classificazione pi√π comune tra gli esempi di training associati a quel nodo.</p>
<p>I nodi vengono rimossi solamente se le prestazione dell&#39;albero potato non peggiorano rispetto la versione originale, confrontate sul validation set.</p>
<ul>
<li>Dividere il training set in due sottinsiemi, uno per fare training e l&#39;altro per fare validazione.</li>
<li>Ripetere fino a quando le prestazioni peggiorano:<ul>
<li>Per ogni nodo interno <em>n</em> valutare l&#39;impatto del nodo sul sottoinsieme di valutazione avendo potato il nodo</li>
<li>Effettuare la potatura che porta alle prestazioni migliori sull&#39;insieme di valutazione.</li>
</ul>
</li>
</ul>
<p>Al sottoalbero radicato in <em>n</em> si sotistuisce la foglia con etichetta uguale alla classe pi√π frequente nell&#39;insieme degli esempi associati al nodo <em>n</em>.</p>
<h4 id="rule-post-pruning">Rule-Post pruning</h4>
<ul>
<li>Si genera una regola <em>R<sub>i</sub></em> per ogni cammino <em>path(r, f<sub>i</sub>)</em> dalla radice <em>r</em> alla foglia <em>i</em>-esima <em>f<sub>i</sub></em>.</li>
<li>Si effettua la potatura indipendentemente su ogni regola <em>R<sub>i</sub></em>:<ul>
<li>Si stimano le prestazioni utilizzando solo <em>R<sub>i</sub></em> come classificatore</li>
<li>Si rimuovo le precondizioni (una o pi√π) che conducono ad un aumento della stima delle prestazioni utilizzando un approccio greedy.</li>
</ul>
</li>
<li>Si ordinano le <em>R<sub>i</sub></em> potate per ordine crescente di prestazione (evitando i conflitti)</li>
<li>Eventualmente si aggiunge come classicazione di default la classe pi√π frequente</li>
</ul>
<p><em>R<sub>i</sub></em> √® del tipo:</p>
<blockquote>
<p>IF (Attr<sub>i<sub>1</sub></sub> = v<sub>i<sub>1</sub></sub>) ‚ãÄ ... ‚ãÄ (Attr<sub>i<sub>k</sub></sub> = v<sub>i<sub>k</sub></sub>) THEN label<sub>f<sub>i</sub></sub></p>
</blockquote>
<p>La classificazione di una nuova istanza a partire da parte delle regole ordinate avviene seguendo l&#39;ordine stabilito per le regole:</p>
<ul>
<li>La prima regola la cui precondizione √® soddisfatta dalla istanza √® usata per generare la classificazione</li>
<li>Se nessuna regola ha le condizioni soddisfatte, si utilizza la regola di default per la classificazione, cio√® si ritorna la classi pi√π frequente nell&#39;insieme di apprendimento.</li>
</ul>
<h1 id="lezione-9-reti-neurali">Lezione 9 - Reti neurali</h1>
<p>Due approcci principali per studiarle:</p>
<ol>
<li>Riprodurre il cervello umano, cercando di modellarne la struttura in modo affidabile.</li>
<li>Estrarre i principi fondamentali di calcolo utilizzati dal cervello replicandone solamente il comportamento, concentrandosi sui principi di calcolo che il cervello utilizza al fne di ripordurre un sistema artificiale in grado di replicarli.</li>
</ol>
<p>Durante il corso ci concentreremo sul secondo approccio applicato al contesto dell&#39;apprendimento supervisionato.</p>
<h2 id="quando-usarle-">Quando usarle?</h2>
<p>Quando si hanno tanti input numerici e discreti e si vuole effettuare una classificazione o regressione.</p>
<p>I dati di input possono anche contenere del rumore e la forma della funzione target √® totalmente sconosciuta.</p>
<p>Il risultato finale non deve essere compreso da un esperto umano, il funzionamento della rete √® una black-box.</p>
<p>Tipicamente vengono utilizzate quando non ci sono conoscenze a priori nel dominio.</p>
<h2 id="reti-neurali-artificiali">Reti neurali artificiali</h2>
<p><img src="./notes/immagini/l9-rete.png" alt=""></p>
<p>Il cervello umano √® sostituito da circa 10<sup>10</sup> neuroni fortemente interconnessi tra loro (da 10<sup>4</sup> a 10<sup>5</sup> connessioni), il tempo di risposta di un neurone √® di circa 0.001 secondi.</p>
<p>Considerando che per riconoscere il contenuto di una scena un unmano impiega circa 0.1 secondi, ne segue che il cervello umano sfrutta pesantemente il calcolo parallelo: infatti, in questo caso, non pul effettuare pi√π di 100 calcoli seriali.</p>
<p>Questo funzionamento va in contrasto con quello attuale dei nostri processori, i quali ottenogno ottime prestazioni nelle operazioni seriali ma sono in difficolt√† con il calcolo parallelo.</p>
<p>Una rete neurale artificiale √® un sistema costituito da unit√† interconnesse che calcolano funzioni numeriche, ci sono vari tipi di unit√†:</p>
<ul>
<li>le unit√† di input che rappresentano le variabili di ingresso;</li>
<li>le unit√† di output che rappresentano le variabili di uscita;</li>
<li>le unit√† nascoste che rappresentano le variabili interne che codificano (dopo l&#39;apprendimento) le correlazioni tra le variabili di input relativamente al valore di output che si vuole generare.</li>
</ul>
<p>Sulle connessioni tra le varie unit√† sono definiti dei pesi che vengono definiti dall&#39;algoritmo di apprendimeno.</p>
<p>Ci sono due modi per replicare un neurone:</p>
<ul>
<li>Hard-threshold</li>
<li>Sigmoidale</li>
</ul>
<h3 id="hard-threshold-iperpiano">Hard-threshold - iperpiano</h3>
<p><img src="./notes/immagini/l9-threshold.png" alt=""></p>
<p>L&#39;idea √® quella di avere un vettore di input che rappresenta i nodi di ingresso da ognuno dei quali  arriva un segnale x<sub>i</sub>. A ogni segnale √® associato un peso w<sub>i</sub> che lo amplifica, tutti questi pesi vengono definiti dall&#39;algoritmo di apprendimento.</p>
<p>Il neurone √® poi composto da altri due elementi: il primo che effettua una sommatoria, detta <strong>net</strong> di tutti i segnali d&#39;ingresso moltiplicati per il loro peso, mentre il secondo utilizza il risultato del primo e calcola una funzione gradino, il cui output √® 1 o -1 in base al segno di net.</p>
<p>Alcune precisazioni:</p>
<ul>
<li>Nella sommatoria iniziale gli ingressi vengono rappresentati da x<sub>1</sub> a x<sub>n</sub>, ognuno moltiplicato per il proprio peso. Tuttavia √® presente anche un ingresso x<sub>0</sub> sempre fisso a 1, al quale viene associato il peso w<sub>0</sub>, questa componente rappresenta il bais induttivo.</li>
<li>Possono essere usate altre funzioni gradino oltre a quella del segno.</li>
</ul>
<p>Si pu√≤ dimostrare che questo tipo di neurone definisce un iperpiano.
Questo perch√© la somamtoria a partire da <em>i=1</em> pu√≤ essere vista come un <em>w<sup>T</sup>x +w<sub>0</sub></em> ed concide con la definizione di iperpiano.</p>
<h3 id="sigmoidale">Sigmoidale</h3>
<p><img src="./notes/immagini/l9-sigmoidale.png" alt=""></p>
<p>Utilizza la stessa sommatoria <em>net</em> alla quale viene applicata la funzione œÉ.</p>
<blockquote>
<p>œÉ(z) = 1 / (1 + e<sup>-z</sup>)</p>
</blockquote>
<p>La funzione √® continua e compresa tra 0 e 1.</p>
<p>Il vantaggio fondamentale di œÉ √® che si tratta di una funzione derivabile e quindi permette di utilizzare l&#39;algoritmo di <strong>back propagation</strong>. Un algoritmo che permette di fare apprendimento all&#39;indietro in grado di funzionare anche su reti composte da pi√π livelli.</p>
<p>Un&#39;altra caratteristica interessante di questa funzione √® che la sua derivata pu√≤ essere espressa come una funzione dei valori di input. 
Cio√®:</p>
<blockquote>
<p>‚àÇœÉ / ‚àÇz = œÉ(z)(1-œÉ(z))</p>
</blockquote>
<p>Questa propriet√† torner√† utile quando sar√† applicato l&#39;algortimo di back propagation.</p>
<p>Infine, il neurone sigmoidale pu√≤ utilizza altre funzioni al posto di <em>1 / (1 + e<sup>-z</sup>)</em>, come la tangente iperbolica.</p>
<h2 id="perceptron">Perceptron</h2>
<p>√à una rete neurale composta da un singolo neurone con Hard Threshold che viene utilizzata per rappresentare un iperpiano.</p>
<p>L&#39;algoritmo di apprendimento per questa rete cerca dei valori per i vari pesi <em>w<sub>i</sub></em> in modo da apprendere la funzione target.
Per apprendere i coefficenti corretti vengono utilizzati gli esempi del training set.</p>
<h3 id="implementazione-di-funzioni-booleane">Implementazione di funzioni booleane</h3>
<p>Ad esempio Percepton pu√≤ implementare l&#39;operatore <em>or</em> con gli ingressi <em>y ‚àà {0,1}<sup>n+1</sup></em> (vettori rappresentanti stringhe binarie), si possono usare come pesi <em>w&#39;<sub>0</sub> = -0.5</em> e <em>w&#39;<sub>i</sub> = 1</em> per <em>i=1..n</em>.</p>
<p>In modo simile pu√≤ essere implementato anche l&#39;operatore <em>and</em> con <em>w&#39;<sub>0</sub> = -n+0.5</em> e <em>w&#39;<sub>i</sub> = 1</em> per <em>i = 1..n</em>.</p>
<p>Si pu√≤ anche realizzare l&#39;operatore <em>not</em> con una singola connessione e con un unico peso negativo.</p>
<p>Un problema che il perceptron non riesce a risolvere √® la <em>xor</em>, questo perch√© si tratta di una funzione non linearmente separabili.</p>
<h3 id="apprendimento-di-funzioni-linearmente-separabili">Apprendimento di funzioni linearmente separabili</h3>
<p>Si pu√≤ far apprendere a Perceptron tutte le funzioni linearmente separabili con un algoritmo che √® garantito che termini.</p>
<p>Tuttavia se la funzione da apprendere non √® linearmente separabile l&#39;algoritmo non converge.</p>
<p>Dato un insieme di apprendimento <em>Tr = {(x<sup>-</sup>,t)</em>, dove <em>t ‚àà {-1,+1}}</em>.</p>
<ol>
<li>Inizializza il vettore dei pesi <em>w</em> al vettore nullo (con tutte le componenti a 0, possono anche essere random ma piccole)</li>
<li>Ripeti finch√© non si raggiunge un punto fisso:<ol>
<li>Seleziona a caso uno delgi esempi di apprendimento <em>(x,t)</em></li>
<li>se <em>out = sign(w * x) ‚â† t</em> allora <em>w = w + (t-out)x</em></li>
</ol>
</li>
</ol>
<p>Cio√® per ogni esempio nel training set va a controllare il segno del prodotto scalare tra <em>x</em> e i pesi, se questo non coincide con il valore di training √® necessario adattare <em>w</em> in modo che anche per <em>x</em> venga calcolato il valore corretto.</p>
<p>In questo modo si riesce ad apprendere una funzione che per costruzione non commette nessun errore nel training set.</p>
<p>Piccola precisazione, <em>x</em> e <em>w</em> sono dei vettori.</p>
<h1 id="lezione-10-reti-neurali-2">Lezione 10 - Reti neurali 2</h1>
<p>Perceptron va bene ma non riesce ad apprendere la XOR perch√© non √® linearmente separabile.</p>
<h2 id="reti-di-perceptron">Reti di Perceptron</h2>
<p>L&#39;idea √® quindi quella di combinare pi√π Perceptron tra loro, in modo che riescano ad apprendere una qualsiasi funzione boolena.</p>
<p>Il problema ora diventa come effettuare l&#39;apprendimento con una rete di Perceptron, dal momento che non √® pi√π triviale come assegnare dei pesi alle unit√† nascoste. 
Una possibile soluzione √® quella di rendere il singolo neurone derivabile e sfruttare la tecnica di Discesa del Gradiente per apprendere i pesi &quot;giusti&quot;.</p>
<h3 id="discesa-di-gradiente">Discesa di gradiente</h3>
<p><strong>Richiami di analisi</strong>: il segno della derivata di una funzione determina se la funzione √® crescente o decrescente. Inoltre se la derviata vale 0, la funzione in quel punto ha un minimo o un massimo locale.</p>
<p>Si pu√≤ quindi seguire il segno della derivata prima di una funzione per  raggiungere un massimo o minimo locale.</p>
<p><img src="./notes/immagini/l10-threshold.png" alt=""></p>
<p>La funzione obiettivo da minimizzare √® la <strong>funzione errore</strong>, la quale rappresenta lo scarto quadratico medio del valore target predetto dal neurone (<em>funzione out</em>).</p>
<p>Dal momento che si tratta di una funzione derivabile √® possibile utilizzare la discessa di gradiente per raggiungere un minimo.</p>
<p><img src="./notes/immagini/l10-step.png" alt=""></p>
<p>Il valore <em>-Œ∑</em> √® lo step con il quale mi sposto e prende il nome di <strong>learn rate</strong>.</p>
<p>Per calcolare lo spostamento rispetto ad ogni <em>w<sub>i</sub></em> per minimizzare la funzione obiettivo, vado a calcolare la derivata.
Una volta calcolati tutti i <em>Œîw<sub>i</sub></em> posso andare a sommarli tra loro e successivamente aggiornare il vettore <em>w</em>.</p>
<p>La seguente serie di calcoli mostra come √® possibile calcolare i <em>Œîw<sub>i</sub></em> per tutti gli esempi presenti nel training set. 
Viene usato <em>out<sup>(d)</sup></em> per indicare il valore calcolato dalla rete per il <em>d</em>-esimo esempio del training set e <em>t<sup>(d)</sup></em> per indicare il corretto valore della funzione target per lo stesso esempio.</p>
<p>In questo caso viene sempre considerata una rete di perceptron senza hard-treshold e senza sigmoide.</p>
<p><img src="./notes/immagini/l10-step-passaggi.png" alt=""></p>
<h4 id="algoritmo-di-apprendimento">Algoritmo di apprendimento</h4>
<p><em>Œîw<sub>i</sub></em> rappresenta lo spostamento dal <em>w<sub>i</sub></em> iniziale.</p>
<p><img src="./notes/immagini/l10-algoritmo-gradiente.png" alt=""></p>
<p>In pratica prima viene esaminato tutti il training set per aggiornare i vari <em>Œîw<sub>i</sub></em>, una volta finito di esaminare il training set si aggiornano i <em>w<sub>i</sub></em> e si ripete fino a che non si verifica una  condizione di stop.</p>
<p>Possono essere utilizzate varie condizioni di stop:</p>
<ul>
<li><em>E(w)</em> minore di una soglia prefissata</li>
<li><em>Œîw<sub>i</sub> = 0 ‚àÄi</em></li>
<li>Il numero di iterazioni ha superato una soglia prefissata. </li>
</ul>
<h3 id="discesa-di-gradiente-con-sigmoide">Discesa di gradiente con sigmoide</h3>
<p><img src="./notes/immagini/l10-sigmoidale.png" alt=""></p>
<p>In questo caso si pu√≤ utilizzare lo stesso algoritmo di apprendimento visto in precedenza, cambia per√≤ come vengono aggiornati i <em>Œîw<sub>i</sub></em>, dal momento che bisona tenere in considerazione la derivata della funzione sigmoidale.</p>
<p><img src="./notes/immagini/l10-derivata-sigmoide.png" alt=""></p>
<p>Nonostate la formula sembri molto minacciosa, i <em>Œîw<sub>i</sub></em> sono uguali a <em>-Œ∑‚àÇE / ‚àÇw<sub>i</sub></em>, cio√® il learn rate moltiplicato per la derivata appena calcolata.</p>
<h2 id="rete-di-perceptron">Rete di Perceptron</h2>
<p><img src="./notes/immagini/l10-rete.png" alt=""></p>
<p><img src="./notes/immagini/l10-rete-parametri.png" alt=""></p>
<p>E rappresenta l&#39;errore quadratico medio di tutte le unit√† di output.</p>
<h3 id="calcolo-dei-pesi-per-le-unit-di-output">Calcolo dei pesi per le unit√† di output</h3>
<p>Calcoliamo i pesi per le unit√† di output, considerando i livelli nascosti come se fossero degli ingressi.</p>
<p>I <em>w<sub>i</sub></em> adesso diventano <em>Œîw<sub>k,j</sub></em> perch√© i pesi vengono calcolati per ogni collegamento da un&#39;unit√† nascosta <em>j</em> all&#39;unit√† di output <em>k</em>.</p>
<p><img src="./notes/immagini/l10-rete-output.png" alt=""></p>
<p>Nel secondo passo sono state fatte due operazioni, prima viene tolta la sommatoria, perch√© quando viene fatta la derivata della sommatoria c&#39;√® un solo elemento diverso da ed √® quello di indice <em>k^=k</em>.</p>
<h3 id="calcolo-dei-pesi-per-le-unit-nascoste">Calcolo dei pesi per le unit√† nascoste</h3>
<p><img src="./notes/immagini/l10-rete-input.png" alt=""></p>
<h3 id="algoritmo-di-apprendimento">Algoritmo di apprendimento</h3>
<p>L&#39;algoritmo di apprendimento lavora in due fasi: nella prima fase, detta <strong>feed forward</strong>, viene forinto in input alla rete un esempio del training set, in modo che questa possa provare a calcolare la funzione target per l&#39;esempio. Una volta calcolata si passa alla fase di <strong>backward progragation</strong>, nella quale si aggiornarno i coefficenti delle unit√† di output e delle unit√† nascoste in base alla correttezza o meno della predizione. In questo caso l&#39;apprendimento avviene a ritroso, prima vengono aggiornati i coefficenti delle unit√† di output e poi quelli dei livelli nascosti.</p>
<p><img src="./notes/immagini/l10-apprendimento-rete.png" alt=""></p>
<p>Il passo 2 dell&#39;algoritmo rappresenta il calcolo della differenza tra l&#39;output atteso e quello ottenuto, questo viene poi utilizzato per aggiornare a ritroso i valori dei nodi interni (passo 3).</p>
<p>L&#39;algoritmo prende il nome di <strong>back propagation stocastico</strong> perch√© il valore dei <em>Œîw<sub>i</sub></em> viene aggiornato subito dopo aver valutato un esempio <em>x</em> e non solamente dopo aver valutato tutti gli esempi del training set.</p>
<p>Le possibili condizioni di terminazione sono le stesse che si hanno quando c&#39;√® un solo neurone.</p>
<h1 id="lezione-11-pipeline-di-apprendimento-supervisionato">Lezione 11 - Pipeline di apprendimento supervisionato</h1>
<p>L&#39;apprendimento supervisionato pu√≤ essere visto come una serie di fasi:</p>
<ol>
<li>Analisi del problema</li>
<li>Raccolta, analisi e preprocessing dei dati</li>
<li>Studio delle correlazioni tra variabili</li>
<li>Feature selection, definizione dei pesi, normalizzazione</li>
<li>Scelta del predittore e del modello</li>
<li>Verifica del modello</li>
</ol>
<h2 id="fase-4-feature-selection-definizione-dei-pesi-normalizzazione">Fase 4 - Feature selection, definizione dei pesi, normalizzazione</h2>
<p>Per rappresensentare gli oggetti con i quali lavora un algoritmo di apprendimento √® possibile utilizzare varie rappresentazioni:</p>
<ul>
<li><strong>vettori</strong>: come il valore di pressione del sangue, il battito cardiacoo, altezza e peso, (Un vettore con dei numeri.</li>
<li><strong>stringhe</strong>: Una serie di caratteri che rappresentano un documento o la struttura del DN</li>
<li><strong>insiemi</strong>: ad esempio l&#39;insieme di termini che compare in un documento</li>
<li><strong>array multidimensionali</strong>: come immagini e video</li>
<li><strong>albero o grafi</strong>: un documento XML </li>
<li><strong>strutture composte</strong>: ottenute combinando tra loro le precedenti.</li>
</ul>
<p>Nel corso ci concentriamo principamente sui vettori.</p>
<p>Per ogni oggetto possiamo avere a disponsizione delle <strong>feature categoriche</strong>, che rappresentano delle caratteristiche nominali dell&#39;oggetto (marca di un auto, paese di origine), alcune di queste possono essere anche <strong>ordinali</strong>, cio√® che impongno un ordine tra gli elementi ma la distanza tra un valore e un altro non √® quantificabile, come per esempio i gradi militari: soldato, caporale, ecc.</p>
<p>Un altro tipo di feature sono le <strong>feature quantitative</strong>, cio√® delle caratteristiche che sono <strong>enumerabili</strong>, come il livello di apprezzamento di un prodotto, oppure <strong>ratio</strong>, ovvero dei numeri reali, come il peso di una persona.</p>
<h3 id="mapping-feature-categoriche">Mapping Feature categoriche</h3>
<p>Le feature categoriche si possono mappare in un vettore con tante componenti quanti sono i possibili valori della variabile (<strong>one-hot</strong>).</p>
<blockquote>
<p>Ad esempio per raooresentare una macchina con le seguenti caratteristiche √® possibile utilizzare un vettore che lo codifica.</p>
<ul>
<li>Marca: Fiat [c1], Toyota [c2], Ford [c3]</li>
<li>Colore: Bianco [c4], Nero [c5], Rosso [c6],</li>
<li>Tipo: Economica [c7], Sportiva [c8]</li>
</ul>
<p>La macchina (Toyota, Rossa, Economica) viene quindi rappresentata con un vettore <code>[0,1,0,0,0,1,1,0]</code></p>
</blockquote>
<h3 id="mapping-per-feature-continue">Mapping per feature continue</h3>
<p>Tipicamente le feature continue vengono trasformate per ottenere dei valori comparabili con le altre feature.</p>
<p>Per ottenere ci√≤ √® possibile applicare una delle seguenti traformazioni:</p>
<ul>
<li><strong>Centramento</strong>: <em>f(x) = x - E(x)</em></li>
<li><strong>Normalizzazione STD</strong>: <em>f(x) = (x - E(x))/œÉ(x)</em></li>
<li><strong>Rescaling</strong>: <em>f(x) = (x - x<sub>min</sub>)/(x<sub>max</sub>-x<sub>min</sub>)</em></li>
</ul>
<p>Dove:</p>
<ul>
<li><em>E(x)</em> √® la media di tutti i possibili valori di <em>x</em></li>
<li><em>œÉ(x)</em> √® lo scarto quadratico medio</li>
</ul>
<h3 id="algoritmo-k-nn">Algoritmo K-NN</h3>
<p><strong>K-Nearest-Neighbors</strong>: √® un algoritmo di classificazione in cui un esempio di test √® classificato come la classe di maggioranza dei sui <em>k</em>-vicini nel training set.</p>
<p>Si vanno a scegliere i <em>k</em> elementi pi√π vicini all&#39;elemento che si vuole classificare e viene scelta come classe quella della maggioranza dei suoi <em>k</em>-vicini.</p>
<p>Volendo si pu√≤ normalizzare per perdere volontariamente delle informazioni, in modo da togliere del rumore.</p>
<p>Trattandosi di vettori la distanza deve essere misurata come:</p>
<blockquote>
<p>||x - y||<sup>2</sup> = ||x||<sup>2</sup> + ||y||<sup>2</sup> - 2x<sup>T</sup>y</p>
</blockquote>
<p>Per semplificare i calcoli, si pu√≤ tenere in considerazione che se i due vettori hanno la stessa norma, la loro distanza √® uguale alla similiarit√† indotta dal prodotto scalare:</p>
<blockquote>
<p>||x - y||<sup>2</sup> = const - 2x<sup>T</sup>y</p>
</blockquote>
<h2 id="fase-5-scelta-del-predittore-e-del-modell">Fase 5 - Scelta del predittore e del modell</h2>
<p>I parametri sono i valori che influiscono nell&#39;apprendimento, come i vari pesi <em>w</em>. Mentre, gli <strong>iper-parametri</strong> sono tutti gli altri parametri che non influiscono con l&#39;apprendimento, come il numero di unit√† nascoste per le reti neurali o il <em>k</em> per l&#39;algoritmo k-nn.</p>
<p>La fase in cui questi valori vengono scelti prende il nome di <strong>model selection</strong> e come valori si cerca di scegliere il migliore per il task.</p>
<h3 id="bias-e-varianza">Bias e varianza</h3>
<p>Per valutare le predizioni di uno stimatore vengono utilizzate due misure:</p>
<ul>
<li><strong>bias</strong>: che misura la distorsione di una stima quando lo stimatore √® corretto</li>
</ul>
<blockquote>
<p>b = E[ùúÉ&#39;] - ùúÉ </p>
</blockquote>
<ul>
<li><strong>varianze</strong>: che misura quanto si disperde la stima.</li>
</ul>
<blockquote>
<p>v = E[(ùúÉ&#39; - E[ùúÉ&#39;])<sup>2</sup>]</p>
</blockquote>
<p>Nelle formule sopra riportate <em>ùúÉ</em> rappresenta il valore corretto e <em>ùúÉ&#39;</em> rappresenta il valore prodotto dallo stimatore.</p>
<h3 id="hold-out">Hold out</h3>
<p>Una strategia per ricercare il valore ottimo per un iper-parametro √® quella dell&#39;<strong>hold out</strong>, ovvero per ogni possibile valore un valore per l&#39;iper-parametro si fa eseguire l&#39;apprendimento allo stimatore su un sotto-insieme del training set, dopodich√© si confrontano i risultati ottenuti effettuando delle predizioni su un insieme di validazione, ovviamente viene scelto il valore dell&#39;iper-parametro che porta ad ottenere le predizioni migliori.</p>
<p>Pi√π formalmente:</p>
<ol>
<li>Si sceglie un piccolo sottoinsieme <em>Tr</em> del training set che viene utilizzato come set di validazione <em>Va</em>.</li>
<li>Il classificatore (algoritmo) apprende utilizzando gli esempi in <em>Tr</em> ma senza usare quelli che compaiono in <em>Va</em>.</li>
<li>Si osserva come si comporta il classificatore con un determinato valore dell&#39;iper-parametro, e si ripete a partire dal punto 2 per tutti i possibili valori dell&#39;iper-parametro.</li>
</ol>
<p>In questo modo riesco a calcolare l&#39;<em>accuracy</em> per ogni valore del iper-parametro e di conseguenza posso scegliere il valore migliore.</p>
<p>Con l&#39;<strong>accuracy</strong> si intende la proporzione di predizione corrette effettuate dallo stimatore.</p>
<p>Una volta scelto il valore, tipicamente si rieffettua l&#39;apprendimento utilizzando il training set completo.</p>
<h3 id="k-fold-cross-validation">K-fold Cross Validation</h3>
<p>Alternativa all&#39;hold-out che permette di valutare in modo pi√π preciso la bont√† dei possibili valori per un iper-parametro.</p>
<p>L&#39;insieme di apprendimento viene partizionato in <em>k</em> parti disgiunte.
Viene poi eseguito l&#39;apprendimento utilizzando <em>k-1</em> partizioni e utilizzando la restante partizione per fare validazione.
L&#39;intero processo di apprendimento viene ripetuto quindi <em>k</em> volte, utilizzando ogni volta una partizione per la validazione diversa.</p>
<p>Cos√¨ facendo per un singolo valore di un iper-parametro si ottengono <em>k</em> valori di accuracy e si pu√≤ utilizzare la media di queti valori per ottenere una stima dell&#39;accuracy migliore.</p>
<p>Il tutto viene poi ripetuto per ogni possibile valore dell&#39;iper-parametro. </p>
<p>Il valore di <em>k</em> influisce la dimensione del training set, utilizzando un <em>k</em> piccolo, si ottiene un training set pi√π piccolo, quindi il bias induttivo aumenta e la varianza della stima ottenuta diminuisce.</p>
<p>Viceversa, se <em>k</em> √® grande, il training set √® pi√π grande e si ottiene un minor bias induttivo.</p>
<p>Tipicamente si usa <em>k=5</em> o <em>k=10</em>.</p>
<h3 id="valutazione-per-dati-non-bilanciati">Valutazione per dati non bilanciati</h3>
<p>Quando nel training set c&#39;√® una classe che domanina sulle altre, l&#39;accuracy non √® pi√π una stima adatta, vengono quindi utilizzate altre misure quali: <strong>precision</strong>, <strong>recall</strong> e <strong>F-Measure</strong>.</p>
<ul>
<li><strong>Precision</strong>: (œÄ) misura quante volte, quanti tra gli esempi classificati come positivi sono effettivamente positivi</li>
</ul>
<blockquote>
<p>œÄ  = true positive / (true positive + false positive)</p>
</blockquote>
<ul>
<li><strong>Recall</strong>: (p) misura quanti che sono effettivamente positivi sono stati classificati come positivi.</li>
</ul>
<blockquote>
<p>p = true positive / (true positive + false negative)</p>
</blockquote>
<p><strong>Precioson</strong>: quanti tra quelli che ho detto essere positivi sono effettivamente positivi.</p>
<p>Un&#39;altra misura pi√π accurata √® la <strong>F-measure</strong> che combina tra loro precision e recall:</p>
<blockquote>
<p>F<sub>1</sub> = 2 œÄp / (œÄ + p)</p>
<p>F<sub>ùú∑</sub> = (1+ùú∑<sup>2</sup>)œÄp / (ùú∑<sup>2</sup>œÄ + p)</p>
</blockquote>
<h1 id="lezione-12-support-vector-machine">Lezione 12 - Support Vector Machine</h1>
<p>Richiamo: l&#39;errore <strong>ideale</strong>, cio√® quello commesso su esempi che non sono stati valutati durante l&#39;apprendimento, pu√≤ essere visto come composto da due termini, un errore empirico sui dati e la VC-Confidence.</p>
<p>L&#39;algoritmo di minimizzazione dei rischi cerca lo spazio delle impotesi che va a minimizzare la VC-Confidence.</p>
<h2 id="svm-idea-di-base">SVM - Idea di base</h2>
<p>Sappiamo che la VC dimension di un iperpiano nello spazio <em>m</em> √® <em>m+1</em>.</p>
<p>Considerando il caso in cui gli esempi sono linearmente separabili si pu√≤ definire il margine <em>r</em> come la distanza minima tra l&#39;iperpiano e l&#39;esempio pi√π vicino.</p>
<p>L&#39;iperpiano che ha un margine maggiore viene detto ottimo e massimizza la minima distanza con gli esempi.</p>
<p><img src="./notes/immagini/l12-space.png" alt=""></p>
<h3 id="margine">Margine</h3>
<p><img src="./notes/immagini/l12-distanza.png" alt=""></p>
<p><img src="./notes/immagini/l12-distanza-2.png" alt=""></p>
<p><img src="./notes/immagini/l12-distanza-3.png" alt=""></p>
<p>Vincoli e funzione di costo sono convessi perch√© i vincoli sono lineare e il costo √® una parabola.</p>
<p><img src="./notes/immagini/l12-caso-separabile.png" alt=""></p>
<p><img src="./notes/immagini/l12-caso-separabile-2.png" alt=""></p>
<p>Quindi i vettori di supporto sono gli esempi di training che si trovano in uno dei due iperpiani margine.</p>
<h1 id="lezione-13-support-vector-machine">Lezione 13 - Support Vector Machine</h1>
<p>Nelle precedenti puntate:</p>
<ul>
<li>Sappiamo che un iperpiano in uno spazio di dimensione m ha VC dimension m+1.</li>
<li>Si pu√≤ aggiungere un vincolo di classificazione relativo al margine.</li>
<li>Per ottenere l&#39;iperpiano con margine ottimo √® necessario considerare le ipotesi che minimizza la norma di <em>w</em>.</li>
<li>Il tutto si fa prima con un polinomio di Lagrange e il suo duale.</li>
</ul>
<h2 id="dati-non-separabili-linearmente">Dati non separabili linearmente</h2>
<p>Tutto quello visto finora funziona se i dati sono linearmente separabili.</p>
<p>Nel caso questi non lo siano √® necessario aggiungere una nuova variabile per ogni elemento presente nel training set.</p>
<p><img src="./notes/immagini/l13-non-linear.png" alt=""></p>
<p>Vengono quindi definite delle psi_i che rappresenta la distanza del elemento i-esimo dal margine entro il quale dovrebbe trovarsi.</p>
<p>L&#39;idea √® quindi quella di andare a sommare alla funzione costo, un altro quoziente della sommatoria di tutti i psi_i dei vari esempi presenti nel training set.</p>
<p>Il valore <em>C</em> del coefficente che va a moltiplicare la sommatoria degli psi_i pu√≤ essere scelta con le tecniche di model selection.</p>
<p>In pratica vengono penalizzati (aumentato il costo) gli esempi che non rispettano il margine.</p>
<p>La funzione psi_i si comprota anche come upper buond per la rappresentazione dell&#39;esempoio i-esimo del trainging set.</p>
<p>Sommando le psi_i di tutti gli esempi √® maggiore o ugale al numero di errrori analizzzando tutto il trainingset.</p>
<p><img src="./notes/immagini/l13-slack.png" alt=""></p>
<p>Allo stesso modo si pu√≤ trovare il problema duale (non vengono visti i conti)</p>
<p><img src="./notes/immagini/l13-cost.png" alt=""></p>
<p>Da notare che nel caso separabile i vettori di supporto stanno su uno dei due iperpiani margini.</p>
<p>Nel caso di dati non linearmente separabili o si trovano in un ipermpiano margine oppire uno psi_i negativo.</p>
<p>Da notare che le psi_i sono variabili del problema primale e che quindi non compaiono nel problema duale.</p>
<p>Questa strategia per esempi non linearmente separabili non sempre garantisce buone prestazioni perch√© un iperpiano pul solo rappresentare dicotomie dello spazio delle istanze.</p>
<p>Per questo motivio, quando gli esempi non sono lineramente separabili su usa una strategia divisa in due passi:</p>
<ol>
<li>Si mappano i dati di ingresso (input sapce) in uno spazio a dimnesione molto superirore (feature space). Quindi a partire dalle feature degli elementi dell&#39;input space vengono creati nuovi esempi nel feature space che utilizza combinazioni non lineari delle feature del primo spazio.</li>
<li>Si calcola poi l&#39;iperpiano ottimo per il nuovo spazio usando la formulazione precedente (che prende il nome di variabili slack).</li>
</ol>
<p>Perch√© dovrei farlo?</p>
<ol>
<li>Perch√© il teorema sulla separabilit√† di Cover afferma che uno spazio delle ipotesi pi√π grande √® pi√π probabile che questo sia linearmente separabile. (Un problema di classificazione complesso, formulato attrvareso una trasfomrazione non linear dei dati in uno spazio ad alata dimensionalit√†, ha maggiore probabilit√† di essere linearmente separabile che in uno spazio a bassa dimnsionalit√†).</li>
<li>Perch√© l&#39;iperpiano ottimo minimizza la VC-Dimension e quindi la capacit√† di generalizzazione migliora.</li>
</ol>
<p><img src="./notes/immagini/l13-alt.png" alt=""></p>
<p>In un modo simile a come accade con il perceptron.</p>
<p><img src="./notes/immagini/l13-train.png" alt=""></p>
<h2 id="funzioni-kernel">Funzioni Kernel</h2>
<p><img src="./notes/immagini/l13-kernel.png" alt=""></p>
<p>La cosa bella √® che si pu√≤ &quot;inventare&quot; una funzione K che ci permette di calcolare agevolmente il prododdo scalare.</p>
<p><img src="./notes/immagini/l13-kernel-2.png" alt=""></p>
<p><img src="./notes/immagini/l13-comparsion.png" alt=""></p>
<h2 id="regressione">Regressione</h2>
<p>Quando si considera il problema di approssimazione di funzioni a valori reali (regressione) si utilizza l&#39;œµ-tubo: output che differiscono dai valori di target per pi√π di œµ in valore assolunto vengono penalizzati linearmente, altrimenti non vengono considerati errori.
In partica aggiungo un intervallo di tolleranza al iperpiano che partiziona lo spazio.</p>
<p><img src="./notes/immagini/l13-min-primale.png" alt=""></p>
<p>che trasformata in duale diventa</p>
<p><img src="./notes/immagini/l13-duale.png" alt=""></p>
<h1 id="lezione-14-funzioni-kernel">Lezione 14 - Funzioni Kernel</h1>
<p><img src="./notes/immagini/l14-kernel.png" alt=""></p>
<p>In pratica la funzione Kernel serve per calcolare un prodotto scalare in uno spazio a pi√π dimensioni.</p>
<h2 id="rappresentazione-dei-dati-con-i-kernel">Rappresentazione dei dati con i Kernel</h2>
<p>Le funzioni Kernel permettono di andare a definire una serie di metodi per l&#39;apprendimento supervisionato.</p>
<p>Ad esempio data una serie di oggetti <em>S = {x<sub>1</sub>,x<sub>2</sub>,.., x<sub>n</sub>}</em> pu√≤ essere rappresentata con i Kernel come una funzione</p>
<blockquote>
<p><em>k</em>: X <em>x</em> X -&gt; R</p>
</blockquote>
<p>Cio√® una funzione che confronta le varie coppie della serie e le valuta utilizzando un numero reale.</p>
<p>Il dataset <em>S</em> pu√≤ essere quindi rappresentato con una matrice simmetrica <em>K<sub>i,j</sub> = k(x<sub>i</sub>,x<sub>j</sub>)</em>. Inoltre, dal momento che la funzione <em>k</em> rappresenta un prodotto scalare su un certo spazio, la matrice <em>k</em> √® semi-definita positiva (questa realzione vale in se e solo se).</p>
<p><strong> aggiungi immagine cone definzione di matrice definita semi positva</strong></p>
<h3 id="vantaggi-di-questa-rappresentazione">Vantaggi di questa rappresentazione</h3>
<p>La rappresentazione dei dati con matrici kernel ha come vantaggi:</p>
<ul>
<li>lo stesso algortimo pu√≤ essere utilizzato per analizzare dati diveri, quindi tutti gli algoritmi <strong>kernel based</strong> saranno definiti sulla forma della matrice.</li>
<li>la progettazione dei kernel e degli algortimi √® modulare</li>
<li>risulta pi√π semplice integrare viste diverse di oggetti, non sempre esiste una rappresentazione ottimale dello stesso oggetto, diventa quindi possibile combinare tra loro queste rappresentazioni.</li>
<li>La dimensionalit√† dei dati dipente solo dal numero di oggetti e non dalla loro dimensione vettoriale.</li>
<li>La comparazione tra oggetti pu√≤ risultare pi√π semplice rispetto ad una loro esplicita rappresentazione.</li>
</ul>
<h3 id="metodi-kernel">Metodi Kernel</h3>
<p>Molti metodi kernel, comprese le SVM possono essere interpretati come algortimi che, dato un insieme di oggetti <em>S</em> risolvono un problema di minimo di una certa funzione <em>L</em> associata al rischio empirico.</p>
<p><strong>immagine 1</strong></p>
<h3 id="modularit-dei-metodi-kernel">Modularit√† dei metodi Kernel</h3>
<p>I metodi Kernel possono essere rappresentatni da 5 fasi modulari</p>
<ol>
<li><em>n</em>-oggetti</li>
<li>definizione della funzione kernel</li>
<li>costruzione della matrice <em>K</em></li>
<li>applicazione dell&#39;algoritmo su <em>K</em> e <em>Y</em> (valori target attesi) (ad esempio SVM)</li>
<li>produzione dalla funzione</li>
</ol>
<p><strong>sostituire con l&#39;immagine</strong></p>
<h2 id="kernel-trick">Kernel Trick</h2>
<p>Ogni algoritmo per i dati vettoriali che pu√≤ essere espresso in termini del prodotto scalre tra vettori pu√≤ essere implicitamente eseguito nello spazio delle feature associatio ad un determinato kernel, rimpiazzando i prodotti scalari con valutazioni kernel.</p>
<ol>
<li>Kerneliizzazione di metodi lineari o basati su distenze, come il Perceptron e K-NN.</li>
<li>Applicazione di algoritmi definiti su vettori a dati non vettoriali, utilizzando dei kernel definiti per dati non vettoriali.</li>
</ol>
<p>Ad esempio K-NN pu√≤ utilizzare i kernel per calcolare la distanza tra due vettori.</p>
<h2 id="tipologie-di-kernel">Tipologie di Kernel</h2>
<p>Per <strong>vettori</strong> si possono utilizzare come kernel:</p>
<ul>
<li><strong>lineare</strong>: <em>k(x,z) = x \</em> z*</li>
<li><strong>polinomiale</strong>: <em>k(x,z) = (x * z + c)<sup>d</sup></em></li>
<li><strong>gaussiano</strong> (RBF): <em>k(x,z) = exp(-ùú∏||x-z||<sup>2</sup>)</em>, ha la caratteristica di essere sempre compreso tra 0 e 1.</li>
</ul>
<p>Il fatto che il kernel sia sempre maggiore di 0, implica che i due vettori sono nello stesso ottante (tra i due vettori c&#39;√® un angolo minore di 90¬∞).</p>
<p>Se <em>k(x,x)</em> √® uguale a 1 si dice che il kernel √® <strong>normalizzato</strong>, ovvero tutti i vettori del feature space sono normalizzati. La matrice kernel definita con un kernel normalizzato ha tutti 1 nella diagonale.</p>
<p>√à sempre possibile normalizzare un kernel <em>k(x,z)</em> dividendolo per la radice quandrata di <em>k(x,x) * k(z,z)</em></p>
<p>Come kernel per le <strong>stringhe</strong> si possono contare tutte le sequenze di una cerca lunghezza e costruire un vettore delle feature delle occorrenze, questo si fa con le tecniche di programmazione dinamica.</p>
<p>Per gli alberi si possono utilizzare delle tecniche analoghe, considerando i sotto alberi in comune.</p>
<p>C&#39;√® un libro <strong>Kernel Methods for Pattern Analysis</strong> che spiega molto bene questa tecnica.</p>
<h2 id="operazioni-sui-kernel">Operazioni sui Kernel</h2>
<p>Una combinazione lineare positiva di kernel √® anchessa un kernel, quindi</p>
<blockquote>
<p>k(x,z) = ak<sub>1</sub>(x,z) + bk<sub>2</sub>(x,z)</p>
</blockquote>
<p>Se quna sequenza di kernel converge puntualmente ad una funzione <em>f</em>, allora anche <em>f</em> √® un kernel.</p>
<p>Ma c&#39;√® di pi√π, i kernel possono essere tra loro composti per ottenere altri kernel.</p>
<p>Tutto questo si pu√≤ andare a combinare per ottenere un kernel migliore.
Dato un insieme <em>S</em> di kernel si pu√≤ definire</p>
<blockquote>
<p>k(x,z) = Sommatoria<sub>[S=1,Q]</sub>Œº<sub>s</sub>k<sub>s</sub>(x,z)</p>
</blockquote>
<p>Dove Œº √® un vettore tale che la loro sommatoria sia 1.</p>
<p>L&#39;idea del Multiple Kernel Learning √® di definire degli algoritmi per apprendere i valori di Œº<sub>s</sub> della combinazione che migliorino le prestazione di una SVM usando il kernel combinato, rispetto alle SVM ottenute utilizzando i kernel individuali.</p>
<h1 id="lezione-15-apprendimento-bayesiano">Lezione 15 - Apprendimento Bayesiano</h1>
<p>Si tratta di algoritmi di apprendimento basati sulla probabilit√† e sul teorema di Bayes.</p>
<h2 id="scelta-delle-ipotesi">Scelta delle ipotesi</h2>
<p>Tutto si basa sulla formula di Bayes.</p>
<blockquote>
<p>P(h|D) = P(D|h)P(h)/ P(D)</p>
</blockquote>
<p>L&#39;obiettivo √® quello di massimizzare <em>P(h|D)</em>, sapendo <em>P(D|h)</em> che viene fornito dal supervisore e <em>P(h)</em> che viene appresa.</p>
<p>Nel massimizzare si pu√≤ tralasciare il termine <em>P(D)</em> dal momento che √® sempre costante.</p>
<blockquote>
<p>h<sub>MAP</sub> = argmax<sub>[h œµ H]</sub> P(h|D)P(D)</p>
</blockquote>
<p>Si pu√≤ inoltre assumere che tutte le ipotesi <em>h</em> abbiano la stessa ipotesi e nel mondo reale questa assunzione √® tipicamente corretta, il problema di massimizzazione diventa:</p>
<blockquote>
<p>h<sub>ML</sub> = argmax<sub>[h œµ H]</sub> P(h|D)</p>
</blockquote>
<p>A pagina 158 del Mitchel c&#39;√® un esempio che mette in evidenza come le probabilit√† a priori influenzino il risultato.</p>
<h2 id="brute-force-map-learning-interpretazione-find-s-">Brute Force MAP Learning (interpretazione Find-S)</h2>
<p>Si assumono fissate le istanze x1 ... xn.</p>
<p>Si assume D essere l√¨insieme dei valori derisderati D 
= {c(x1)...c(xn)}</p>
<p>Considerando tutte le ipotesi equiprobabili: <em>1/|H|</em></p>
<blockquote>
<p>P(D|h) = 1 se h √® consistente con gli elementi di D</p>
<p>P(D|h) = 0 altrimenti </p>
</blockquote>
<p>Supponiamo inoltre che non sia presente del rumore.</p>
<p>In questo modo la probabilit√† <em>P(h|D)</em> si ottiene applicando la regola di Bayes, in particolare:</p>
<blockquote>
<p>P(h|D) = 0 se h √® non √® consistente con D</p>
<p>P(h|D) = 1/VS<sub>H,D</sub> se h √® consistente con D</p>
</blockquote>
<p>Quindi se tutte le ipotesi <em>h</em> sono equiprobabili, allora qualsiasi ipotesi presente in <em>H</em> va bene con probabilit√†  <em>1/VS<sub>H,D</sub></em>.</p>
<p>Se vengono cambiate le probabilit√† in modo che la probabilit√† di un&#39;ipotesi pi√π specifica sia pi√π alta si ottiene che <em>P(h|D) = P(h)</em>.</p>
<h2 id="apprendimento-di-una-funzione-ml-">Apprendimento di una funzione (ML)</h2>
<blockquote>
<p>di = f(xi) + ei</p>
</blockquote>
<p>dove Ei √® l&#39;errore che segue una probabilit√† gaussiana con media 0 di cui non si conosce la varianza.</p>
<blockquote>
<p>ei = di - f(xi)</p>
</blockquote>
<p>Per√≤ si vuole valutare l&#39;errore come se al posto di <em>f</em> (che √® sconsociuta) ci fosse <em>h</em></p>
<blockquote>
<p>ei = di - h(xi)</p>
</blockquote>
<p>La probabilit√† di <em>P(di|h)</em>, cio√® che l&#39;ipotesi <em>h</em> classifichi correttamente <em>di</em> segue la distribuzione guassiana di <em>ei</em>.</p>
<blockquote>
<p>h<sub>ML</sub> = argmax<sub>[h œµ H]</sub> P(D|h)</p>
<p>h<sub>ML</sub> = argmax<sub>[h œµ H]</sub> (produttoria) P(di|h)</p>
<p>h<sub>ML</sub> = argmax<sub>[h œµ H]</sub> (produttoria) gaussiana di (di-h(xi))</p>
</blockquote>
<p>Dal momento che la gaussiana contiene un&#39;esponenziale, conviene utilizzare il logaritmo, tanto per il problema di massimizzazione √® la stessa cosa.</p>
<p><strong>fai screen delle slide per i conti</strong></p>
<p>Segue quindi che</p>
<blockquote>
<p>h<sub>ML</sub> = argmin<sub>[h œµ H]</sub> (sommatoria)(di-h(xi))<sup>2</sup></p>
</blockquote>
<p>Quindi per trovare l&#39;ipotesi <strong>maximum likelihood</strong> √® necessario minimizzare l&#39;errore quadratico, sotto le ipotesi che la probabilit√† di ogni ipotesi √® uniforme e assumendo che non ci sia rumore nei dati di training.</p>
<h3 id="classificazione">Classificazione</h3>
<p>Finora abbiamo cercato l&#39;ipotesi pi√π probabile per i dati <em>D</em> (<em>h<sub>MAP</sub></em>), ma dato un nuovo esempio, qual&#39;√® la classificazione pi√π probabile? Non sempre</p>
<p>Supponiamo di avere <em>P(h1|D)=0.4</em>,<em>P(h2|D)=0.3</em>, <em>P(h3|D)=0.3</em>, data una nuova istanza <em>x</em> pu√≤ succedere che <em>h1(x) = (+)</em> e <em>h2(x) = h3(x) = (-)</em>. Quindi considerando le tre ipotesi, la classificazione pi√π probabile √® <em>(-)</em> e non <em>(+)</em>.</p>
<p>Segue che la <strong>classificazione ottima di Bayes</strong>:</p>
<blockquote>
<p>argmax<sub>[v œµ vj]</sub> (sommatoria<sub>[h œµ H]</sub>) P(vj | h)P(h)</p>
</blockquote>
<p>Si va cio√® a considerare tra tutte le ipotesi, pesate per la loro probabilit√†, e si considera come classe quella che compare pi√π volte.</p>
<h4 id="classificazione-di-gibbs">Classificazione di Gibbs</h4>
<p>Dal momento che il classificatore ottimo di Bayes potrebbe essere molto costoso da calcolare se ci sono tante impotesi.</p>
<p>Si pu√≤ tulizzare un&#39;alternativa, scegliendo un ipotesi a caso, secondo la probabilit√† <em>P(h|D)</em> e utilizzando quell&#39;ipotesi per classificare la nuova istanza, si ottiene un errore medio minore del doppio dell&#39;errore medio che si ottiene utilizzando il classificatore ottimo.</p>
<blockquote>
<p>E[errore<sub>Gibbs</sub>] &lt;= E[errore<sub>OttimoBayes</sub>]</p>
</blockquote>
<p>Sempre assumendo probabilit√† uniforme per tutte le ipotesi del version space.</p>
<h1 id="lezione-17-clustering">Lezione 17 - Clustering</h1>
<p>Il clustering √® il processo che partiziona un&#39;insieme di oggetti in sottogruppi in modo che gli oggetti di questi gruppi siano simili tra loro.</p>
<p>Questa tipologia di apprendimento prende il nome di <strong>apprendimento non supervisionato</strong> dal momento che non vengono calcolate delle etichette e non c&#39;√® un supervisore che fornisce delle etichette per i dati di apprendimento.</p>
<h2 id="il-problema-del-clustering">Il problema del clustering</h2>
<p>Tipicamente √® composto da:</p>
<ul>
<li>Un insieme di esempi, detti anche documenti, D = {d<sub>1</sub>..d<sub>n</sub>}</li>
<li>Una misura di similiarit√† o distanza, decisa da noi</li>
<li>Un criterio di partizionamento</li>
<li>Un numero desiderato di cluster <em>K</em>.</li>
</ul>
<p>L&#39;algoritmo di clustering calcola quindi una funzione di assegnamento ùú∏ che prende un elemento di <em>D</em> e lo assegna ad un gruppo <em>{1..K}</em>, in modo che non ci siano cluster vuoti e che venga soddisfatta la misura di similarit√†.</p>
<h2 id="problemi-del-clustering">Problemi del clustering</h2>
<p>Come rappresentare i dati? Anche in questo caso √® necessario utilizzare una rappresentazione nel vector space, normalizzando i dati.
Inoltre, la rappresentazione influsce sulla misura di similarit√†.</p>
<p>Serve poi una notazione per la similarit√†/distanza.</p>
<p>C&#39;√® poi il problema di quanti cluster fare, se stabilirlo a priori o sceglierlo in base ai dati, evitando i casi triviali con cluster troppo grandi o troppo piccoli.</p>
<h2 id="funzione-obiettivo">Funzione obiettivo</h2>
<p>Tipicamente l&#39;obiettivo di un problrma di clustering √® quello di ottimizzare una funzione, definendo cos√¨ un problema di ricerca tra i possibili assegnamenti.</p>
<p>Questi stati sono tanti, <em>K<sup>N</sup>/K!</em>. Il <em>K!</em> serve per togliere i cluster equivalenti, cio√® quando la divisione degli elementi √® identica ma cambia &quot;l&#39;etichetta&quot; dei cluster a cui sono assegnati.</p>
<p>Tra l&#39;altro ci sono dei problemi con i minimi locali per la funzione obiettivo, possono essercene tanti e possono impedire di raggiungere un minimo ottimo.</p>
<h2 id="valutazione-di-un-clustering">Valutazione di un clustering</h2>
<p>Ci sono dei <strong>criteri interni</strong> che vanno a misurare la similarit√† tra oggetti della stessa classe (<strong>intra-class</strong>) e tra oggetti di classi diversi (<strong>extra class</strong>), un buon clustering cerca quindi di massimizzare l&#39;intra-class e di minimizzare l&#39;extraclass.</p>
<p>La qualit√† misurata inoltre dipende da come vengono rappresentati i dati e dalla misura di similirit√† adottata.</p>
<p>Ci sono poi i <strong>criteri esterni</strong>, l&#39;idea √® quella di trovare quanto simile √® il clustering trovato rispetto ad una divisione data a priori che prende il nome di <strong>ground truth</strong>.</p>
<p>Si assume quindi che i documenti possano essere partizionati in <em>C</em> classi che rappresentano la ground truth e che l&#39;algortimo di clustering produca <em>K</em> cluster, <em>œâ<sub>1</sub> ... œâ<sub>K</sub></em>, ognuno contenente <em>n<sub>i</sub></em> documenti.</p>
<p>La misura pi√π semplice prende il nome di <strong>purity</strong> e rappresenta il rapporto medio tra i vari cluster che c&#39;√® tra la classe nominante in quel cluster e la dimensione del cluster.</p>
<p>Dalle slide: purity, the ratio between the dominant class in the cluster œÄ<sub>i</sub> and the size of the cluster œâ<sub>i</sub></p>
<p>Altre misure si basano sull&#39;entropia.</p>
<p><img src="./notes/immagini/l17-purity.png" alt=""></p>
<p>Nell&#39;esempio il numero di cluster coincide con il numero di etichette √® una cosa voluta, ma il gioco funziona anche con un numero diverso di cluster.</p>
<p><strong>il core business della situazione √® che le etichette per il clustering servono solo per VALUTARLO e non per fare apprendimento</strong></p>
<h3 id="rand-index">Rand Index</h3>
<p>√à una misura di similirat√† tra cluster, definita come il rapporto tra il numero di elementi che hanno la stessa classe ground e si trovano nello stesso cluster e con classi diverse in cluster diversi, sul numero totale di elementi.</p>
<p><img src="./notes/immagini/l17-rand-index.png" alt=""></p>
<p>Viene creata una tabella di contingenza, valutando per ogni coppia di punti, se hanno etichette diverse e se sono nello stesso cluster.</p>
<p>Probabilmente, ma non ne sono sicuro, i numeri della tabella corrispondo alle coppie che rispondo a quella categoria.</p>
<p>In questo modo ci si riconduce all&#39;accuracy:</p>
<blockquote>
<p>RI = A + D / A+B+C+D</p>
</blockquote>
<p>Allo stesso modo si possono calcolare <strong>precision</strong> e <strong>recall</strong></p>
<blockquote>
<p>P = A/A+B</p>
<p>R = A/A+C</p>
</blockquote>
<h2 id="algoritmi-di-clustering">Algoritmi di Clustering</h2>
<p>Ci sono due tipoleogie di algoritmi: </p>
<ul>
<li><strong>partitional</strong>: che partono da un partizionamento casuale e cercano di migliorarlo iterativamente (K-means clustering, Model based clustering)</li>
<li><strong>hierarchical</strong>: che vanno a definire un clustering come un albero in cui la radice contiene tutti gli esempi e man mano che si scende questi vegono partizionati. Si pu√≤ usare un approccio <strong>agglomerative</strong> che costruisce l&#39;albero in modo bottom-up (permettendo di fissare un numero di cluster), o <strong>divisive</strong> che funziona in top-down, applicando K-mean sulla radice e poi ricorsivamente su ogni figlio, arrivando fino alla foglie che consistono in cluster di un solo elemento.</li>
</ul>
<h2 id="k-means">K-means</h2>
<p>Questo algoritmo appartiene alla categoria degli algoritmi di partizionamento, ovvero vengono partizionati gli <em>n</em> documenti in <em>K</em> cluster, cercando di trovare un partizionamento ottimo secondo un determinato criterio.</p>
<p>Gli elementi da clusterizzare sono dei vettori con numeri reali e come criterio di partizionamento si utilizza la distanza vettoriale tra gli esempi e il centro del cluster.</p>
<p>Si cerca quindi di creare dei cluster che minimizzano il raggio della ipersfera che contiene gli esempi. (cluster <strong>centroidi</strong>)</p>
<p>La formula da minimizzare √® la seguente:</p>
<p><img src="./notes/immagini/l17-center.png" alt=""></p>
<h3 id="algoritmo">Algoritmo</h3>
<ol>
<li>Si posizionano K punti a caso nello spazio degli oggetti da clusterizzare, questi punti rappresentano i centroidi dei cluster.</li>
<li>Si assegna ogni oggetto al centroide pi√π vicino.</li>
<li>Una volta completato l&#39;assegnamento si ricalcola la posizione di tutti i centroidi utilizzano la media dei valori di tutti gli oggetti che sono finiti nel cluster.</li>
<li>Si ripetono i passi 2 e 3 finch√© non si spostano pi√π i centrodi.</li>
</ol>
<p>Questo algoritmo raggiunge un punto fisso.</p>
<p>Resta comunque il problema della scelta del numero di cluster da utilizzare.</p>
<h2 id="approcci-gerarchici-agglormerativi">Approcci gerarchici agglormerativi</h2>
<p><strong>quelli disivi utilizzano ricorsivamente k-means</strong></p>
<p>Costruiscono un dendogramma a partire dagli oggetti, che vengono agglomerati tra loro quando vengono trovati simili.
Si ripete il procedimento finch√© tutti gli oggetti non vengono agglomerati in un unico cluster.</p>
<p>Si parte quindi da N cluster, uno per ogni esempio e si agglomerano via via finch√© non si ottiene un unico cluster.</p>
<p>Ad ogni itereazione l&#39;algoritmo pu√≤ essere interroto per evitare di ottenere un unico cluster.</p>
<p>Le linee verticale di un dendogramma rappresentano un cluster, mentre quelle orizzontali rappresentano un punto di <strong>merge</strong> ovvero quando la similarit√† di due cluster √® tale che vengono uniti in un unico cluster.</p>
<p><img src="./notes/immagini/l17-clustering.png" alt=""></p>
<p>In base alla misura di similitarit√† l&#39;operazione pu√≤ essere <strong>monotona</strong> o meno, cio√® se <em>s<sub>1</sub>, ..., s<sub>k-1</sub></em> sono combinazioni di similarit√† associate a delle operazioni di merge, allora <em>s<sub>1</sub> &gt; ... &gt; s<sub>k-1</sub></em></p>
<h3 id="hac-hierarchical-agglormerative-clustering">HAC - Hierarchical agglormerative Clustering</h3>
<p>Prima viene creato un cluster per ogni esempio, dopodich√© viene eseguito via via il merge del <strong>clostes pair</strong>, ovvero dei due cluster pi√π simili, fino a che non rimane un unico cluster.
Lo storico dei merge crea il dendogramma.</p>
<p>Per scegliere il <strong>closest pair</strong> di cluster utilizzando vari criteri:</p>
<ul>
<li><strong>single link</strong>: ovvero la distanza minima che c&#39;√® tra tutte le coppie di elementi di cluster dirversi</li>
<li><strong>complete link</strong>: ovvero la distanza massima che c&#39;√® tra tutte le coppie di elementi di cluster dirversi</li>
<li><strong>centroid link</strong>: ovvero la distanza tra i dentroidi dei due cluster</li>
<li><strong>average link</strong>: la distanza media che c&#39;√® tra tutte le coppie di elementi di cluster dirversi</li>
</ul>
<p>Viene quindi effettuato prima il merge dei cluster con similirit√† minima.</p>
<p><img src="./notes/immagini/l17-dendogram-cluster.png" alt=""></p>
<p>Sia single link che complete link garantiscono la monotonia, tuttavia con single link si tendono a creare dei cluster che sono delle <em>catene</em>, ovvero si ottengono dei dendogrammi sbilanciati, mentre il complete link tende a dare dei cluster sferici e pi√π compatti, se per√≤ ci sono degli esempi <strong>outliers</strong>, ovvero che escono dalla distribuzione.</p>
<p>Il centroid link √® carino ma non garantisce la monotonia.</p>
<p><img src="./notes/immagini/l17-riassunto.png" alt=""></p>
<p>(le complessit√† della tabella indicano quante operazioni servono per scegliere il closest pair)</p>
<h1 id="lezione-18-feature-selection-e-kernel-learning">Lezione 18 - Feature selection e Kernel learning</h1>
<p>Gli attributi o variabili dovrebbero essere utilizzati solo se veramente utili (rilevanti) per la classificazione/predizione.</p>
<p>Avere meno attributi porta modelli di classificazione-predizione pi√π compatti e che hanno bisogno di un numero minore di esempi di apprendimento per ottenere dei buoni risultati.
Infatti, alcuni attributi possono introdurre del rumore sui dati.</p>
<p>Inoltre, modelli che usano pochi attributi sono pi√π semplci da ocmprendere per un umano e sono pi√π facilmente rappresentabili.</p>
<h2 id="feature-selection-ed-extraction">Feature selection ed extraction</h2>
<p><strong>Feature selection</strong>: viene selezionato un sotto insieme &quot;migliore&quot; degli attributi tra quelli originali. Ad esempio possono essere scartate delle feature ridondanti o non rilevanti. </p>
<p>In questo modo si ottiene un interpretabilit√† migliore del modello predittivo, pertanto questo approccio √® preferibile dove l&#39;interpretabilit√† √® pi√π importante dell&#39;accuratezza.</p>
<p><strong>Feature extraction</strong>: si derivano nuovi attributi da quelli originali, per esempio, nuove features vengono ottenuteo come combinazione di attributi.</p>
<p>In questo modo si ottengono featuer pi√π discriminative che portano ad avere un&#39;accuratezza migliore, pertanto questo approccio √® preferibile per applicazioni dove l&#39;accuratezza √® pi√π importante dell&#39;interpretabilit√†.</p>
<h3 id="feature-selection">Feature selection</h3>
<p>Ci sono tre famiglie principali di metodi:</p>
<ul>
<li><strong>Filter methods</strong>: considerano caratteristiche generali del training set, andando a pre-processare i dati indipendenemnte dall&#39;algoritmo di apprendimento. Viene calcolato uno score per le varie feature e vengono tenute solamente quelle migliori, senza tenere conto del supervisiore. Ad esempio questo metodo va a scartare le informazioni relative al nome di una persona.</li>
<li><strong>Wrapper methods</strong>: la selezione delle feature viene fatta sulla base della loro capacit√† predittive, tipicamente utilizzando un insieme di hold-out. Pu√≤ essere utilizzato un&#39;approccio <strong>backward</strong>, partendo prima con tutte le feature possibili, dopodich√© per ognuna delle feature si prova a toglierla e si controlla quanto migliora lo score. Si vanno via via a rimuovere in modo greedy le feature che portano ad un miglioramento dello score. L&#39;approccio <strong>backward</strong> parte da un numero minimo di feature e va ad aggiungere feature in modo da aumentare lo score.</li>
<li><strong>Embedde methons</strong>: la scelta delle feature viene inserita nel problema di minimizzazione, come nel metodo <strong>LASSO</strong>, Se <em>w</em> √® il vettore dei pesi che si va ad apprendere, si aggiunge al problema la massimizzazione della norma zero del vettore <em>w</em>. Nel lato pratico si usa l&#39;approssimazione ottenuta massimizzando la norma uno del vettore. (da sistemare)</li>
</ul>
<h3 id="feature-extraction">Feature extraction</h3>
<p>Il metodo pi√π importante si chiama <strong>Principal Component Analysis</strong> (PCA) e che consiste nella estrazione di un insieme di features non correlate linearmente.</p>
<p>Ovvero si mappano tutti gli esempi in poche dimensioni, queste dimensioni sono quelle che rappresentano meglio i dati del problema e allo stesso tempo diminuiscono il rumore sui dati.</p>
<p>Il numero di componenti principali √® solitamente molto inferiore al numero di features originali.</p>
<h3 id="applicazioni-della-feature-selection">Applicazioni della Feature Selection</h3>
<ul>
<li><strong>Biologia computazionale</strong>: in quanto si hanno pochi esempi e migliaia di features. Ad esempio si vuole sapere, dato il paziente si vuole sapere se una cura pu√≤ essere efficace o meno.</li>
<li><strong>Riconoscimento di facce</strong>: per determinare quali sono le feature importanti per il riconoscimento della faccia.</li>
<li><strong>Ambito medico</strong>: generalmente le variabili sono dei risultati degli esami medici, pertanto si cerca di minimizzare le variabili per ridurre i costi.</li>
<li><strong>Ambito finanziario</strong>: moltissimi fattori possono influenzare un titolo in borsa. Si cerca quindi di ridurre questo numero per rendere pi√π semplice il modello risultante.</li>
<li><strong>Classificazione dei testi</strong>: ad ogni termine √® associata una feature, riducendo questo numero si velocizza l&#39;apprendimento.</li>
</ul>
<h2 id="kernel-learning">Kernel Learning</h2>
<p>L&#39;idea √® quella di apprendere la funzione o la matrice kernel:</p>
<ol>
<li>Metodi parametrici per il kernel learing</li>
<li>Tranductive featuer extraction con kernel non lineari</li>
<li>Spectral kernel learning</li>
<li>Multiple kernel learning</li>
</ol>
<p><strong>Matrice kernel</strong>: matrice che per ogni coppia di dati di traning fornisce un valore che rappresenta il prodotto scalare della coppia.</p>
<h3 id="metodi-parametrici-per-il-kernel-learning">Metodi parametrici per il kernel learning</h3>
<p>L&#39;idea √® quella di prendere una funzione kernel come RBF e aggiungerci dei parametri.</p>
<blockquote>
<p>k(x,z) = e^{-(x-z)^t M(x-z)}</p>
</blockquote>
<p>e se <em>M = ùú∏I</em> si ottiene la versione classica di RBF</p>
<blockquote>
<p>k(x,z) = e^{-ùú∏||x-z||^2}</p>
</blockquote>
<p>Un&#39;altra scelta tipica √® <em>M = diag(ùú∏<sub>1</sub>, ...,ùú∏<sub>m</sub>)</em>, in questo caso le distanze vengono pesate dando maggiore importanza rispetto ad altre.</p>
<p>Con questo approccio vengono appresi anche i parametri ùú∏.</p>
<h3 id="transduction-feature-extraction-con-kernel-non-lineari">Transduction feature extraction con kernel non lineari</h3>
<p>Effettua una feature extraction implicitamente nel featuer space.</p>
<p><strong>KPCA</strong> o Kernel Principal Component Analisys va a calcolare implicitamente le proiezioni delle featuer principagli sugli autovettori (direzioni) principali.</p>
<p>Trattandosi di un caso non lineare, non √® possibile andare a calcolare esplicitamente le componenti principali, ma viene utilizzata una forumale che permette di calcolarle in modo pi√π agevole (implicitamente), un po&#39; come accade con i margini delle SVM. </p>
<p>Trattandosi di un approccio trasduttivo, pertanto pu√≤ essere utilizzato sole se si hanno ha disposizione tutte le componenti si riesce ad applicare. Se questo non √® possibile √® necessatio utilizzare delle tecniche dette <strong>out sample</strong>.</p>
<h3 id="spectral-kernel-learning">Spectral Kernel learning</h3>
<p>La matrice kernel, essendo definita positiva, pu√≤ essere scritta in un modo compatto in funzione degli autovalori e autovettori.</p>
<p>Utilizzando una trasfomrazione degli autovalori si va ad agire implicitamente nello spazio delle feature. Intaffi, il kernel modificato pu√≤ essere ottenuto utilizzando un po&#39; di algebra, andando a moltiplicare la matrice degli autovettori con la radice quadrata della matrice degli autovalori.</p>
<h3 id="multiple-kernel-learning">Multiple kernel learning</h3>
<p>L&#39;idea √® quella di combinare linearmente kernel diversi e definiti a priori, per poi apprendere la combinazione lineare di questi in modo da ottimizzare il kernel risultante.</p>
<ul>
<li><strong>Fixed methods</strong>: o metodi euristici, vengono utilizzati semplici regole che vengono utilizzate per il caloclo dei coefficenti, ad esempio il metodo pi√π semplice √® prendere la media dei kernel e stranamente, a livello pratico, funziona molto bene, oppure possono essere scelti dei pesi in base all&#39;accuratezza dei singoli kernel (funziona peggio rispetto alla media).</li>
<li><strong>Optimization method</strong>: inglobano i coefficenti come variabile da apprendere nel problema di ottimizzazione, ad esempio nelle SVM si pu√≤ modificare il problema di apprendimento per apprendere sia i coefficenti ùú∂, sia per i coefficenti della combinazione lineare.</li>
</ul>
<h1 id="lezione-19-sistemi-di-raccomandazione">Lezione 19 - Sistemi di raccomandazione</h1>
<p>Quando Facebook suggerisce gli amici, quando Amazon suggerisce dei prodotti e quando Youtube suggerisce dei video, viene utilizzato un sistema di raccomandazione.</p>
<h2 id="organizzazione-di-un-rs">Organizzazione di un RS</h2>
<p>C&#39;√® un sistema di <strong>esplict feedback</strong> che l&#39;utente esprime in modo quantitativo:</p>
<ul>
<li>Valutazione da 1 a 5 o con stelle</li>
<li>Un ordinamento dal preferito al meno favorito</li>
<li>Preferenze su coppie di oggetti</li>
</ul>
<p>Tutte queste valutazione sono intrusive e richiedono che l&#39;interazione dell&#39;utente.</p>
<p>Il sistema pu√≤ senn√≤ basarsi su <strong>implicit feedback</strong>:</p>
<ul>
<li>elenco dei prodotti che l&#39;utente ha visto/comprato</li>
<li>tempo di permanenza in una data pagina del sito</li>
<li>rete sociale dell&#39;utente</li>
</ul>
<p>In questo caso non c&#39;√® un responso esplicito delle preferenze dell&#39;utente ma vengono usati dei valori impliciti, ad esempio si pu√≤ presupporre che se l&#39;utente sta molto in una pagina web, quella gli interessa.
Il vantaggio del feedback implicito √® che non viene richiesto direttamente all&#39;utente, ma viene calcolato.</p>
<h2 id="approcci-per-la-raccomandazione">Approcci per la raccomandazione</h2>
<p>Ci sono 2 approcci principali per questi sistemi:</p>
<ul>
<li><strong>Content base</strong>: dato un utente sul quale si vuole fare predizione e si conosce gi√† il suo storico (di acquisti) gli si va a proporre dei prodotti simili secondo qualche categoria (autore, genere, ecc.).</li>
<li><strong>Collavorative filtering</strong>: si va a raccomandare agli utente gli pi√π simili a quelli che piaccinono ad altri utenti simili a lui. L&#39;idea √® che se un item piace a degli utenti simili all&#39;utente target, √® pi√π probabile che piaccia anche al target. La similarit√† tiene conto delle interazioni tra utenti e item.<ul>
<li>Similarit√† item-item: due oggetti sono simili se tendono ad ottenere lo stesso rate da parte degli utenti</li>
<li>Similarit√† user-user: due utenti sono simili se tendo a dare lo stesso rate ad item simili.</li>
<li>Questo approccio non tiene conto delle caratteristiche degli oggetti, ma solo delle preferenze degli utenti.</li>
</ul>
</li>
</ul>
<p>Il content base risulta migliore quando c&#39;√® poco storico (<strong>cold start problem</strong>), ovvero quando ho troppo poche informazioni relative alle interazioni tra l&#39;utente e gli oggetti.</p>
<p>Il collaborative filtering va di gran lunga meglio del content base quando le informazioni implicite contenute sulle interazioni tra l&#39;utente e gli oggetti diventa prevalente rispetto alle informazioni sugli oggetti.
Questo perch√© permette di scoprire nuovi pattern molto pi√π potenti rispetto a quelli che si possono definire sulle caratteristiche degli oggetti (ad esempio: suggerire canzoni dello stesso artista).</p>
<h2 id="rating-matrix">Rating Matrix</h2>
<p>Matrice che ha come righe gli utenti e come colonne i vari item.
Le celle della matrice contengono la valutazione dell&#39;utente per il dato item.</p>
<p>Nei casi reali queste matrici sono molto sparse, tipicamente 0.1% dei valori presenti.</p>
<p>C&#39;√® poi un&#39;altra sfiga, l&#39;<strong>effetto long tail</strong>: per pochi utenti saranno presenti tanti rate e per pochi prodotti ci saranno tanti rate. Ovvero ci sono poche righe che hanno tanti elementi e tante righe che hanno pochi elementi. Lo stesso vale anche per le colonne.</p>
<h2 id="problemi-di-predizione">Problemi di predizione</h2>
<p>Ci sono due problemi tipici:</p>
<ul>
<li><strong>Rate prediction</strong>: si vuole predirre il rate per un item che non √® stato valutato (tipico del rate esplicito).</li>
<li><strong>Item top-n recommendation</strong>: ordinamento degli item in funzione del gradimento che l&#39;utente potrebbe avere (tipo del rate implicito).</li>
</ul>
<p>Un esempio del secondo problema √® <strong>Million Song Dataset</strong>, una sfida di kaggle che consistenva nel predirre quali canzoni avrebbe ascoltato degli utenti, avendo a disposizione lo storico degli ascolti di un gran numero di utenti e met√† dello storico degli utenti per i queli si vuole fare la predizione.</p>
<h3 id="metodi-per-collaborative-filtering">Metodi per Collaborative filtering</h3>
<ul>
<li><strong>Rate Prediction</strong> (problema di regressione): Matrix Factorization, ovvero si apprende una rappresentazione per gli utenti e per gli items in modo che il loro prodotto scalare approssimi i rates presenti.</li>
</ul>
<blockquote>
<p>R&#39; = W V</p>
<ul>
<li>R&#39; √® la matrice approssimata</li>
<li>W √® una matrice NumeroUtenti x m</li>
<li>V √® una matrice m x NumeroItem</li>
</ul>
</blockquote>
<ul>
<li><strong>Top-N recomendation</strong> (problema di ranking): Matrix Factorization su preferenze, ovvero dato un utente si vuole stimare come l&#39;utente valuterebbe gli item per i quali non l&#39;ha ancora espressa. Gli item vengono quindi visti come gli esempi e gli si vuole dare una classe (l&#39;utente) e li si vuole ordinare in base a quanto quella classificazione √® probabile.
C&#39;√® un problema con il trattamento dei dati mancanti, perch√© la mancanza di un rating da parte dell&#39;utente non deve essere interpretata come negativa, ma come ignoranza.
Il problema √® quindi sbilanciato dal momento che non si hanno informazioni riguardo a che cosa non piace all&#39;utente.</li>
</ul>
<h2 id="valutazione-dei-rs">Valutazione dei RS</h2>
<p>Nel caso del rating esplicito si pu√≤ utilizzare <strong>RMSE</strong> (root mean square error), lo scarto quadratico medio degli errori commessi dall&#39;approssimazione.
Si tratta della misura pi√π popolare per questi problemi.</p>
<p>Nel caso di top-N ci sono:</p>
<ul>
<li><strong>AUC</strong> (Area Under ROC curve): propozione di coppie di items correttamente ordinate. Ovvero per ogni coppia di item controllo quanti sono ordinati male, proporzionati sul numero di confronto. Il caso ottimo ha AUC uguale a 1. Questa misura viene calcolata su tutto l&#39;ordinamento.</li>
<li><strong>prec@n</strong>: precisione ottenuta sui primi <em>n</em> item ordinati, una specie di AUC limitato ai primi <em>n</em> elementi.</li>
</ul>
<h2 id="collaborative-filtering-la-matematica-">Collaborative filtering (la matematica)</h2>
<h3 id="matrixfactorization-e-regressione">MatrixFactorization e regressione</h3>
<blockquote>
<p>r_ui = x_u<sup>T</sup>y_i</p>
</blockquote>
<p>L&#39;algorimto di apprendimento tenta quindi di ottimizzare x e y in modo da minimizzare l&#39;errore al quadrato sommato alla norma al quadrato di xu o yu.</p>
<p><em>formulone dalle slide</em></p>
<p>Il problema di minimizzazione non √® convesso, quindi o xu o yi deve essere fissato.</p>
<p>L&#39;approccio tipico √® quello di inizializzare a caso yi e fissarlo, per poi minimizzare su xu, una volta raggiunto il minimo, si fissa xu e si minimizza per yi, e via cos√¨ finch√© non si raggiunge la precisione desiderata.</p>
<h3 id="neirest-neightbors-based-cf">Neirest Neightbors based CF</h3>
<p>Per stimare il rate dell&#39;utente <em>u</em> si fa la media pesata dei rate dati dagli utenti che sono pi√π simili all&#39;utente <em>u</em>.
C&#39;√® anche il reciproco per gli item.</p>
<p><em>formulona dalle slide</em></p>
<h2 id="similarit-tra-utenti-e-items">Similarit√† tra utenti e items</h2>
<p><em>altre formulone dalla slide</em></p>
<p>La misura che si usa di pi√π √® la <strong>similirt√† coseno</strong> (prima formula), dove per coseno si intende il coseno definito tra due vettori.</p>
<p>L&#39;idea √® di prendere un vettore per ogni utente di lunghezza pari alla cardinalit√† dell&#39;insieme degli item e di mettere a 1 tutti gli elementi  del vettore che corrispondo ad un item che √® stato valutato.</p>
<p>In questo modo, facendo il prodotto scalare tra due vettori utenti, il risultato √® il numero di elementi in comunque, in questo caso quanti item sono stati valutati dai due utenti.
Mentre facendo la radice della norma di ...</p>
<p>Le formule delle slide ragionano ad insiemi, quanto detto sopra e fatto alla lavagna √® espresso in vettori, il punto √® che sono la stessa cosa.</p>
<p>Lo stesso ragionamento pu√≤ essere fatto per gli item in funzione degli utenti.</p>
<h2 id="link-prediction">Link prediction</h2>
<p>Altro argomento correlato ai RS.</p>
<p>Si ha a disposizione un grafo, con tutti i nodi noti e alcuni archi, si vuole riuscre a predirre se ci saranno dei nuovi archi tra questi nodi in base alla struttura nota del grafo.</p>
<p>Tipicamente questo problema viene rimappato su un problema di ranking/classificazione.</p>
<p>Ogni possibile arco pu√≤ essere rappresentato come un insieme di feature che possono essere usate per fare predizione con:</p>
<ul>
<li>Common Neighbours</li>
<li>Jacacard o altre misure di correlazione</li>
<li>Analisi dei path esistenti tra due nodi (come il PageRank)</li>
<li>ecc.</li>
</ul>
<p>La differenza con un problema di raccomanazione sta nel come vengono calcolate le feature.</p>
</body></html>